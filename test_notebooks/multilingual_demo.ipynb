{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Long-Form Alignment Demo\n",
    "\n",
    "This notebook demonstrates **TorchAudio Long-Form Aligner** across 8 languages using real-world audio and text data.\n",
    "\n",
    "## Languages Covered\n",
    "1. **English** - Meta Q1 2025 Earnings Call (~1 hour, 9K words)\n",
    "2. **Portuguese** - Orpheu Poetry (17 min, 18K words book)\n",
    "3. **Chinese** - Analects of Confucius (11.5 min, 15K chars)\n",
    "4. **Japanese** - Kaze Tachinu novel (57 min, 57K chars)\n",
    "5. **Hindi** - Universal Declaration of Human Rights (17.5 min)\n",
    "6. **Korean** - Universal Declaration of Human Rights (12 min)\n",
    "7. **Filipino (Tagalog)** - Universal Declaration of Human Rights (17.5 min)\n",
    "8. **Zhuang** - Bible Luke chapter (15.5 min, low-resource language)\n",
    "\n",
    "## Key Features Demonstrated\n",
    "- **Simple 3-line API**: `align_long_audio(audio, text)`\n",
    "- **Automatic text normalization**: PDF parsing, romanization, number expansion\n",
    "- **Long-form handling**: Segments audio, aligns with fuzzy matching, stitches with LIS\n",
    "- **Interactive verification**: Listen to aligned segments word-by-word\n",
    "\n",
    "## Requirements\n",
    "- k2 (WFST library)\n",
    "- lis (longest increasing subsequence)\n",
    "- Language-specific: uroman, cutlet (Japanese), zhon (CJK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Install Dependencies (auto-detect k2 version)\n# =============================================================================\n\nimport subprocess\nimport sys\n\ndef install_k2_if_needed():\n    \"\"\"Check if k2 is available, if not, install the correct version.\"\"\"\n    try:\n        import k2\n        print(f\"k2 already installed:\")\n        ! pip show k2\n        return True\n    except ImportError:\n        pass\n    \n    # Get system info\n    import torch\n    torch_version = torch.__version__.split('+')[0]  # e.g., \"2.5.0\"\n    torch_major_minor = '.'.join(torch_version.split('.')[:2])  # e.g., \"2.5\"\n    cuda_available = torch.cuda.is_available()\n    cuda_version = torch.version.cuda if cuda_available else None\n    \n    print(f\"PyTorch: {torch_version}\")\n    print(f\"CUDA available: {cuda_available}\")\n    if cuda_version:\n        print(f\"CUDA version: {cuda_version}\")\n    \n    # Determine which k2 to install\n    if cuda_available and cuda_version:\n        # GPU version\n        cuda_major_minor = '.'.join(cuda_version.split('.')[:2])  # e.g., \"12.4\"\n        index_url = \"https://k2-fsa.github.io/k2/cuda.html\"\n        print(f\"\\nLooking for k2 with CUDA {cuda_major_minor} and PyTorch {torch_major_minor}...\")\n        \n        # Try to find matching version from the index\n        # Common patterns: k2==1.24.4.dev20251030+cuda12.4.torch2.5.0\n        try:\n            import urllib.request\n            with urllib.request.urlopen(index_url, timeout=10) as response:\n                html = response.read().decode('utf-8')\n            \n            # Parse available versions\n            import re\n            # Match pattern like: k2-1.24.4.dev20251030+cuda12.4.torch2.5.0\n            pattern = rf'k2-[\\d.]+dev\\d+\\+cuda{re.escape(cuda_major_minor)}\\.torch{re.escape(torch_major_minor)}\\.\\d+'\n            matches = re.findall(pattern, html)\n            \n            if matches:\n                # Get the latest version (last match usually)\n                latest = matches[-1].replace('k2-', 'k2==').replace('+', '%2B')\n                # Convert back for pip\n                pkg_name = matches[-1].replace('k2-', 'k2==')\n                print(f\"Found: {pkg_name}\")\n                cmd = f\"pip install {pkg_name} -f {index_url}\"\n            else:\n                print(f\"No exact match found for CUDA {cuda_major_minor} + PyTorch {torch_major_minor}\")\n                print(\"Trying generic GPU install...\")\n                cmd = f\"pip install k2 -f {index_url}\"\n        except Exception as e:\n            print(f\"Could not fetch index: {e}\")\n            cmd = f\"pip install k2 -f {index_url}\"\n    else:\n        # CPU version\n        index_url = \"https://k2-fsa.github.io/k2/cpu.html\"\n        print(f\"\\nLooking for k2 CPU version for PyTorch {torch_major_minor}...\")\n        \n        try:\n            import urllib.request\n            with urllib.request.urlopen(index_url, timeout=10) as response:\n                html = response.read().decode('utf-8')\n            \n            import re\n            pattern = rf'k2-[\\d.]+dev\\d+\\+cpu\\.torch{re.escape(torch_major_minor)}\\.\\d+'\n            matches = re.findall(pattern, html)\n            \n            if matches:\n                pkg_name = matches[-1].replace('k2-', 'k2==')\n                print(f\"Found: {pkg_name}\")\n                cmd = f\"pip install {pkg_name} --no-deps -f {index_url}\"\n            else:\n                print(f\"No exact match found for PyTorch {torch_major_minor}\")\n                cmd = f\"pip install k2 --no-deps -f {index_url}\"\n        except Exception as e:\n            print(f\"Could not fetch index: {e}\")\n            cmd = f\"pip install k2 --no-deps -f {index_url}\"\n    \n    print(f\"\\nInstalling: {cmd}\")\n    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n    if result.returncode == 0:\n        print(\"k2 installed successfully!\")\n        return True\n    else:\n        print(f\"Installation failed: {result.stderr}\")\n        return False\n\ndef install_other_deps():\n    \"\"\"Install other required dependencies.\"\"\"\n    deps = [\n        \"pytorch-lightning\",\n        \"cmudict\",\n        \"g2p_en\",\n        \"pydub\",\n        \"pypdf\",\n        \"git+https://github.com/huangruizhe/lis.git\",\n    ]\n    for dep in deps:\n        try:\n            subprocess.run(f\"pip install -q {dep}\", shell=True, check=True)\n        except:\n            print(f\"Warning: Failed to install {dep}\")\n\n# Run installation\ninstall_k2_if_needed()\ninstall_other_deps()\nprint(\"\\nDependency installation complete.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Setup: Clone Repository and Configure Imports\n# =============================================================================\n\nimport sys\nimport os\nfrom pathlib import Path\n\n# ===== CONFIGURATION =====\nGITHUB_REPO = \"https://github.com/huangruizhe/torchaudio_aligner.git\"\nBRANCH = \"dev\"\n# =========================\n\ndef setup_imports():\n    IN_COLAB = 'google.colab' in sys.modules\n    \n    if IN_COLAB:\n        repo_path = '/content/torchaudio_aligner'\n        src_path = f'{repo_path}/src'\n        data_path = '/content/data'\n        \n        if not os.path.exists(repo_path):\n            print(f\"Cloning repository (branch: {BRANCH})...\")\n            os.system(f'git clone -b {BRANCH} {GITHUB_REPO} {repo_path}')\n        else:\n            print(f\"Updating repository (branch: {BRANCH})...\")\n            os.system(f'cd {repo_path} && git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}')\n        \n        if not os.path.exists(data_path):\n            os.makedirs(data_path)\n    else:\n        possible_paths = [\n            Path(\".\").absolute().parent / \"src\",\n            Path(\".\").absolute() / \"src\",\n        ]\n        src_path = None\n        for p in possible_paths:\n            if p.exists() and (p / \"alignment\").exists():\n                src_path = str(p.absolute())\n                break\n        if src_path is None:\n            raise FileNotFoundError(\"src directory not found\")\n        \n        # Data in parent directory\n        data_path = str(Path(src_path).parent.parent / \"examples\")\n        os.makedirs(data_path, exist_ok=True)\n        print(f\"Running locally from: {src_path}\")\n    \n    if src_path not in sys.path:\n        sys.path.insert(0, src_path)\n    \n    return src_path, data_path\n\nsrc_path, data_path = setup_imports()\n\nimport torch\nimport torchaudio\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\n# Import the simple API\nfrom api import align_long_audio\n\nprint()\nprint(\"=\" * 60)\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"TorchAudio: {torchaudio.__version__}\")\nprint(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\nprint(f\"Data path: {data_path}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check dependencies\nprint(\"Checking dependencies...\")\n\nK2_AVAILABLE = False\nLIS_AVAILABLE = False\n\ntry:\n    import k2\n    K2_AVAILABLE = True\n    print(\"k2: available\")\nexcept ImportError:\n    print(\"k2: NOT AVAILABLE - install with pip\")\n\ntry:\n    import lis\n    LIS_AVAILABLE = True\n    print(\"lis: available\")\nexcept ImportError:\n    print(\"lis: NOT AVAILABLE - pip install git+https://github.com/huangruizhe/lis.git\")\n\ntry:\n    from pypdf import PdfReader\n    print(\"pypdf: available\")\nexcept ImportError:\n    print(\"pypdf: NOT AVAILABLE - pip install pypdf\")\n\ntry:\n    from pydub import AudioSegment\n    print(\"pydub: available\")\nexcept ImportError:\n    print(\"pydub: NOT AVAILABLE - pip install pydub\")"
  },
  {
   "cell_type": "code",
   "source": "!pip install pytorch-lightning\n!pip install cmudict g2p_en\n!pip install pydub\n!pip install git+https://github.com/huangruizhe/lis.git\n!pip install torchcodec",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Import Audio Preview Functions from Library\n# =============================================================================\n\nfrom visualization_utils import play_random, play_words_sequential, play_segment\n\n# Note: result.summary() is built-in, no need for custom show_alignment_summary()\n\nprint(\"Audio preview functions imported from visualization_utils\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Language 1: English\n",
    "\n",
    "**Source**: Meta Q1 2025 Earnings Call\n",
    "- Audio: ~1 hour recording from SeekingAlpha\n",
    "- Text: ~9,200 words from Meta's investor relations PDF\n",
    "\n",
    "This demonstrates alignment of a real-world earnings call with noisy transcript (PDF artifacts, headers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download English data\n",
    "!wget -q -nc https://static.seekingalpha.com/cdn/s3/transcripts_audio/4780182.mp3 -O {data_path}/meta_earnings.mp3\n",
    "!wget -q -nc https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Transcripts/META-Q1-2025-Earnings-Call-Transcript-1.pdf -O {data_path}/meta_earnings.pdf\n",
    "\n",
    "print(\"English data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align English - Just 3 lines!\nresult_en = align_long_audio(\n    audio=f\"{data_path}/meta_earnings.mp3\",\n    text=f\"{data_path}/meta_earnings.pdf\",\n    language=\"eng\",\n    verbose=True,\n)\n\n# Use built-in summary\nprint(result_en.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Listen to a random segment using library function\ndisplay(play_random(result_en, num_words=30)[0])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Word-by-word listening using library function\nimport random\nstart = random.randint(0, max(0, len(result_en) - 10))\nplay_words_sequential(result_en, start_idx=start, num_words=8)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Portuguese data\n",
    "!wget -q -nc https://ia801705.us.archive.org/7/items/orpheu_no1_2010_librivox/orpheuno1_46__128kb.mp3 -O {data_path}/portuguese_orpheu.mp3\n",
    "\n",
    "# Download and parse text\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/23620/pg23620-images.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "text_pt = soup.get_text().replace(\"\\r\\n\", \"\\n\")\n",
    "\n",
    "# Save text\n",
    "with open(f\"{data_path}/portuguese_orpheu.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text_pt)\n",
    "\n",
    "print(f\"Portuguese data downloaded! Text: {len(text_pt.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Listen to a random segment\ndisplay(play_random(result_pt, num_words=30)[0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Chinese data\n",
    "!wget -q -nc https://ia801307.us.archive.org/15/items/lun_yu_0801_librivox/lunyu_14_confucius.mp3 -O {data_path}/chinese_confucius.mp3\n",
    "!wget -q -nc https://www.with.org/analects_ch.pdf -O {data_path}/chinese_confucius.pdf\n",
    "\n",
    "print(\"Chinese data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align Chinese\nresult_zh = align_long_audio(\n    audio=f\"{data_path}/chinese_confucius.mp3\",\n    text=f\"{data_path}/chinese_confucius.pdf\",\n    language=\"cmn\",  # ISO 639-3 code for Mandarin\n    verbose=True,\n)\n\nprint(result_zh.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Japanese data\n",
    "!wget -q -nc https://ia803207.us.archive.org/30/items/kazetachinu_ek_librivox/kazetachinu_03_hori.mp3 -O {data_path}/japanese_kaze.mp3\n",
    "\n",
    "# Download and parse Japanese text (with proper encoding)\n",
    "import urllib.request\n",
    "import html\n",
    "\n",
    "url = \"https://www.aozora.gr.jp/cards/001030/files/4803_14204.html\"\n",
    "response = urllib.request.urlopen(url)\n",
    "html_bytes = response.read()\n",
    "\n",
    "try:\n",
    "    text_ja = html_bytes.decode('utf-8')\n",
    "except:\n",
    "    try:\n",
    "        text_ja = html_bytes.decode('shiftjis')\n",
    "    except:\n",
    "        text_ja = html_bytes.decode('shift_jisx0213')\n",
    "\n",
    "text_ja = html.unescape(text_ja)\n",
    "soup = BeautifulSoup(text_ja, \"html.parser\")\n",
    "text_ja = soup.get_text().replace(\"\\r\\n\", \"\\n\")\n",
    "\n",
    "with open(f\"{data_path}/japanese_kaze.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text_ja)\n",
    "\n",
    "print(f\"Japanese data downloaded! Text: {len(text_ja)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align Japanese\nresult_ja = align_long_audio(\n    audio=f\"{data_path}/japanese_kaze.mp3\",\n    text=f\"{data_path}/japanese_kaze.txt\",\n    language=\"jpn\",  # ISO 639-3 code\n    verbose=True,\n)\n\nprint(result_ja.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align Hindi\nresult_hi = align_long_audio(\n    audio=f\"{data_path}/hindi_udhr.mp3\",\n    text=f\"{data_path}/hindi_udhr.pdf\",\n    language=\"hin\",  # ISO 639-3 code\n    verbose=True,\n)\n\nprint(result_hi.summary())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Listen to a random segment\ndisplay(play_random(result_hi, num_words=30)[0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align Korean\nresult_ko = align_long_audio(\n    audio=f\"{data_path}/korean_udhr.mp3\",\n    text=f\"{data_path}/korean_udhr.pdf\",\n    language=\"kor\",  # ISO 639-3 code\n    verbose=True,\n)\n\nprint(result_ko.summary())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Listen to a random segment\ndisplay(play_random(result_ko, num_words=30)[0])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Filipino data\n",
    "!wget -q -nc https://ia800906.us.archive.org/24/items/universal_declaration_librivox/human_rights_un_fil_alnl.mp3 -O {data_path}/filipino_udhr.mp3\n",
    "!wget -q -nc https://web.archive.org/web/20250110125503/https://www.ohchr.org/sites/default/files/UDHR/Documents/UDHR_Translations/tgl.pdf -O {data_path}/filipino_udhr.pdf\n",
    "\n",
    "print(\"Filipino data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align Filipino\nresult_fil = align_long_audio(\n    audio=f\"{data_path}/filipino_udhr.mp3\",\n    text=f\"{data_path}/filipino_udhr.pdf\",\n    language=\"tgl\",  # ISO 639-3 code for Tagalog\n    verbose=True,\n)\n\nprint(result_fil.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Zhuang data\n",
    "!wget -q -nc \"https://www.zhuangfuyin.org/sites/www.zhuangfuyin.org/files/media_stream/encodings/audio_download_mp3_orig_qual/499-.mp3\" -O {data_path}/zhuang_luke.mp3\n",
    "!wget -q -nc https://www.zhuangfuyin.org/sites/www.zhuangfuyin.org/files/uploads/Luhzaz.pdf -O {data_path}/zhuang_luke.pdf\n",
    "\n",
    "print(\"Zhuang data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align Zhuang\nresult_za = align_long_audio(\n    audio=f\"{data_path}/zhuang_luke.mp3\",\n    text=f\"{data_path}/zhuang_luke.pdf\",\n    language=\"zha\",  # ISO 639-3 code for Zhuang (generic)\n    verbose=True,\n)\n\nprint(result_za.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all results\n",
    "import os\n",
    "\n",
    "export_dir = f\"{data_path}/exports\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "for name, result, _ in results:\n",
    "    try:\n",
    "        prefix = name.lower().replace(\" \", \"_\")\n",
    "        \n",
    "        # Audacity labels\n",
    "        result.save_audacity_labels(f\"{export_dir}/{prefix}_labels.txt\")\n",
    "        \n",
    "        # JSON\n",
    "        result.save_json(f\"{export_dir}/{prefix}_alignment.json\")\n",
    "        \n",
    "        # SRT subtitles\n",
    "        result.save_srt(f\"{export_dir}/{prefix}_subtitles.srt\")\n",
    "        \n",
    "        print(f\"{name}: exported to {export_dir}/{prefix}_*\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: export failed - {e}\")\n",
    "\n",
    "print(f\"\\nAll exports saved to: {export_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}