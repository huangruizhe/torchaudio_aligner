{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multilingual Long-Form Alignment Demo\n",
        "\n",
        "This notebook demonstrates **TorchAudio Long-Form Aligner** across 8 languages using real-world audio and text data.\n",
        "\n",
        "## Languages Covered\n",
        "1. **English** - Meta Q1 2025 Earnings Call (~1 hour, 9K words)\n",
        "2. **Portuguese** - Orpheu Poetry (17 min, 18K words book)\n",
        "3. **Chinese** - Analects of Confucius (11.5 min, 15K chars)\n",
        "4. **Japanese** - Kaze Tachinu novel (57 min, 57K chars)\n",
        "5. **Hindi** - Universal Declaration of Human Rights (17.5 min)\n",
        "6. **Korean** - Universal Declaration of Human Rights (12 min)\n",
        "7. **Filipino (Tagalog)** - Universal Declaration of Human Rights (17.5 min)\n",
        "8. **Zhuang** - Bible Luke chapter (15.5 min, low-resource language)\n",
        "\n",
        "## Key Features Demonstrated\n",
        "- **Simple 3-line API**: `align_long_audio(audio, text)`\n",
        "- **Automatic text normalization**: PDF parsing, romanization, number expansion\n",
        "- **Long-form handling**: Segments audio, aligns with fuzzy matching, stitches with LIS\n",
        "- **Interactive verification**: Listen to aligned segments word-by-word\n",
        "\n",
        "## Requirements\n",
        "- k2 (WFST library)\n",
        "- lis (longest increasing subsequence)\n",
        "- Language-specific: uroman, cutlet (Japanese), zhon (CJK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Install Dependencies\n",
        "# =============================================================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_k2_if_needed():\n",
        "    \"\"\"Auto-detect and install the correct k2 version.\"\"\"\n",
        "    try:\n",
        "        import k2\n",
        "        print(f\"k2 already installed: {k2.__version__}\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        pass\n",
        "    \n",
        "    import torch\n",
        "    torch_version = '.'.join(torch.__version__.split('.')[:2])\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    cuda_version = torch.version.cuda if cuda_available else None\n",
        "    \n",
        "    print(f\"PyTorch: {torch.__version__}, CUDA: {cuda_version}\")\n",
        "    \n",
        "    if cuda_available and cuda_version:\n",
        "        cuda_mm = '.'.join(cuda_version.split('.')[:2])\n",
        "        index_url = \"https://k2-fsa.github.io/k2/cuda.html\"\n",
        "        cmd = f\"pip install k2 -f {index_url}\"\n",
        "    else:\n",
        "        index_url = \"https://k2-fsa.github.io/k2/cpu.html\"\n",
        "        cmd = f\"pip install k2 --no-deps -f {index_url}\"\n",
        "    \n",
        "    print(f\"Installing k2: {cmd}\")\n",
        "    subprocess.run(cmd, shell=True)\n",
        "    return True\n",
        "\n",
        "# Install all dependencies\n",
        "install_k2_if_needed()\n",
        "\n",
        "!pip install -q pytorch-lightning pydub pypdf\n",
        "!pip install -q git+https://github.com/huangruizhe/lis.git\n",
        "!pip install -q uroman-python zhon  # For romanization\n",
        "!pip install -q cutlet unidic-lite  # For Japanese\n",
        "!pip install -q num2words  # For number expansion\n",
        "\n",
        "print(\"\\nDependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Setup: Clone Repository and Configure Imports\n",
        "# =============================================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "GITHUB_REPO = \"https://github.com/huangruizhe/torchaudio_aligner.git\"\n",
        "BRANCH = \"dev\"\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    repo_path = '/content/torchaudio_aligner'\n",
        "    src_path = f'{repo_path}/src'\n",
        "    data_path = '/content/data'\n",
        "    \n",
        "    if not os.path.exists(repo_path):\n",
        "        print(f\"Cloning repository (branch: {BRANCH})...\")\n",
        "        os.system(f'git clone -b {BRANCH} {GITHUB_REPO} {repo_path}')\n",
        "    else:\n",
        "        print(f\"Updating repository...\")\n",
        "        os.system(f'cd {repo_path} && git pull origin {BRANCH}')\n",
        "    \n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "else:\n",
        "    # Running locally\n",
        "    src_path = str(Path(\".\").absolute().parent / \"src\")\n",
        "    data_path = str(Path(\".\").absolute().parent / \"examples\")\n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "from pydub import AudioSegment\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"TorchAudio: {torchaudio.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Data path: {data_path}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Import TorchAudio Aligner\n",
        "# =============================================================================\n",
        "\n",
        "from api import align_long_audio, AlignmentResult, AlignedWord\n",
        "from visualization_utils import preview_word_seconds, preview_segment_seconds\n",
        "\n",
        "print(\"TorchAudio Aligner imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Helper Functions for Demo\n",
        "# =============================================================================\n",
        "\n",
        "def play_random_segment(result, audio_file, num_words=30):\n",
        "    \"\"\"\n",
        "    Play a random segment of aligned words.\n",
        "    \n",
        "    Args:\n",
        "        result: AlignmentResult from align_long_audio()\n",
        "        audio_file: Path to the audio file\n",
        "        num_words: Number of words to play\n",
        "    \"\"\"\n",
        "    if len(result) < num_words:\n",
        "        num_words = len(result)\n",
        "    \n",
        "    start_idx = random.randint(0, len(result) - num_words)\n",
        "    words = result.words[start_idx:start_idx + num_words]\n",
        "    \n",
        "    # Get time range (use start_seconds() method)\n",
        "    t1 = words[0].start_seconds()\n",
        "    t2 = words[-1].end_seconds()\n",
        "    \n",
        "    # Load and slice audio\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "    segment = audio[t1 * 1000:t2 * 1000].set_channels(1)\n",
        "    \n",
        "    # Display text\n",
        "    text = \" \".join(w.word for w in words)\n",
        "    print(f\"\\nPlaying words {start_idx} to {start_idx + num_words}:\")\n",
        "    print(f\"Time: {t1:.2f}s - {t2:.2f}s\")\n",
        "    print(f\"\\nText: {text[:200]}{'...' if len(text) > 200 else ''}\")\n",
        "    \n",
        "    return ipd.Audio(segment.get_array_of_samples(), rate=segment.frame_rate)\n",
        "\n",
        "\n",
        "def play_word_by_word(result, audio_file, start_idx=0, num_words=10):\n",
        "    \"\"\"\n",
        "    Play words one by one with their text.\n",
        "    \n",
        "    Args:\n",
        "        result: AlignmentResult from align_long_audio()\n",
        "        audio_file: Path to the audio file\n",
        "        start_idx: Starting word index\n",
        "        num_words: Number of words to play\n",
        "    \"\"\"\n",
        "    audio = AudioSegment.from_file(audio_file).set_channels(1)\n",
        "    \n",
        "    print(f\"\\nPlaying words {start_idx} to {start_idx + num_words - 1}:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    words = result.words[start_idx:start_idx + num_words]\n",
        "    \n",
        "    for i, word in enumerate(words):\n",
        "        # Get end time (use next word's start or add buffer)\n",
        "        if i + 1 < len(words):\n",
        "            end_time = words[i + 1].start_seconds()\n",
        "        else:\n",
        "            end_time = word.end_seconds() + 0.3\n",
        "        \n",
        "        start_time = word.start_seconds()\n",
        "        \n",
        "        # Display word info\n",
        "        display_text = word.display_text if hasattr(word, 'display_text') else word.word\n",
        "        print(f\"\\n[{start_idx + i}] '{display_text}' ({start_time:.2f}s - {end_time:.2f}s):\")\n",
        "        \n",
        "        # Play audio segment\n",
        "        segment = audio[start_time * 1000:end_time * 1000]\n",
        "        display(ipd.Audio(segment.get_array_of_samples(), rate=segment.frame_rate))\n",
        "\n",
        "\n",
        "def show_alignment_summary(result, name=\"Alignment\"):\n",
        "    \"\"\"\n",
        "    Show a summary of alignment results.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"{name} Results\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    print(f\"Total aligned words: {len(result)}\")\n",
        "    \n",
        "    if len(result) > 0:\n",
        "        first_word = result.words[0]\n",
        "        last_word = result.words[-1]\n",
        "        duration = last_word.end_seconds() - first_word.start_seconds()\n",
        "        print(f\"Time span: {first_word.start_seconds():.2f}s - {last_word.end_seconds():.2f}s ({duration:.1f}s)\")\n",
        "        \n",
        "        print(f\"\\nFirst 5 words:\")\n",
        "        for w in result.words[:5]:\n",
        "            print(f\"  '{w.word}': {w.start_seconds():.2f}s - {w.end_seconds():.2f}s\")\n",
        "        \n",
        "        print(f\"\\nLast 5 words:\")\n",
        "        for w in result.words[-5:]:\n",
        "            print(f\"  '{w.word}': {w.start_seconds():.2f}s - {w.end_seconds():.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 1: English\n",
        "\n",
        "**Source**: Meta Q1 2025 Earnings Call\n",
        "- Audio: ~1 hour recording from SeekingAlpha\n",
        "- Text: ~9,200 words from Meta's investor relations PDF\n",
        "\n",
        "This demonstrates alignment of a real-world earnings call with noisy transcript (PDF artifacts, headers, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download English data\n",
        "!wget -q -nc https://static.seekingalpha.com/cdn/s3/transcripts_audio/4780182.mp3 -O {data_path}/meta_earnings.mp3\n",
        "!wget -q -nc https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Transcripts/META-Q1-2025-Earnings-Call-Transcript-1.pdf -O {data_path}/meta_earnings.pdf\n",
        "\n",
        "print(\"English data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align English - Just 3 lines!\n",
        "result_en = align_long_audio(\n",
        "    audio=f\"{data_path}/meta_earnings.mp3\",\n",
        "    text=f\"{data_path}/meta_earnings.pdf\",\n",
        "    language=\"eng\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_en, \"English (Meta Earnings Call)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_en, f\"{data_path}/meta_earnings.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Word-by-word listening (pick a random starting point)\n",
        "start = random.randint(0, max(0, len(result_en) - 10))\n",
        "play_word_by_word(result_en, f\"{data_path}/meta_earnings.mp3\", start_idx=start, num_words=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 2: Portuguese\n",
        "\n",
        "**Source**: Orpheu Poetry Book (LibriVox)\n",
        "- Audio: 17 minutes chapter \"Ode Triunfal\"\n",
        "- Text: 18K words from Project Gutenberg\n",
        "\n",
        "Demonstrates alignment with romanization (uroman for Portuguese diacritics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Portuguese data\n",
        "!wget -q -nc https://ia801705.us.archive.org/7/items/orpheu_no1_2010_librivox/orpheuno1_46__128kb.mp3 -O {data_path}/portuguese_orpheu.mp3\n",
        "\n",
        "# Download and parse text\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.gutenberg.org/cache/epub/23620/pg23620-images.html\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "text_pt = soup.get_text().replace(\"\\r\\n\", \"\\n\")\n",
        "\n",
        "# Save text\n",
        "with open(f\"{data_path}/portuguese_orpheu.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_pt)\n",
        "\n",
        "print(f\"Portuguese data downloaded! Text: {len(text_pt.split())} words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align Portuguese\n",
        "result_pt = align_long_audio(\n",
        "    audio=f\"{data_path}/portuguese_orpheu.mp3\",\n",
        "    text=f\"{data_path}/portuguese_orpheu.txt\",\n",
        "    language=\"por\",  # ISO 639-3 code\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_pt, \"Portuguese (Orpheu Poetry)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_pt, f\"{data_path}/portuguese_orpheu.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 3: Chinese (Mandarin)\n",
        "\n",
        "**Source**: Analects of Confucius (LibriVox)\n",
        "- Audio: 11.5 minutes chapter\n",
        "- Text: 15K Chinese characters\n",
        "\n",
        "Demonstrates character-level alignment for CJK languages with romanization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Chinese data\n",
        "!wget -q -nc https://ia801307.us.archive.org/15/items/lun_yu_0801_librivox/lunyu_14_confucius.mp3 -O {data_path}/chinese_confucius.mp3\n",
        "!wget -q -nc https://www.with.org/analects_ch.pdf -O {data_path}/chinese_confucius.pdf\n",
        "\n",
        "print(\"Chinese data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align Chinese\n",
        "result_zh = align_long_audio(\n",
        "    audio=f\"{data_path}/chinese_confucius.mp3\",\n",
        "    text=f\"{data_path}/chinese_confucius.pdf\",\n",
        "    language=\"cmn\",  # ISO 639-3 code for Mandarin\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_zh, \"Chinese (Analects of Confucius)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_zh, f\"{data_path}/chinese_confucius.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 4: Japanese\n",
        "\n",
        "**Source**: Kaze Tachinu (The Wind Rises) novel (LibriVox)\n",
        "- Audio: 57.5 minutes chapter\n",
        "- Text: 57K Japanese characters from Aozora Bunko\n",
        "\n",
        "Demonstrates alignment with Japanese morphological analysis (cutlet for romaji)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Japanese data\n",
        "!wget -q -nc https://ia803207.us.archive.org/30/items/kazetachinu_ek_librivox/kazetachinu_03_hori.mp3 -O {data_path}/japanese_kaze.mp3\n",
        "\n",
        "# Download and parse Japanese text (with proper encoding)\n",
        "import urllib.request\n",
        "import html\n",
        "\n",
        "url = \"https://www.aozora.gr.jp/cards/001030/files/4803_14204.html\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html_bytes = response.read()\n",
        "\n",
        "try:\n",
        "    text_ja = html_bytes.decode('utf-8')\n",
        "except:\n",
        "    try:\n",
        "        text_ja = html_bytes.decode('shiftjis')\n",
        "    except:\n",
        "        text_ja = html_bytes.decode('shift_jisx0213')\n",
        "\n",
        "text_ja = html.unescape(text_ja)\n",
        "soup = BeautifulSoup(text_ja, \"html.parser\")\n",
        "text_ja = soup.get_text().replace(\"\\r\\n\", \"\\n\")\n",
        "\n",
        "with open(f\"{data_path}/japanese_kaze.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_ja)\n",
        "\n",
        "print(f\"Japanese data downloaded! Text: {len(text_ja)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align Japanese\n",
        "result_ja = align_long_audio(\n",
        "    audio=f\"{data_path}/japanese_kaze.mp3\",\n",
        "    text=f\"{data_path}/japanese_kaze.txt\",\n",
        "    language=\"jpn\",  # ISO 639-3 code\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_ja, \"Japanese (Kaze Tachinu)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_ja, f\"{data_path}/japanese_kaze.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 5: Hindi\n",
        "\n",
        "**Source**: Universal Declaration of Human Rights (LibriVox)\n",
        "- Audio: 17.5 minutes\n",
        "- Text: 2K Hindi words (from PDF with OCR)\n",
        "\n",
        "Demonstrates alignment with OCR-extracted text and Devanagari script romanization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Hindi data\n",
        "!wget -q -nc https://www.archive.org/download/human_rights_02_0908_librivox/human_rights_un_hin_brc.mp3 -O {data_path}/hindi_udhr.mp3\n",
        "!wget -q -nc https://web.archive.org/web/20250623004015/https://www.ohchr.org/sites/default/files/UDHR/Documents/UDHR_Translations/hnd.pdf -O {data_path}/hindi_udhr.pdf\n",
        "\n",
        "print(\"Hindi data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: Hindi PDF requires OCR. For this demo, we'll use uroman on the extracted text.\n",
        "# In production, you might use easyocr for scanned PDFs.\n",
        "\n",
        "result_hi = align_long_audio(\n",
        "    audio=f\"{data_path}/hindi_udhr.mp3\",\n",
        "    text=f\"{data_path}/hindi_udhr.pdf\",\n",
        "    language=\"hin\",  # ISO 639-3 code\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_hi, \"Hindi (UDHR)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_hi, f\"{data_path}/hindi_udhr.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 6: Korean\n",
        "\n",
        "**Source**: Universal Declaration of Human Rights (LibriVox)\n",
        "- Audio: 12 minutes\n",
        "- Text: 1.3K Korean words from PDF\n",
        "\n",
        "Demonstrates alignment with Hangul script romanization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Korean data\n",
        "!wget -q -nc https://ia800906.us.archive.org/24/items/universal_declaration_librivox/human_rights_un_kkn_lsj.mp3 -O {data_path}/korean_udhr.mp3\n",
        "!wget -q -nc https://web.archive.org/web/20250114234231/https://www.ohchr.org/sites/default/files/UDHR/Documents/UDHR_Translations/kkn.pdf -O {data_path}/korean_udhr.pdf\n",
        "\n",
        "print(\"Korean data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align Korean\n",
        "result_ko = align_long_audio(\n",
        "    audio=f\"{data_path}/korean_udhr.mp3\",\n",
        "    text=f\"{data_path}/korean_udhr.pdf\",\n",
        "    language=\"kor\",  # ISO 639-3 code\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_ko, \"Korean (UDHR)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_ko, f\"{data_path}/korean_udhr.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 7: Filipino (Tagalog)\n",
        "\n",
        "**Source**: Universal Declaration of Human Rights (LibriVox)\n",
        "- Audio: 17.5 minutes\n",
        "- Text: 2K words from PDF\n",
        "\n",
        "Demonstrates alignment for Filipino/Tagalog which uses Latin script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Filipino data\n",
        "!wget -q -nc https://ia800906.us.archive.org/24/items/universal_declaration_librivox/human_rights_un_fil_alnl.mp3 -O {data_path}/filipino_udhr.mp3\n",
        "!wget -q -nc https://web.archive.org/web/20250110125503/https://www.ohchr.org/sites/default/files/UDHR/Documents/UDHR_Translations/tgl.pdf -O {data_path}/filipino_udhr.pdf\n",
        "\n",
        "print(\"Filipino data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align Filipino\n",
        "result_fil = align_long_audio(\n",
        "    audio=f\"{data_path}/filipino_udhr.mp3\",\n",
        "    text=f\"{data_path}/filipino_udhr.pdf\",\n",
        "    language=\"tgl\",  # ISO 639-3 code for Tagalog\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_fil, \"Filipino/Tagalog (UDHR)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_fil, f\"{data_path}/filipino_udhr.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Language 8: Zhuang (Low-Resource)\n",
        "\n",
        "**Source**: Bible - Book of Luke (Southern Zhuang translation)\n",
        "- Audio: 15.5 minutes chapter\n",
        "- Text: 21K words from PDF\n",
        "\n",
        "Demonstrates alignment for a **low-resource language**. Zhuang is spoken in Southern China. Northern Zhuang is in MMS training data, but Southern Zhuang is NOT - this tests cross-dialect transfer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Zhuang data\n",
        "!wget -q -nc \"https://www.zhuangfuyin.org/sites/www.zhuangfuyin.org/files/media_stream/encodings/audio_download_mp3_orig_qual/499-.mp3\" -O {data_path}/zhuang_luke.mp3\n",
        "!wget -q -nc https://www.zhuangfuyin.org/sites/www.zhuangfuyin.org/files/uploads/Luhzaz.pdf -O {data_path}/zhuang_luke.pdf\n",
        "\n",
        "print(\"Zhuang data downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align Zhuang\n",
        "# Note: Zhuang uses Latin script with tone marks, so minimal romanization needed\n",
        "result_za = align_long_audio(\n",
        "    audio=f\"{data_path}/zhuang_luke.mp3\",\n",
        "    text=f\"{data_path}/zhuang_luke.pdf\",\n",
        "    language=\"zha\",  # ISO 639-3 code for Zhuang (generic)\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "show_alignment_summary(result_za, \"Zhuang (Bible - Luke)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to a random segment\n",
        "display(play_random_segment(result_za, f\"{data_path}/zhuang_luke.mp3\", num_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "We've demonstrated alignment across 8 languages:\n",
        "\n",
        "| Language | Script | Romanization | Audio Length | Text Size |\n",
        "|----------|--------|--------------|--------------|----------|\n",
        "| English | Latin | None needed | ~60 min | ~9K words |\n",
        "| Portuguese | Latin | uroman | ~17 min | ~18K words |\n",
        "| Chinese | Han | uroman | ~11 min | ~15K chars |\n",
        "| Japanese | Mixed | cutlet | ~57 min | ~57K chars |\n",
        "| Hindi | Devanagari | uroman | ~17 min | ~2K words |\n",
        "| Korean | Hangul | uroman | ~12 min | ~1.3K words |\n",
        "| Filipino | Latin | uroman | ~17 min | ~2K words |\n",
        "| Zhuang | Latin | None needed | ~15 min | ~21K words |\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Simple API**: `align_long_audio(audio, text, language)` handles everything\n",
        "2. **Automatic preprocessing**: PDF parsing, text normalization, romanization\n",
        "3. **Robust to noise**: Works with real-world noisy transcripts (PDF artifacts, headers, etc.)\n",
        "4. **Low-resource languages**: MMS model transfers to unseen languages\n",
        "5. **Long-form support**: Handles hours of audio efficiently with segment-and-stitch approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary table\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ALIGNMENT SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Language':<15} {'Words Aligned':<15} {'Coverage':<12} {'Duration':<12}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "results = [\n",
        "    (\"English\", result_en, f\"{data_path}/meta_earnings.mp3\"),\n",
        "    (\"Portuguese\", result_pt, f\"{data_path}/portuguese_orpheu.mp3\"),\n",
        "    (\"Chinese\", result_zh, f\"{data_path}/chinese_confucius.mp3\"),\n",
        "    (\"Japanese\", result_ja, f\"{data_path}/japanese_kaze.mp3\"),\n",
        "    (\"Hindi\", result_hi, f\"{data_path}/hindi_udhr.mp3\"),\n",
        "    (\"Korean\", result_ko, f\"{data_path}/korean_udhr.mp3\"),\n",
        "    (\"Filipino\", result_fil, f\"{data_path}/filipino_udhr.mp3\"),\n",
        "    (\"Zhuang\", result_za, f\"{data_path}/zhuang_luke.mp3\"),\n",
        "]\n",
        "\n",
        "for name, result, audio_path in results:\n",
        "    try:\n",
        "        words = len(result)\n",
        "        if words > 0:\n",
        "            duration = result.words[-1].end_seconds() - result.words[0].start_seconds()\n",
        "            duration_str = f\"{duration/60:.1f} min\"\n",
        "        else:\n",
        "            duration_str = \"N/A\"\n",
        "        print(f\"{name:<15} {words:<15} {'N/A':<12} {duration_str:<12}\")\n",
        "    except:\n",
        "        print(f\"{name:<15} {'ERROR':<15}\")\n",
        "\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Export Results\n",
        "\n",
        "Save alignment results in various formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export all results\n",
        "import os\n",
        "\n",
        "export_dir = f\"{data_path}/exports\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "for name, result, _ in results:\n",
        "    try:\n",
        "        prefix = name.lower().replace(\" \", \"_\")\n",
        "        \n",
        "        # Audacity labels\n",
        "        result.save_audacity_labels(f\"{export_dir}/{prefix}_labels.txt\")\n",
        "        \n",
        "        # JSON\n",
        "        result.save_json(f\"{export_dir}/{prefix}_alignment.json\")\n",
        "        \n",
        "        # SRT subtitles\n",
        "        result.save_srt(f\"{export_dir}/{prefix}_subtitles.srt\")\n",
        "        \n",
        "        print(f\"{name}: exported to {export_dir}/{prefix}_*\")\n",
        "    except Exception as e:\n",
        "        print(f\"{name}: export failed - {e}\")\n",
        "\n",
        "print(f\"\\nAll exports saved to: {export_dir}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
