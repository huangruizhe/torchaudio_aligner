{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Long-Form Alignment Test\n",
    "\n",
    "This notebook tests the complete long-form alignment pipeline using **Meta's Q1 2025 Earnings Call** (~1 hour audio, ~9K words).\n",
    "\n",
    "**Pipeline:**\n",
    "1. Audio Frontend: Load, resample, segment\n",
    "2. Text Frontend: Load PDF, normalize, tokenize\n",
    "3. Labeling Utils: MMS-FA model inference\n",
    "4. Alignment: WFST-based flexible alignment\n",
    "5. Stitching: LIS-based segment concatenation\n",
    "6. Visualization: Audacity labels, Gentle HTML, audio preview\n",
    "\n",
    "**Tests:**\n",
    "1. Setup and imports\n",
    "2. Load audio (Meta earnings call)\n",
    "3. Load text (PDF transcript)\n",
    "4. Run alignment pipeline (step-by-step, Tutorial.py pattern)\n",
    "4B. **High-level API test** (`align_long_audio()` - recommended for users)\n",
    "5. Inspect results\n",
    "6. Audacity label export\n",
    "7. Gentle HTML visualization\n",
    "8. Random segment listening test\n",
    "9. Word-by-word listening test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Install Dependencies (auto-detect k2 version)\n",
    "# =============================================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_k2_if_needed():\n",
    "    \"\"\"Check if k2 is available, if not, install the correct version.\"\"\"\n",
    "    try:\n",
    "        import k2\n",
    "        print(f\"k2 already installed:\")\n",
    "        ! pip show k2\n",
    "        return True\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Get system info\n",
    "    import torch\n",
    "    torch_version = torch.__version__.split('+')[0]  # e.g., \"2.5.0\"\n",
    "    torch_major_minor = '.'.join(torch_version.split('.')[:2])  # e.g., \"2.5\"\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    cuda_version = torch.version.cuda if cuda_available else None\n",
    "    \n",
    "    print(f\"PyTorch: {torch_version}\")\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "    if cuda_version:\n",
    "        print(f\"CUDA version: {cuda_version}\")\n",
    "    \n",
    "    # Determine which k2 to install\n",
    "    if cuda_available and cuda_version:\n",
    "        # GPU version\n",
    "        cuda_major_minor = '.'.join(cuda_version.split('.')[:2])  # e.g., \"12.4\"\n",
    "        index_url = \"https://k2-fsa.github.io/k2/cuda.html\"\n",
    "        print(f\"\\nLooking for k2 with CUDA {cuda_major_minor} and PyTorch {torch_major_minor}...\")\n",
    "        \n",
    "        # Try to find matching version from the index\n",
    "        # Common patterns: k2==1.24.4.dev20251030+cuda12.4.torch2.5.0\n",
    "        try:\n",
    "            import urllib.request\n",
    "            with urllib.request.urlopen(index_url, timeout=10) as response:\n",
    "                html = response.read().decode('utf-8')\n",
    "            \n",
    "            # Parse available versions\n",
    "            import re\n",
    "            # Match pattern like: k2-1.24.4.dev20251030+cuda12.4.torch2.5.0\n",
    "            pattern = rf'k2-[\\d.]+dev\\d+\\+cuda{re.escape(cuda_major_minor)}\\.torch{re.escape(torch_major_minor)}\\.\\d+'\n",
    "            matches = re.findall(pattern, html)\n",
    "            \n",
    "            if matches:\n",
    "                # Get the latest version (last match usually)\n",
    "                latest = matches[-1].replace('k2-', 'k2==').replace('+', '%2B')\n",
    "                # Convert back for pip\n",
    "                pkg_name = matches[-1].replace('k2-', 'k2==')\n",
    "                print(f\"Found: {pkg_name}\")\n",
    "                cmd = f\"pip install {pkg_name} -f {index_url}\"\n",
    "            else:\n",
    "                print(f\"No exact match found for CUDA {cuda_major_minor} + PyTorch {torch_major_minor}\")\n",
    "                print(\"Trying generic GPU install...\")\n",
    "                cmd = f\"pip install k2 -f {index_url}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch index: {e}\")\n",
    "            cmd = f\"pip install k2 -f {index_url}\"\n",
    "    else:\n",
    "        # CPU version\n",
    "        index_url = \"https://k2-fsa.github.io/k2/cpu.html\"\n",
    "        print(f\"\\nLooking for k2 CPU version for PyTorch {torch_major_minor}...\")\n",
    "        \n",
    "        try:\n",
    "            import urllib.request\n",
    "            with urllib.request.urlopen(index_url, timeout=10) as response:\n",
    "                html = response.read().decode('utf-8')\n",
    "            \n",
    "            import re\n",
    "            pattern = rf'k2-[\\d.]+dev\\d+\\+cpu\\.torch{re.escape(torch_major_minor)}\\.\\d+'\n",
    "            matches = re.findall(pattern, html)\n",
    "            \n",
    "            if matches:\n",
    "                pkg_name = matches[-1].replace('k2-', 'k2==')\n",
    "                print(f\"Found: {pkg_name}\")\n",
    "                cmd = f\"pip install {pkg_name} --no-deps -f {index_url}\"\n",
    "            else:\n",
    "                print(f\"No exact match found for PyTorch {torch_major_minor}\")\n",
    "                cmd = f\"pip install k2 --no-deps -f {index_url}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch index: {e}\")\n",
    "            cmd = f\"pip install k2 --no-deps -f {index_url}\"\n",
    "    \n",
    "    print(f\"\\nInstalling: {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"k2 installed successfully!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Installation failed: {result.stderr}\")\n",
    "        return False\n",
    "\n",
    "def install_other_deps():\n",
    "    \"\"\"Install other required dependencies.\"\"\"\n",
    "    deps = [\n",
    "        \"pytorch-lightning\",\n",
    "        \"cmudict\",\n",
    "        \"g2p_en\",\n",
    "        \"pydub\",\n",
    "        \"pypdf\",\n",
    "        \"git+https://github.com/huangruizhe/lis.git\",\n",
    "    ]\n",
    "    for dep in deps:\n",
    "        try:\n",
    "            subprocess.run(f\"pip install -q {dep}\", shell=True, check=True)\n",
    "        except:\n",
    "            print(f\"Warning: Failed to install {dep}\")\n",
    "\n",
    "# Run installation\n",
    "install_k2_if_needed()\n",
    "install_other_deps()\n",
    "print(\"\\nDependency installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Setup: Clone Repository and Configure Imports\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "GITHUB_REPO = \"https://github.com/huangruizhe/torchaudio_aligner.git\"\n",
    "BRANCH = \"dev\"\n",
    "# =========================\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "def setup_imports():\n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        repo_path = '/content/torchaudio_aligner'\n",
    "        src_path = f'{repo_path}/src'\n",
    "        examples_path = '/content/examples'\n",
    "        \n",
    "        if not os.path.exists(repo_path):\n",
    "            print(f\"Cloning repository (branch: {BRANCH})...\")\n",
    "            os.system(f'git clone -b {BRANCH} {GITHUB_REPO} {repo_path}')\n",
    "        else:\n",
    "            print(f\"Updating repository (branch: {BRANCH})...\")\n",
    "            os.system(f'cd {repo_path} && git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}')\n",
    "        \n",
    "        # Download Meta earnings call if not present\n",
    "        if not os.path.exists(examples_path):\n",
    "            os.makedirs(examples_path)\n",
    "        \n",
    "        if not os.path.exists(f'{examples_path}/4780182.mp3'):\n",
    "            print(\"Downloading Meta Q1 2025 Earnings Call audio...\")\n",
    "            os.system(f'wget -q https://static.seekingalpha.com/cdn/s3/transcripts_audio/4780182.mp3 -O {examples_path}/4780182.mp3')\n",
    "        \n",
    "        if not os.path.exists(f'{examples_path}/META-Q1-2025-Earnings-Call-Transcript-1.pdf'):\n",
    "            print(\"Downloading Meta Q1 2025 Earnings Call transcript...\")\n",
    "            os.system(f'wget -q https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Transcripts/META-Q1-2025-Earnings-Call-Transcript-1.pdf -O {examples_path}/META-Q1-2025-Earnings-Call-Transcript-1.pdf')\n",
    "    else:\n",
    "        possible_paths = [\n",
    "            Path(\".\").absolute().parent / \"src\",\n",
    "            Path(\".\").absolute() / \"src\",\n",
    "        ]\n",
    "        src_path = None\n",
    "        for p in possible_paths:\n",
    "            if p.exists() and (p / \"alignment\").exists():\n",
    "                src_path = str(p.absolute())\n",
    "                break\n",
    "        if src_path is None:\n",
    "            raise FileNotFoundError(\"src directory not found\")\n",
    "        \n",
    "        # Examples in parent directory\n",
    "        examples_path = str(Path(src_path).parent.parent / \"examples\")\n",
    "        print(f\"Running locally from: {src_path}\")\n",
    "    \n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "    \n",
    "    return src_path, examples_path\n",
    "\n",
    "src_path, examples_path = setup_imports()\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"TorchAudio: {torchaudio.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "print(f\"Examples: {examples_path}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dependencies\n",
    "print(\"Checking dependencies...\")\n",
    "\n",
    "K2_AVAILABLE = False\n",
    "LIS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import k2\n",
    "    K2_AVAILABLE = True\n",
    "    print(\"k2: available\")\n",
    "except ImportError:\n",
    "    print(\"k2: NOT AVAILABLE - install with pip\")\n",
    "\n",
    "try:\n",
    "    import lis\n",
    "    LIS_AVAILABLE = True\n",
    "    print(\"lis: available\")\n",
    "except ImportError:\n",
    "    print(\"lis: NOT AVAILABLE - pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "\n",
    "try:\n",
    "    from pypdf import PdfReader\n",
    "    print(\"pypdf: available\")\n",
    "except ImportError:\n",
    "    print(\"pypdf: NOT AVAILABLE - pip install pypdf\")\n",
    "\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    print(\"pydub: available\")\n",
    "except ImportError:\n",
    "    print(\"pydub: NOT AVAILABLE - pip install pydub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752498d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning\n",
    "!pip install cmudict g2p_en\n",
    "!pip install pydub\n",
    "!pip install git+https://github.com/huangruizhe/lis.git\n",
    "!pip install torchcodec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Test 1: Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"Test 1: Module Imports\")\nprint(\"=\" * 60)\n\ntry:\n    # Core modules\n    from audio_frontend import AudioFrontend, segment_audio, segment_waveform\n    from text_frontend import load_text_from_pdf, normalize_for_mms, CharTokenizer, create_tokenizer_from_labels\n    from labeling_utils import load_model\n    \n    # Alignment - following Tutorial.py pattern\n    from alignment import AlignmentResult, AlignedWord, AlignmentConfig\n    from alignment.wfst.factor_transducer import make_factor_transducer_word_level_index_with_skip\n    from alignment.wfst.k2_utils import align_segments, concat_alignments, get_final_word_alignment\n    from alignment.wfst.lis_utils import compute_lis, remove_outliers, find_unaligned_regions\n    from alignment.base import AlignedToken\n    \n    print(\"All modules imported successfully!\")\n    test_results[\"Test 1\"] = \"PASSED\"\n    print(\"\\nTest 1 PASSED\")\nexcept Exception as e:\n    test_results[\"Test 1\"] = \"FAILED\"\n    print(f\"Test 1 FAILED: {e}\")\n    import traceback; traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Test 2: Load Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 2: Load Audio (Meta Q1 2025 Earnings Call)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    AUDIO_FILE = f\"{examples_path}/4780182.mp3\"\n",
    "    \n",
    "    print(f\"\\nLoading: {AUDIO_FILE}\")\n",
    "    \n",
    "    # Load and preprocess\n",
    "    waveform, orig_sr = torchaudio.load(AUDIO_FILE)\n",
    "    print(f\"  Original: {waveform.shape}, {orig_sr}Hz\")\n",
    "    \n",
    "    # Resample to 16kHz\n",
    "    if orig_sr != 16000:\n",
    "        waveform = torchaudio.functional.resample(waveform, orig_sr, 16000)\n",
    "    sr = 16000\n",
    "    \n",
    "    # Convert to mono\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(0, keepdim=True)\n",
    "    \n",
    "    duration_sec = waveform.size(1) / sr\n",
    "    duration_min = duration_sec / 60\n",
    "    \n",
    "    print(f\"  Processed: {waveform.shape}, {sr}Hz\")\n",
    "    print(f\"  Duration: {duration_sec:.1f}s ({duration_min:.1f} minutes)\")\n",
    "    \n",
    "    # Segment\n",
    "    from audio_frontend import segment_waveform\n",
    "    segmentation = segment_waveform(\n",
    "        waveform.squeeze(0),\n",
    "        sample_rate=sr,\n",
    "        segment_size=15.0,\n",
    "        overlap=2.0,\n",
    "    )\n",
    "    print(f\"  Segments: {segmentation.num_segments}\")\n",
    "    \n",
    "    test_results[\"Test 2\"] = \"PASSED\"\n",
    "    print(\"\\nTest 2 PASSED\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 2\"] = \"FAILED\"\n",
    "    print(f\"Test 2 FAILED: {e}\")\n",
    "    import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Test 3: Load Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 3: Load Text (Meta Q1 2025 Earnings Call Transcript)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    PDF_FILE = f\"{examples_path}/META-Q1-2025-Earnings-Call-Transcript-1.pdf\"\n",
    "    \n",
    "    print(f\"\\nLoading: {PDF_FILE}\")\n",
    "    \n",
    "    # Load PDF\n",
    "    text = load_text_from_pdf(PDF_FILE)\n",
    "    print(f\"  Raw text: {len(text)} characters\")\n",
    "    print(f\"  Raw words: {len(text.split())}\")\n",
    "    \n",
    "    # Preview\n",
    "    print(f\"\\n  Preview (first 500 chars):\")\n",
    "    print(f\"  {text[:500]}...\")\n",
    "    \n",
    "    # Normalize for MMS\n",
    "    text_normalized = normalize_for_mms(text, expand_numbers=True)\n",
    "    text_words = text_normalized.split()\n",
    "    print(f\"\\n  Normalized words: {len(text_words)}\")\n",
    "    print(f\"  Preview: {' '.join(text_words[:20])}...\")\n",
    "    \n",
    "    test_results[\"Test 3\"] = \"PASSED\"\n",
    "    print(\"\\nTest 3 PASSED\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 3\"] = \"FAILED\"\n",
    "    print(f\"Test 3 FAILED: {e}\")\n",
    "    import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Test 4: Run Alignment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"Test 4: Run Alignment Pipeline (following Tutorial.py)\")\nprint(\"=\" * 60)\n\nif not K2_AVAILABLE or not LIS_AVAILABLE:\n    test_results[\"Test 4\"] = \"SKIPPED\"\n    print(\"SKIPPED - k2 or lis not available\")\nelse:\n    try:\n        from tqdm import tqdm\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Device: {device}\")\n        \n        # Step 1: Load model\n        print(\"\\nStep 1: Loading MMS-FA model...\")\n        model = load_model(\"mms-fa\")\n        vocab = model.get_vocab_info()\n        print(f\"  Vocab size: {len(vocab.labels)}\")\n        \n        # Step 2: Create tokenizer\n        print(\"\\nStep 2: Creating tokenizer...\")\n        tokenizer = create_tokenizer_from_labels(\n            tuple(vocab.labels),\n            blank_token=vocab.blank_token,\n            unk_token=vocab.unk_token,\n        )\n        text_tokenized = tokenizer.encode(text_normalized)\n        print(f\"  Tokenized: {len(text_tokenized)} words\")\n        \n        # Step 3: Build WFST\n        print(\"\\nStep 3: Building WFST decoding graph...\")\n        decoding_graph, word_index_sym_tab, token_sym_tab = \\\n            make_factor_transducer_word_level_index_with_skip(\n                text_tokenized,\n                blank_penalty=0,\n                skip_penalty=-0.5,\n                return_penalty=-18.0,\n            )\n        decoding_graph = decoding_graph.to(device)\n        print(f\"  Nodes: {decoding_graph.shape[0]}, Arcs: {decoding_graph.num_arcs}\")\n        \n        # Step 4: Align segments (following Tutorial.py pattern)\n        print(\"\\nStep 4: Aligning segments...\")\n        batch_size = 32 if device.type == \"cuda\" else 4\n        frame_duration = 0.02\n        \n        waveforms_batched, lengths = segmentation.get_waveforms_batched()\n        offsets = segmentation.get_offsets_in_frames(frame_duration)\n        \n        alignment_results = []\n        \n        for i in tqdm(range(0, segmentation.num_segments, batch_size)):\n            batch_waveforms = waveforms_batched[i:i+batch_size].to(device)\n            batch_lengths = lengths[i:i+batch_size].to(device)\n            batch_offsets = offsets[i:i+batch_size]\n            \n            with torch.inference_mode():\n                emissions, emission_lengths = model.get_emissions(batch_waveforms, batch_lengths)\n            \n            # Use align_segments (following Tutorial.py pattern)\n            batch_results = align_segments(\n                emissions,\n                decoding_graph,\n                emission_lengths,\n            )\n            \n            # Add frame offsets and word indices (following Tutorial.py)\n            for aligned_tokens, offset in zip(batch_results, batch_offsets):\n                offset_val = offset.item()\n                for token in aligned_tokens:\n                    token.timestamp += offset_val  # Absolute frame timestamp\n                    if token.token_id == tokenizer.blk_id:\n                        continue\n                    if token.token_id in word_index_sym_tab:\n                        token.attr[\"wid\"] = word_index_sym_tab[token.token_id]\n                    if token.token_id in token_sym_tab:\n                        token.attr[\"tk\"] = token_sym_tab[token.token_id]\n            \n            alignment_results.extend(batch_results)\n            \n            # Break early for CPU demo\n            if device.type == \"cpu\" and i >= 8:\n                print(\"  (CPU mode: stopping after 8 batches for demo)\")\n                break\n        \n        print(f\"  Aligned {len(alignment_results)} segments\")\n        \n        # Step 5: Concatenate alignments (following Tutorial.py pattern)\n        print(\"\\nStep 5: Concatenating alignments...\")\n        stitched_tokens = concat_alignments(alignment_results)\n        print(f\"  Stitched tokens: {len(stitched_tokens)}\")\n        \n        # Step 6: Get final word alignment (following Tutorial.py pattern)\n        print(\"\\nStep 6: Building word alignment...\")\n        word_alignment = get_final_word_alignment(stitched_tokens, text_words)\n        print(f\"  Aligned words: {len(word_alignment)}\")\n        \n        # Find unaligned regions\n        aligned_indices = set(word_alignment.keys())\n        if aligned_indices:\n            rg_min, rg_max = min(aligned_indices), max(aligned_indices)\n            unaligned_indices = find_unaligned_regions(rg_min, rg_max, aligned_indices)\n            print(f\"  Unaligned regions: {len(unaligned_indices)}\")\n        else:\n            unaligned_indices = []\n        \n        test_results[\"Test 4\"] = \"PASSED\"\n        print(\"\\nTest 4 PASSED\")\n        \n    except Exception as e:\n        test_results[\"Test 4\"] = \"FAILED\"\n        print(f\"Test 4 FAILED: {e}\")\n        import traceback; traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vy47qs9u9wd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 4B: High-Level API (align_long_audio)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    test_results[\"Test 4B\"] = \"SKIPPED\"\n",
    "    print(\"SKIPPED - k2 or lis not available\")\n",
    "else:\n",
    "    try:\n",
    "        from api import align_long_audio, LongFormAlignmentResult\n",
    "        \n",
    "        print(\"\\nUsing high-level API: align_long_audio()\")\n",
    "        print(\"This is the recommended way to use the library.\\n\")\n",
    "        \n",
    "        # Simple one-liner API call\n",
    "        result = align_long_audio(\n",
    "            audio=AUDIO_FILE,\n",
    "            text=PDF_FILE,\n",
    "            language=\"eng\",\n",
    "            verbose=True,\n",
    "        )\n",
    "        \n",
    "        # Use convenience methods on result object\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(\"Result Summary:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(result.summary())\n",
    "        \n",
    "        # Test save methods\n",
    "        print(\"\\nTesting result.save_audacity_labels()...\")\n",
    "        output_path = f\"{examples_path}/meta_earnings_highlevel_labels.txt\"\n",
    "        result.save_audacity_labels(output_path)\n",
    "        print(f\"  Saved to: {output_path}\")\n",
    "        \n",
    "        # Store for later tests\n",
    "        word_alignment_highlevel = result.word_alignments\n",
    "        \n",
    "        test_results[\"Test 4B\"] = \"PASSED\"\n",
    "        print(\"\\nTest 4B PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 4B\"] = \"FAILED\"\n",
    "        print(f\"Test 4B FAILED: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Test 5: Inspect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 5: Inspect Alignment Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 4\" not in test_results or test_results[\"Test 4\"] != \"PASSED\":\n",
    "    test_results[\"Test 5\"] = \"SKIPPED\"\n",
    "    print(\"SKIPPED - Test 4 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\nAligned {len(word_alignment)} out of {len(text_words)} words\")\n",
    "        print(f\"Coverage: {100*len(word_alignment)/len(text_words):.1f}%\")\n",
    "        \n",
    "        # First 10 aligned words\n",
    "        print(\"\\nFirst 10 aligned words:\")\n",
    "        for i, (idx, word) in enumerate(sorted(word_alignment.items())[:10]):\n",
    "            start_sec = word.start_time * frame_duration\n",
    "            end_sec = word.end_time * frame_duration if word.end_time else start_sec + 0.3\n",
    "            print(f\"  [{idx:4d}] {word.word:15s} {start_sec:7.2f}s - {end_sec:7.2f}s\")\n",
    "        \n",
    "        # Last 10 aligned words\n",
    "        print(\"\\nLast 10 aligned words:\")\n",
    "        for i, (idx, word) in enumerate(sorted(word_alignment.items())[-10:]):\n",
    "            start_sec = word.start_time * frame_duration\n",
    "            end_sec = word.end_time * frame_duration if word.end_time else start_sec + 0.3\n",
    "            print(f\"  [{idx:4d}] {word.word:15s} {start_sec:7.2f}s - {end_sec:7.2f}s\")\n",
    "        \n",
    "        # Unaligned regions\n",
    "        if unaligned_indices:\n",
    "            print(f\"\\nUnaligned regions (showing first 5 of {len(unaligned_indices)}):\")\n",
    "            for s, e in unaligned_indices[:5]:\n",
    "                if e - s > 0:\n",
    "                    unaligned_text = \" \".join(text_words[s:e+1][:5])\n",
    "                    if e - s > 5:\n",
    "                        unaligned_text += \"...\"\n",
    "                    print(f\"  [{s}, {e}]: {unaligned_text}\")\n",
    "        \n",
    "        test_results[\"Test 5\"] = \"PASSED\"\n",
    "        print(\"\\nTest 5 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 5\"] = \"FAILED\"\n",
    "        print(f\"Test 5 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Test 6: Audacity Label Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 6: Audacity Label Export\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 4\" not in test_results or test_results[\"Test 4\"] != \"PASSED\":\n",
    "    test_results[\"Test 6\"] = \"SKIPPED\"\n",
    "    print(\"SKIPPED - Test 4 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        labels = get_audacity_labels(word_alignment, frame_duration=0.02)\n",
    "        \n",
    "        print(\"\\nAudacity labels (first 10 lines):\")\n",
    "        for line in labels.split(\"\\n\")[:10]:\n",
    "            print(f\"  {line}\")\n",
    "        \n",
    "        # Save to file\n",
    "        output_path = f\"{examples_path}/meta_earnings_labels.txt\"\n",
    "        save_audacity_labels(word_alignment, output_path, frame_duration=0.02)\n",
    "        print(f\"\\nSaved to: {output_path}\")\n",
    "        print(\"\\nTo use in Audacity:\")\n",
    "        print(\"  1. Open the audio file in Audacity\")\n",
    "        print(\"  2. File > Import > Labels\")\n",
    "        print(f\"  3. Select {output_path}\")\n",
    "        \n",
    "        test_results[\"Test 6\"] = \"PASSED\"\n",
    "        print(\"\\nTest 6 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 6\"] = \"FAILED\"\n",
    "        print(f\"Test 6 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Test 7: Gentle HTML Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 7: Gentle HTML Visualization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 4\" not in test_results or test_results[\"Test 4\"] != \"PASSED\":\n",
    "    test_results[\"Test 7\"] = \"SKIPPED\"\n",
    "    print(\"SKIPPED - Test 4 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        # Save HTML\n",
    "        html_path = f\"{examples_path}/meta_earnings_visualization.html\"\n",
    "        save_gentle_html(\n",
    "            word_alignment,\n",
    "            text_normalized,\n",
    "            html_path,\n",
    "            audio_file=AUDIO_FILE,\n",
    "            frame_duration=0.02,\n",
    "            title=\"Meta Q1 2025 Earnings Call - Alignment Visualization\",\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nSaved to: {html_path}\")\n",
    "        print(\"\\nTo view:\")\n",
    "        print(\"  1. Download the HTML file\")\n",
    "        print(\"  2. Open in a web browser\")\n",
    "        print(\"  3. Click on words to play audio\")\n",
    "        \n",
    "        # Show preview in notebook\n",
    "        from IPython.display import HTML, display\n",
    "        preview_html = get_gentle_visualization(\n",
    "            word_alignment,\n",
    "            text_normalized,\n",
    "            frame_duration=0.02,\n",
    "            i_word_end=200,  # Just first 200 words for preview\n",
    "        )\n",
    "        print(\"\\nPreview (first 200 words):\")\n",
    "        display(HTML(preview_html))\n",
    "        \n",
    "        test_results[\"Test 7\"] = \"PASSED\"\n",
    "        print(\"\\nTest 7 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 7\"] = \"FAILED\"\n",
    "        print(f\"Test 7 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Test 8: Random Segment Listening Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 8: Random Segment Listening Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 4\" not in test_results or test_results[\"Test 4\"] != \"PASSED\":\n",
    "    test_results[\"Test 8\"] = \"SKIPPED\"\n",
    "    print(\"SKIPPED - Test 4 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        from IPython.display import display, Audio\n",
    "        import random\n",
    "        \n",
    "        print(\"\\nPlaying 3 random segments (50 words each):\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i in range(3):\n",
    "            audio_widget, words, start_idx = preview_random_segment(\n",
    "                waveform.squeeze(0),\n",
    "                word_alignment,\n",
    "                num_words=50,\n",
    "                sample_rate=sr,\n",
    "                frame_duration=0.02,\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nSegment {i+1} (starting at position {start_idx}):\")\n",
    "            if audio_widget:\n",
    "                display(audio_widget)\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        test_results[\"Test 8\"] = \"PASSED\"\n",
    "        print(\"\\nTest 8 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 8\"] = \"FAILED\"\n",
    "        print(f\"Test 8 FAILED: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Test 9: Word-by-Word Listening Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 9: Word-by-Word Listening Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 4\" not in test_results or test_results[\"Test 4\"] != \"PASSED\":\n",
    "    test_results[\"Test 9\"] = \"SKIPPED\"\n",
    "    print(\"SKIPPED - Test 4 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        from IPython.display import display, Audio\n",
    "        \n",
    "        # Pick a random starting point\n",
    "        import random\n",
    "        sorted_items = sorted(word_alignment.items())\n",
    "        start = random.randint(0, max(0, len(sorted_items) - 20))\n",
    "        \n",
    "        print(f\"\\nPlaying words {start} to {start+10}:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, (word_idx, word) in enumerate(sorted_items[start:start+10]):\n",
    "            start_sec = word.start_time * 0.02\n",
    "            end_sec = word.end_time * 0.02 if word.end_time else start_sec + 0.3\n",
    "            \n",
    "            print(f\"\\n[{word_idx}] '{word.word}' ({start_sec:.2f}s - {end_sec:.2f}s):\")\n",
    "            \n",
    "            audio_widget = preview_word(\n",
    "                waveform.squeeze(0),\n",
    "                word_alignment,\n",
    "                word_idx,\n",
    "                sample_rate=sr,\n",
    "                frame_duration=0.02,\n",
    "            )\n",
    "            if audio_widget:\n",
    "                display(audio_widget)\n",
    "        \n",
    "        test_results[\"Test 9\"] = \"PASSED\"\n",
    "        print(\"\\nTest 9 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 9\"] = \"FAILED\"\n",
    "        print(f\"Test 9 FAILED: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print()\n",
    "for test_name, result in sorted(test_results.items(), key=lambda x: int(x[0].split()[1])):\n",
    "    status = \"PASSED\" if result == \"PASSED\" else (\"SKIPPED\" if result == \"SKIPPED\" else \"FAILED\")\n",
    "    icon = \"[PASS]\" if status == \"PASSED\" else (\"[SKIP]\" if status == \"SKIPPED\" else \"[FAIL]\")\n",
    "    print(f\"  {icon}  {test_name}\")\n",
    "\n",
    "passed = sum(1 for r in test_results.values() if r == \"PASSED\")\n",
    "failed = sum(1 for r in test_results.values() if r == \"FAILED\")\n",
    "skipped = sum(1 for r in test_results.values() if r == \"SKIPPED\")\n",
    "\n",
    "print()\n",
    "print(f\"  Passed:  {passed}\")\n",
    "print(f\"  Skipped: {skipped}\")\n",
    "print(f\"  Failed:  {failed}\")\n",
    "print()\n",
    "\n",
    "if failed == 0:\n",
    "    print(\"All tests passed (or skipped due to missing dependencies)!\")\n",
    "else:\n",
    "    print(f\"{failed} test(s) failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Interactive: Explore Alignment\n",
    "\n",
    "Use the cells below to interactively explore the alignment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a specific segment by position\n",
    "# Change the start_idx to explore different parts\n",
    "\n",
    "if \"Test 4\" in test_results and test_results[\"Test 4\"] == \"PASSED\":\n",
    "    from IPython.display import display\n",
    "    \n",
    "    start_idx = 100  # Change this to explore different parts\n",
    "    num_words = 30\n",
    "    \n",
    "    audio, words = preview_segment(\n",
    "        waveform.squeeze(0),\n",
    "        word_alignment,\n",
    "        start_idx,\n",
    "        num_words,\n",
    "        sample_rate=sr,\n",
    "        frame_duration=0.02,\n",
    "    )\n",
    "    \n",
    "    if audio:\n",
    "        display(audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}