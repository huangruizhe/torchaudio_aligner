{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook: Alignment Module\n",
    "\n",
    "This notebook tests the `alignment` module for speech-to-text alignment.\n",
    "\n",
    "**Features tested:**\n",
    "1. Module imports and structure\n",
    "2. Data classes (AlignmentResult, AlignedWord, AlignedToken)\n",
    "3. WFST factor transducer construction\n",
    "4. Tokenizers (Character, BPE, Phoneme) - via unified `text_frontend`\n",
    "5. Audio segmentation - via unified `audio_frontend`\n",
    "6. LIS (Longest Increasing Subsequence) utilities\n",
    "7. MFA backend availability\n",
    "8. Gentle backend availability\n",
    "9. Full WFST Aligner integration\n",
    "10. **Segment-wise alignment API** (for use with stitching_utils)\n",
    "11. **Ground truth data** loading\n",
    "12. **Run WFST alignment** on sample audio\n",
    "13. **Accuracy comparison** (frame error, IoU metrics)\n",
    "14. **Listening test** (audio preview of aligned words)\n",
    "15. **MFA aligner test** (if installed)\n",
    "16. **Gentle aligner test** (if installed)\n",
    "\n",
    "**Architecture:**\n",
    "The alignment module produces **SEGMENT-WISE** results (each segment aligned independently).\n",
    "For global alignment, use `stitching_utils` to combine segments.\n",
    "\n",
    "**Alignment Backends:**\n",
    "| Backend | Description | Fuzzy Support | Languages |\n",
    "|---------|-------------|---------------|-----------|\n",
    "| `WFSTAligner` | k2-based factor transducer | ‚úÖ Yes | 1100+ (MMS) |\n",
    "| `MFAAligner` | Montreal Forced Aligner | ‚ùå No | 50+ |\n",
    "| `GentleAligner` | Kaldi-based (English) | ‚ùå No | English only |\n",
    "\n",
    "**Key methods:**\n",
    "- `aligner.align_segments(waveform, text)` ‚Üí `List[SegmentAlignmentResult]` (no stitching)\n",
    "- `aligner.align(waveform, text, stitch=True)` ‚Üí `AlignmentResult` (with optional stitching)\n",
    "\n",
    "**Accuracy Testing:**\n",
    "- Ground truth from MMS-FA CTC alignment (50fps frame rate)\n",
    "- Metrics: Frame error (start/end), IoU (boundary overlap)\n",
    "- Audio preview: `preview_word(idx)`, `preview_word_by_name(\"CURIOSITY\")`, `preview_all_words()`\n",
    "\n",
    "**Installation (Colab):**\n",
    "```bash\n",
    "# GPU Version\n",
    "pip install k2==1.24.4.dev20251030+cuda12.6.torch2.9.0 -f https://k2-fsa.github.io/k2/cuda.html\n",
    "\n",
    "# CPU Version (use --no-deps to avoid env changes)\n",
    "pip install k2==1.24.4.dev20251029+cpu.torch2.9.0 --no-deps -f https://k2-fsa.github.io/k2/cpu.html\n",
    "\n",
    "# Common dependencies\n",
    "pip install pytorch-lightning cmudict g2p_en pydub\n",
    "pip install git+https://github.com/huangruizhe/lis.git\n",
    "\n",
    "# Optional: MFA\n",
    "pip install montreal-forced-aligner\n",
    "\n",
    "# Optional: Gentle\n",
    "pip install gentle  # or docker run -p 8765:8765 lowerquality/gentle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/torchaudio_aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Install Dependencies (run once)\n",
    "# =============================================================================\n",
    "# Uncomment and run the appropriate section for your environment\n",
    "\n",
    "# ===== GPU Version (Colab with GPU) =====\n",
    "# !pip install k2==1.24.4.dev20251030+cuda12.6.torch2.9.0 -f https://k2-fsa.github.io/k2/cuda.html\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install cmudict g2p_en\n",
    "# !pip install pydub\n",
    "# !pip install git+https://github.com/huangruizhe/lis.git\n",
    "\n",
    "# ===== CPU Version (Colab CPU or local) =====\n",
    "# Note: --no-deps to avoid changing the Python environment\n",
    "!pip install k2==1.24.4.dev20251029+cpu.torch2.9.0 --no-deps -f https://k2-fsa.github.io/k2/cpu.html\n",
    "!pip install pytorch-lightning\n",
    "!pip install cmudict g2p_en\n",
    "!pip install pydub\n",
    "!pip install git+https://github.com/huangruizhe/lis.git\n",
    "!pip install torchcodec\n",
    "\n",
    "# ===== Optional: MFA (Montreal Forced Aligner) =====\n",
    "# !pip install montreal-forced-aligner\n",
    "# # Or via conda: conda install -c conda-forge montreal-forced-aligner\n",
    "\n",
    "# ===== Optional: Gentle Aligner =====\n",
    "# !pip install gentle\n",
    "# # Or via Docker: docker run -p 8765:8765 lowerquality/gentle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Setup: Configure Imports\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "GITHUB_REPO = \"https://github.com/huangruizhe/torchaudio_aligner.git\"\n",
    "BRANCH = \"dev\"  # Use 'dev' for testing, 'main' for stable\n",
    "# =========================\n",
    "\n",
    "# Test result tracking\n",
    "test_results = {}\n",
    "\n",
    "def setup_imports():\n",
    "    \"\"\"Setup Python path for imports based on environment.\"\"\"\n",
    "    \n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        repo_path = '/content/torchaudio_aligner'\n",
    "        src_path = f'{repo_path}/src'\n",
    "        \n",
    "        if not os.path.exists(repo_path):\n",
    "            print(f\"Cloning repository (branch: {BRANCH})...\")\n",
    "            os.system(f'git clone -b {BRANCH} {GITHUB_REPO} {repo_path}')\n",
    "            print(\"Repository cloned\")\n",
    "        else:\n",
    "            print(f\"Updating repository (branch: {BRANCH})...\")\n",
    "            os.system(f'cd {repo_path} && git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}')\n",
    "            print(\"Repository updated\")\n",
    "    else:\n",
    "        possible_paths = [\n",
    "            Path(\".\").absolute().parent / \"src\",\n",
    "            Path(\".\").absolute() / \"src\",\n",
    "        ]\n",
    "        \n",
    "        src_path = None\n",
    "        for p in possible_paths:\n",
    "            if p.exists() and (p / \"alignment\").exists():\n",
    "                src_path = str(p.absolute())\n",
    "                break\n",
    "        \n",
    "        if src_path is None:\n",
    "            raise FileNotFoundError(\"src directory not found\")\n",
    "        \n",
    "        print(f\"Running locally from: {src_path}\")\n",
    "    \n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "    \n",
    "    return src_path\n",
    "\n",
    "src_path = setup_imports()\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Check dependencies\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Checking dependencies...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check k2\n",
    "try:\n",
    "    import k2\n",
    "    print(f\"‚úÖ k2 version:\")\n",
    "    ! pip show k2\n",
    "    K2_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è k2 not available - WFST tests will be limited\")\n",
    "    print(\"   Install with: pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\")\n",
    "    K2_AVAILABLE = False\n",
    "\n",
    "# Check lis\n",
    "try:\n",
    "    import lis\n",
    "    print(\"‚úÖ lis library available\")\n",
    "    LIS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è lis not available - LIS tests will be skipped\")\n",
    "    print(\"   Install with: pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "    LIS_AVAILABLE = False\n",
    "\n",
    "print(f\"   Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Module Imports and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 1: Module Imports and Structure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import (\n",
    "        # Data classes\n",
    "        AlignmentResult,\n",
    "        AlignedWord,\n",
    "        AlignedToken,\n",
    "        AlignmentConfig,\n",
    "        # Base class\n",
    "        AlignerBackend,\n",
    "        # Backends\n",
    "        WFSTAligner,\n",
    "        MFAAligner,\n",
    "        GentleAligner,\n",
    "        # API functions\n",
    "        align,\n",
    "        align_long_audio,\n",
    "        get_aligner,\n",
    "        list_backends,\n",
    "    )\n",
    "    \n",
    "    print(\"üì¶ Imports successful!\")\n",
    "    \n",
    "    # List available backends\n",
    "    backends = list_backends()\n",
    "    print(\"\\nüîß Available backends:\")\n",
    "    for name, info in backends.items():\n",
    "        status = \"üöß\" if info.get(\"status\") == \"placeholder\" else \"‚úÖ\"\n",
    "        print(f\"   {status} {name}: {info['description']}\")\n",
    "        print(f\"      Languages: {info['languages']}\")\n",
    "        print(f\"      Fuzzy alignment: {info['fuzzy']}\")\n",
    "    \n",
    "    test_results[\"Test 1\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 1 PASSED - Module imports successful\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 1\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 1 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 2: Data Classes (AlignmentConfig, AlignedWord, AlignmentResult)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Test AlignmentConfig\n",
    "    print(\"\\nüìã AlignmentConfig:\")\n",
    "    config = AlignmentConfig(\n",
    "        backend=\"wfst\",\n",
    "        language=\"eng\",\n",
    "        segment_size=15.0,\n",
    "        overlap=2.0,\n",
    "        skip_penalty=-0.5,\n",
    "        return_penalty=-18.0,\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Backend: {config.backend}\")\n",
    "    print(f\"   ‚Ä¢ Device: {config.device}\")\n",
    "    print(f\"   ‚Ä¢ Segment size: {config.segment_size}s\")\n",
    "    print(f\"   ‚Ä¢ Skip penalty: {config.skip_penalty}\")\n",
    "    print(f\"   ‚Ä¢ Return penalty: {config.return_penalty}\")\n",
    "    \n",
    "    # Test AlignedWord\n",
    "    print(\"\\nüìù AlignedWord:\")\n",
    "    word = AlignedWord(\n",
    "        word=\"hello\",\n",
    "        start_time=100,\n",
    "        end_time=150,\n",
    "        phones=[\n",
    "            AlignedToken(token_id=\"h\", timestamp=100, score=0.9),\n",
    "            AlignedToken(token_id=\"e\", timestamp=110, score=0.85),\n",
    "            AlignedToken(token_id=\"l\", timestamp=120, score=0.88),\n",
    "            AlignedToken(token_id=\"l\", timestamp=130, score=0.92),\n",
    "            AlignedToken(token_id=\"o\", timestamp=140, score=0.87),\n",
    "        ],\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Word: '{word.word}'\")\n",
    "    print(f\"   ‚Ä¢ Start: {word.start_seconds:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ End: {word.end_seconds:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Duration: {word.duration:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Phones: {[p.token_id for p in word.phones]}\")\n",
    "    \n",
    "    # Test AlignmentResult\n",
    "    print(\"\\nüìä AlignmentResult:\")\n",
    "    result = AlignmentResult(\n",
    "        word_alignments={\n",
    "            0: AlignedWord(\"hello\", 100, 150),\n",
    "            1: AlignedWord(\"world\", 160, 220),\n",
    "        },\n",
    "        unaligned_indices=[(2, 3)],\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n",
    "    print(f\"   ‚Ä¢ Aligned text: '{result.aligned_text}'\")\n",
    "    print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n",
    "    \n",
    "    # Test Audacity export\n",
    "    labels = result.to_audacity_labels()\n",
    "    print(f\"\\nüè∑Ô∏è Audacity labels format:\")\n",
    "    for line in labels.split('\\n'):\n",
    "        print(f\"   {line}\")\n",
    "    \n",
    "    test_results[\"Test 2\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 2 PASSED - Data classes work correctly\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 2\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 2 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: WFST Factor Transducer Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 3: WFST Factor Transducer Construction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE:\n",
    "    test_results[\"Test 3\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 3 SKIPPED - k2 not available\")\n",
    "    print(\"   Install with: pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment.wfst import (\n",
    "            make_factor_transducer_word_level_index_with_skip,\n",
    "            flatten_list,\n",
    "        )\n",
    "        \n",
    "        # Simulated tokenized text: [[h,e,l,l,o], [w,o,r,l,d]]\n",
    "        # Using fake token IDs\n",
    "        tokenized_text = [\n",
    "            [7, 4, 11, 11, 14],   # hello\n",
    "            [22, 14, 17, 11, 3],  # world\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nüìù Tokenized text: {tokenized_text}\")\n",
    "        print(f\"   Flattened: {flatten_list(tokenized_text)}\")\n",
    "        \n",
    "        # Build factor transducer\n",
    "        graph, word_sym, token_sym = make_factor_transducer_word_level_index_with_skip(\n",
    "            tokenized_text,\n",
    "            skip_penalty=-0.5,\n",
    "            return_penalty=-18.0,\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüîß Factor Transducer:\")\n",
    "        print(f\"   ‚Ä¢ States: {graph.shape[0]}\")\n",
    "        print(f\"   ‚Ä¢ Arcs: {graph.num_arcs}\")\n",
    "        print(f\"   ‚Ä¢ Skip ID: {graph.skip_id}\")\n",
    "        print(f\"   ‚Ä¢ Return ID: {graph.return_id}\")\n",
    "        \n",
    "        print(f\"\\nüìñ Symbol tables:\")\n",
    "        print(f\"   ‚Ä¢ Word index table: {word_sym}\")\n",
    "        print(f\"   ‚Ä¢ Token table (first 5): {dict(list(token_sym.items())[:5])}...\")\n",
    "        \n",
    "        test_results[\"Test 3\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 3 PASSED - Factor transducer construction works\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 3\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 3 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 4: Tokenizers (via text_frontend)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Import from unified text_frontend\n",
    "    from text_frontend import (\n",
    "        TokenizerInterface,\n",
    "        CharTokenizer,\n",
    "        create_tokenizer_from_labels,\n",
    "    )\n",
    "    \n",
    "    # Create tokenizer with MMS-FA style labels\n",
    "    labels = ('-', 'a', 'i', 'e', 'n', 'o', 'u', 't', 's', 'r', 'm', 'k', 'l', 'd', \n",
    "              'g', 'h', 'y', 'b', 'p', 'w', 'c', 'v', 'j', 'z', 'f', \"'\", 'q', 'x', '*')\n",
    "    \n",
    "    tokenizer = create_tokenizer_from_labels(labels, blank_token='-', unk_token='*')\n",
    "    \n",
    "    print(f\"\\nüî§ CharTokenizer (MMS-FA style):\")\n",
    "    print(f\"   ‚Ä¢ Vocab size: {len(tokenizer.token2id)}\")\n",
    "    print(f\"   ‚Ä¢ Blank ID: {tokenizer.blk_id}\")\n",
    "    print(f\"   ‚Ä¢ UNK ID: {tokenizer.unk_id}\")\n",
    "    print(f\"   ‚Ä¢ Implements TokenizerInterface: {isinstance(tokenizer, TokenizerInterface)}\")\n",
    "    \n",
    "    # Test encoding\n",
    "    text = \"hello world\"\n",
    "    normalized = tokenizer.text_normalize(text)\n",
    "    encoded = tokenizer.encode(normalized)\n",
    "    decoded = tokenizer.decode(encoded)\n",
    "    \n",
    "    print(f\"\\nüìù Encoding test:\")\n",
    "    print(f\"   ‚Ä¢ Original: '{text}'\")\n",
    "    print(f\"   ‚Ä¢ Normalized: '{normalized}'\")\n",
    "    print(f\"   ‚Ä¢ Encoded: {encoded}\")\n",
    "    print(f\"   ‚Ä¢ Decoded: {decoded}\")\n",
    "    \n",
    "    # Test flatten\n",
    "    flattened = tokenizer.encode_flatten(normalized)\n",
    "    print(f\"   ‚Ä¢ Flattened: {flattened}\")\n",
    "    \n",
    "    # Test with OOV characters\n",
    "    text_oov = \"hello ‰Ω†Â•Ω world\"\n",
    "    normalized_oov = tokenizer.text_normalize(text_oov)\n",
    "    encoded_oov = tokenizer.encode(normalized_oov)\n",
    "    \n",
    "    print(f\"\\nüåê OOV handling:\")\n",
    "    print(f\"   ‚Ä¢ Original: '{text_oov}'\")\n",
    "    print(f\"   ‚Ä¢ Normalized: '{normalized_oov}'\")\n",
    "    print(f\"   ‚Ä¢ Encoded: {encoded_oov}\")\n",
    "    \n",
    "    test_results[\"Test 4\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 4 PASSED - Tokenizers work correctly\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 4\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 4 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Audio Segmentation (via audio_frontend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 5: Audio Segmentation (via audio_frontend)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Import from unified audio_frontend\n",
    "    from audio_frontend import (\n",
    "        segment_waveform,\n",
    "        AudioSegment,\n",
    "        SegmentationResult,\n",
    "    )\n",
    "    \n",
    "    # Create test waveform: 30 seconds at 16kHz\n",
    "    waveform = torch.randn(480000)  # (T,) - 1D\n",
    "    sample_rate = 16000\n",
    "    \n",
    "    print(f\"\\nüéµ Input waveform:\")\n",
    "    print(f\"   ‚Ä¢ Shape: {waveform.shape}\")\n",
    "    print(f\"   ‚Ä¢ Duration: {waveform.shape[0] / sample_rate:.2f}s\")\n",
    "    \n",
    "    # Segment with overlap using audio_frontend\n",
    "    result = segment_waveform(\n",
    "        waveform,\n",
    "        sample_rate=sample_rate,\n",
    "        segment_size=15.0,    # 15 seconds\n",
    "        overlap=2.0,          # 2 seconds overlap\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÇÔ∏è Segmentation result (SegmentationResult):\")\n",
    "    print(f\"   ‚Ä¢ Num segments: {result.num_segments}\")\n",
    "    print(f\"   ‚Ä¢ Segment size: {result.segment_size_samples} samples ({result.segment_size_samples/sample_rate:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Overlap: {result.overlap_samples} samples ({result.overlap_samples/sample_rate:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Original duration: {result.original_duration_seconds:.2f}s\")\n",
    "    \n",
    "    # Get batched tensors\n",
    "    segments, lengths = result.get_waveforms_batched()\n",
    "    offsets = torch.tensor([seg.offset_samples for seg in result.segments])\n",
    "    \n",
    "    print(f\"\\nüì¶ Batched tensors:\")\n",
    "    print(f\"   ‚Ä¢ Segments shape: {segments.shape}\")\n",
    "    print(f\"   ‚Ä¢ Lengths: {lengths.tolist()}\")\n",
    "    print(f\"   ‚Ä¢ Offsets: {offsets.tolist()}\")\n",
    "    \n",
    "    # Verify AudioSegment objects\n",
    "    print(f\"\\nüîç First segment (AudioSegment):\")\n",
    "    seg0 = result.segments[0]\n",
    "    print(f\"   ‚Ä¢ Waveform shape: {seg0.waveform.shape}\")\n",
    "    print(f\"   ‚Ä¢ Offset: {seg0.offset_samples} samples ({seg0.offset_seconds:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Duration: {seg0.duration_seconds:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Index: {seg0.segment_index}\")\n",
    "    \n",
    "    # Verify overlap\n",
    "    step = result.segment_size_samples - result.overlap_samples\n",
    "    expected_offsets = [i * step for i in range(result.num_segments)]\n",
    "    # Allow for small differences due to extra_samples\n",
    "    offsets_match = all(abs(a - e) < 200 for a, e in zip(offsets.tolist(), expected_offsets))\n",
    "    \n",
    "    print(f\"\\nüìê Overlap verification:\")\n",
    "    print(f\"   ‚Ä¢ Step size: {step} samples ({step/sample_rate:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Offsets approximately match expected: {'‚úÖ' if offsets_match else '‚ùå'}\")\n",
    "    \n",
    "    test_results[\"Test 5\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 5 PASSED - Segmentation works correctly\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 5\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 5 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: LIS Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 6: LIS (Longest Increasing Subsequence) Utilities\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not LIS_AVAILABLE:\n",
    "    test_results[\"Test 6\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 6 SKIPPED - lis library not available\")\n",
    "    print(\"   Install with: pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment.wfst.lis_utils import (\n",
    "            compute_lis,\n",
    "            remove_outliers,\n",
    "            remove_isolated_words,\n",
    "            find_unaligned_regions,\n",
    "        )\n",
    "        \n",
    "        # Test LIS computation\n",
    "        # Simulating word indices from multiple overlapping segments\n",
    "        word_indices = [1, 5, 2, 6, 3, 7, 4, 8, 9, 10, 11, 15, 12, 16, 13]\n",
    "        \n",
    "        print(f\"\\nüìà LIS computation:\")\n",
    "        print(f\"   ‚Ä¢ Input: {word_indices}\")\n",
    "        \n",
    "        lis_result = compute_lis(word_indices)\n",
    "        print(f\"   ‚Ä¢ LIS: {lis_result}\")\n",
    "        print(f\"   ‚Ä¢ LIS length: {len(lis_result)}\")\n",
    "        \n",
    "        # Verify LIS is increasing\n",
    "        is_increasing = all(lis_result[i] < lis_result[i+1] for i in range(len(lis_result)-1))\n",
    "        print(f\"   ‚Ä¢ Is strictly increasing: {'‚úÖ' if is_increasing else '‚ùå'}\")\n",
    "        \n",
    "        # Test outlier removal\n",
    "        print(f\"\\nüîç Outlier removal:\")\n",
    "        with_outliers = [5, 100, 10, 15, 20, 25, 30, 35, 200]\n",
    "        cleaned = remove_outliers(with_outliers, scan_range=3, outlier_threshold=50)\n",
    "        print(f\"   ‚Ä¢ Input: {with_outliers}\")\n",
    "        print(f\"   ‚Ä¢ Cleaned: {cleaned}\")\n",
    "        \n",
    "        # Test unaligned region detection\n",
    "        print(f\"\\nüï≥Ô∏è Unaligned region detection:\")\n",
    "        aligned = set(lis_result)\n",
    "        rg_min, rg_max = min(lis_result), max(lis_result)\n",
    "        unaligned = find_unaligned_regions(rg_min, rg_max, aligned)\n",
    "        print(f\"   ‚Ä¢ Aligned range: [{rg_min}, {rg_max}]\")\n",
    "        print(f\"   ‚Ä¢ Aligned indices: {sorted(aligned)}\")\n",
    "        print(f\"   ‚Ä¢ Unaligned regions: {unaligned}\")\n",
    "        \n",
    "        test_results[\"Test 6\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 6 PASSED - LIS utilities work correctly\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 6\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 6 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7: MFA Backend Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 7: MFA Backend Availability\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import MFAAligner, AlignmentConfig\n",
    "    \n",
    "    config = AlignmentConfig(backend=\"mfa\", language=\"english_us_arpa\")\n",
    "    aligner = MFAAligner(config)\n",
    "    \n",
    "    print(f\"\\nüîß MFA Aligner:\")\n",
    "    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "    print(f\"   ‚Ä¢ Acoustic model: {aligner.acoustic_model}\")\n",
    "    print(f\"   ‚Ä¢ Dictionary: {aligner.dictionary}\")\n",
    "    print(f\"   ‚Ä¢ Supported languages (sample): {aligner.SUPPORTED_LANGUAGES[:5]}...\")\n",
    "    \n",
    "    # Check if MFA is available\n",
    "    mfa_available = aligner._check_mfa_available()\n",
    "    \n",
    "    if mfa_available:\n",
    "        print(f\"\\n‚úÖ MFA CLI is installed and available\")\n",
    "        test_results[\"Test 7\"] = \"‚úÖ PASSED\"\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è MFA CLI not installed (optional)\")\n",
    "        print(f\"   Install with: conda install -c conda-forge montreal-forced-aligner\")\n",
    "        test_results[\"Test 7\"] = \"‚ö†Ô∏è MFA NOT INSTALLED\"\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test 7 PASSED - MFA backend class works\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 7\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 7 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8: Gentle Backend Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 8: Gentle Backend Availability\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import GentleAligner, AlignmentConfig\n",
    "    \n",
    "    config = AlignmentConfig(backend=\"gentle\")\n",
    "    aligner = GentleAligner(config)\n",
    "    \n",
    "    print(f\"\\nüîß Gentle Aligner:\")\n",
    "    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "    print(f\"   ‚Ä¢ Server URL: {aligner.server_url}\")\n",
    "    print(f\"   ‚Ä¢ Supported languages: {aligner.SUPPORTED_LANGUAGES}\")\n",
    "    \n",
    "    # Check availability\n",
    "    python_available = aligner._check_gentle_python()\n",
    "    server_available = aligner._check_gentle_server()\n",
    "    \n",
    "    print(f\"\\nüì° Availability:\")\n",
    "    print(f\"   ‚Ä¢ Python API: {'‚úÖ' if python_available else '‚ùå not installed'}\")\n",
    "    print(f\"   ‚Ä¢ Server (localhost:8765): {'‚úÖ' if server_available else '‚ùå not running'}\")\n",
    "    \n",
    "    if python_available or server_available:\n",
    "        test_results[\"Test 8\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Gentle is available\")\n",
    "    else:\n",
    "        test_results[\"Test 8\"] = \"‚ö†Ô∏è GENTLE NOT INSTALLED\"\n",
    "        print(f\"\\n‚ö†Ô∏è Gentle not available (optional)\")\n",
    "        print(f\"   Install: git clone https://github.com/lowerquality/gentle && cd gentle && ./install.sh\")\n",
    "        print(f\"   Or start server: docker run -p 8765:8765 lowerquality/gentle\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test 8 PASSED - Gentle backend class works\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 8\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 8 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 10: Segment-wise Alignment (for stitching_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 10: Segment-wise Alignment (for stitching_utils)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    missing = []\n",
    "    if not K2_AVAILABLE:\n",
    "        missing.append(\"k2\")\n",
    "    if not LIS_AVAILABLE:\n",
    "        missing.append(\"lis\")\n",
    "    test_results[\"Test 10\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(f\"‚è≠Ô∏è Test 10 SKIPPED - Missing dependencies: {', '.join(missing)}\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment import WFSTAligner, AlignmentConfig, SegmentAlignmentResult\n",
    "        \n",
    "        print(\"\\nüìã SegmentAlignmentResult data class:\")\n",
    "        print(f\"   ‚Ä¢ Available: ‚úÖ\")\n",
    "        \n",
    "        # Test SegmentAlignmentResult\n",
    "        from alignment.base import AlignedToken\n",
    "        test_tokens = [\n",
    "            AlignedToken(1, 10, 0.9, {\"wid\": 0}),\n",
    "            AlignedToken(2, 20, 0.85, {\"wid\": 1}),\n",
    "        ]\n",
    "        seg_result = SegmentAlignmentResult(\n",
    "            tokens=test_tokens,\n",
    "            segment_index=0,\n",
    "            frame_offset=0,\n",
    "            rejected=False,\n",
    "            score=0.95,\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Num tokens: {len(seg_result)}\")\n",
    "        print(f\"   ‚Ä¢ Word indices: {seg_result.get_word_indices()}\")\n",
    "        print(f\"   ‚Ä¢ Rejected: {seg_result.rejected}\")\n",
    "        print(f\"   ‚Ä¢ Score: {seg_result.score:.2f}\")\n",
    "        \n",
    "        # Test WFSTAligner.align_segments method exists\n",
    "        print(f\"\\nüîß WFSTAligner.align_segments method:\")\n",
    "        config = AlignmentConfig(\n",
    "            backend=\"wfst\",\n",
    "            segment_size=15.0,\n",
    "            overlap=2.0,\n",
    "        )\n",
    "        aligner = WFSTAligner(config)\n",
    "        \n",
    "        has_align_segments = hasattr(aligner, 'align_segments')\n",
    "        print(f\"   ‚Ä¢ Method exists: {'‚úÖ' if has_align_segments else '‚ùå'}\")\n",
    "        \n",
    "        if has_align_segments:\n",
    "            import inspect\n",
    "            sig = inspect.signature(aligner.align_segments)\n",
    "            params = list(sig.parameters.keys())\n",
    "            print(f\"   ‚Ä¢ Parameters: {params}\")\n",
    "            print(f\"   ‚Ä¢ Returns: List[SegmentAlignmentResult]\")\n",
    "        \n",
    "        # Test align() with stitch=False option\n",
    "        print(f\"\\nüîß WFSTAligner.align(stitch=False) option:\")\n",
    "        sig = inspect.signature(aligner.align)\n",
    "        params = dict(sig.parameters)\n",
    "        has_stitch_param = 'stitch' in params\n",
    "        print(f\"   ‚Ä¢ 'stitch' parameter exists: {'‚úÖ' if has_stitch_param else '‚ùå'}\")\n",
    "        if has_stitch_param:\n",
    "            default = params['stitch'].default\n",
    "            print(f\"   ‚Ä¢ Default value: {default}\")\n",
    "        \n",
    "        # Show usage example\n",
    "        print(f\"\\nüìù Usage with stitching_utils:\")\n",
    "        print(f\"   # Get segment-wise results\")\n",
    "        print(f\"   segment_results = aligner.align_segments(waveform, text)\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Convert to stitching_utils format\")\n",
    "        print(f\"   from stitching_utils import SegmentAlignment, stitch_alignments\")\n",
    "        print(f\"   stitch_input = [\")\n",
    "        print(f\"       SegmentAlignment(\")\n",
    "        print(f\"           tokens=seg.tokens,\")\n",
    "        print(f\"           segment_index=seg.segment_index,\")\n",
    "        print(f\"           frame_offset=seg.frame_offset,\")\n",
    "        print(f\"           rejected=seg.rejected,\")\n",
    "        print(f\"       )\")\n",
    "        print(f\"       for seg in segment_results\")\n",
    "        print(f\"   ]\")\n",
    "        print(f\"   final = stitch_alignments(stitch_input, method='lis')\")\n",
    "        \n",
    "        test_results[\"Test 10\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 10 PASSED - Segment-wise alignment API ready\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 10\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 10 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 9: WFST Aligner Integration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    missing = []\n",
    "    if not K2_AVAILABLE:\n",
    "        missing.append(\"k2\")\n",
    "    if not LIS_AVAILABLE:\n",
    "        missing.append(\"lis\")\n",
    "    test_results[\"Test 9\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(f\"‚è≠Ô∏è Test 9 SKIPPED - Missing dependencies: {', '.join(missing)}\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment import WFSTAligner, AlignmentConfig\n",
    "        \n",
    "        config = AlignmentConfig(\n",
    "            backend=\"wfst\",\n",
    "            segment_size=15.0,\n",
    "            overlap=2.0,\n",
    "            skip_penalty=-0.5,\n",
    "            return_penalty=-18.0,\n",
    "        )\n",
    "        \n",
    "        aligner = WFSTAligner(config)\n",
    "        \n",
    "        print(f\"\\nüîß WFST Aligner:\")\n",
    "        print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "        print(f\"   ‚Ä¢ Config segment_size: {config.segment_size}s\")\n",
    "        print(f\"   ‚Ä¢ Config skip_penalty: {config.skip_penalty}\")\n",
    "        \n",
    "        print(f\"\\nüìù To use WFST aligner:\")\n",
    "        print(f\"   from labeling_utils import load_model\")\n",
    "        print(f\"   from alignment import align\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   model = load_model('mms-fa')\")\n",
    "        print(f\"   result = align(waveform, text, model_backend=model)\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   for idx, word in result.word_alignments.items():\")\n",
    "        print(f\"       print(f'{{word.word}}: {{word.start_seconds:.2f}}s')\")\n",
    "        \n",
    "        test_results[\"Test 9\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 9 PASSED - WFST Aligner class works\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 9\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 9 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üìã TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display test results\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "for test_name, result in test_results.items():\n",
    "    print(f\"  {result}  {test_name}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Count results\n",
    "passed = sum(1 for r in test_results.values() if \"‚úÖ\" in r)\n",
    "failed = sum(1 for r in test_results.values() if \"‚ùå\" in r)\n",
    "skipped = sum(1 for r in test_results.values() if \"‚è≠Ô∏è\" in r)\n",
    "warning = sum(1 for r in test_results.values() if \"‚ö†Ô∏è\" in r)\n",
    "total = len(test_results)\n",
    "\n",
    "print(f\"\\n  Total: {total} tests\")\n",
    "print(f\"  ‚úÖ Passed:  {passed}\")\n",
    "if warning > 0:\n",
    "    print(f\"  ‚ö†Ô∏è Warning: {warning}\")\n",
    "if skipped > 0:\n",
    "    print(f\"  ‚è≠Ô∏è Skipped: {skipped}\")\n",
    "if failed > 0:\n",
    "    print(f\"  ‚ùå Failed:  {failed}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if failed == 0:\n",
    "    print(\"üéâ All tests passed (or skipped due to optional dependencies)!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {failed} test(s) failed - please check above for details\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüì¶ To enable all tests, install:\")\n",
    "print(\"   pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\")\n",
    "print(\"   pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Architecture note:\")\n",
    "print(\"   The alignment module uses unified frontends:\")\n",
    "print(\"   ‚Ä¢ text_frontend: TokenizerInterface, CharTokenizer, create_tokenizer_from_labels\")\n",
    "print(\"   ‚Ä¢ audio_frontend: segment_waveform, AudioSegment, SegmentationResult\")\n",
    "print(\"   This eliminates duplicate code and provides a consistent API.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 11: Alignment Accuracy Test (with Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 11: Alignment Accuracy Test (with Ground Truth)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if dependencies not available\n",
    "if not K2_AVAILABLE:\n",
    "    test_results[\"Test 11\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 11 SKIPPED - k2 not available\")\n",
    "else:\n",
    "    try:\n",
    "        import torchaudio\n",
    "        from IPython.display import Audio, display\n",
    "        \n",
    "        # =================================================================\n",
    "        # Ground Truth Data (from MMS-FA CTC alignment)\n",
    "        # =================================================================\n",
    "        # Transcript: \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        # Frame rate: 50fps (20ms per frame)\n",
    "        \n",
    "        GROUND_TRUTH_WORDS = [\n",
    "            {\"word\": \"I\", \"start\": 31, \"end\": 35, \"score\": 0.78},\n",
    "            {\"word\": \"HAD\", \"start\": 37, \"end\": 44, \"score\": 0.84},\n",
    "            {\"word\": \"THAT\", \"start\": 45, \"end\": 53, \"score\": 0.52},\n",
    "            {\"word\": \"CURIOSITY\", \"start\": 56, \"end\": 92, \"score\": 0.89},\n",
    "            {\"word\": \"BESIDE\", \"start\": 95, \"end\": 116, \"score\": 0.94},\n",
    "            {\"word\": \"ME\", \"start\": 118, \"end\": 124, \"score\": 0.67},\n",
    "            {\"word\": \"AT\", \"start\": 126, \"end\": 129, \"score\": 0.66},\n",
    "            {\"word\": \"THIS\", \"start\": 131, \"end\": 139, \"score\": 0.70},\n",
    "            {\"word\": \"MOMENT\", \"start\": 143, \"end\": 157, \"score\": 0.88},\n",
    "        ]\n",
    "        \n",
    "        GROUND_TRUTH_CHARS = [\n",
    "            {\"char\": \"|\", \"start\": 0, \"end\": 31, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 31, \"end\": 35, \"score\": 0.78},\n",
    "            {\"char\": \"|\", \"start\": 35, \"end\": 37, \"score\": 0.80},\n",
    "            {\"char\": \"H\", \"start\": 37, \"end\": 39, \"score\": 1.00},\n",
    "            {\"char\": \"A\", \"start\": 39, \"end\": 41, \"score\": 0.96},\n",
    "            {\"char\": \"D\", \"start\": 41, \"end\": 44, \"score\": 0.65},\n",
    "            {\"char\": \"|\", \"start\": 44, \"end\": 45, \"score\": 1.00},\n",
    "            {\"char\": \"T\", \"start\": 45, \"end\": 47, \"score\": 0.55},\n",
    "            {\"char\": \"H\", \"start\": 47, \"end\": 49, \"score\": 1.00},\n",
    "            {\"char\": \"A\", \"start\": 49, \"end\": 52, \"score\": 0.03},\n",
    "            {\"char\": \"T\", \"start\": 52, \"end\": 53, \"score\": 1.00},\n",
    "            {\"char\": \"|\", \"start\": 53, \"end\": 56, \"score\": 1.00},\n",
    "            {\"char\": \"C\", \"start\": 56, \"end\": 61, \"score\": 0.97},\n",
    "            {\"char\": \"U\", \"start\": 61, \"end\": 63, \"score\": 1.00},\n",
    "            {\"char\": \"R\", \"start\": 63, \"end\": 67, \"score\": 0.75},\n",
    "            {\"char\": \"I\", \"start\": 67, \"end\": 75, \"score\": 0.88},\n",
    "            {\"char\": \"O\", \"start\": 75, \"end\": 79, \"score\": 0.99},\n",
    "            {\"char\": \"S\", \"start\": 79, \"end\": 83, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 83, \"end\": 86, \"score\": 0.89},\n",
    "            {\"char\": \"T\", \"start\": 86, \"end\": 90, \"score\": 0.78},\n",
    "            {\"char\": \"Y\", \"start\": 90, \"end\": 92, \"score\": 0.70},\n",
    "            {\"char\": \"|\", \"start\": 92, \"end\": 95, \"score\": 0.66},\n",
    "            {\"char\": \"B\", \"start\": 95, \"end\": 98, \"score\": 1.00},\n",
    "            {\"char\": \"E\", \"start\": 98, \"end\": 102, \"score\": 1.00},\n",
    "            {\"char\": \"S\", \"start\": 102, \"end\": 109, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 109, \"end\": 111, \"score\": 1.00},\n",
    "            {\"char\": \"D\", \"start\": 111, \"end\": 113, \"score\": 0.93},\n",
    "            {\"char\": \"E\", \"start\": 113, \"end\": 116, \"score\": 0.66},\n",
    "            {\"char\": \"|\", \"start\": 116, \"end\": 118, \"score\": 1.00},\n",
    "            {\"char\": \"M\", \"start\": 118, \"end\": 121, \"score\": 0.67},\n",
    "            {\"char\": \"E\", \"start\": 121, \"end\": 124, \"score\": 0.67},\n",
    "            {\"char\": \"|\", \"start\": 124, \"end\": 126, \"score\": 0.49},\n",
    "            {\"char\": \"A\", \"start\": 126, \"end\": 127, \"score\": 1.00},\n",
    "            {\"char\": \"T\", \"start\": 127, \"end\": 129, \"score\": 0.50},\n",
    "            {\"char\": \"|\", \"start\": 129, \"end\": 131, \"score\": 0.51},\n",
    "            {\"char\": \"T\", \"start\": 131, \"end\": 132, \"score\": 1.00},\n",
    "            {\"char\": \"H\", \"start\": 132, \"end\": 134, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 134, \"end\": 136, \"score\": 0.75},\n",
    "            {\"char\": \"S\", \"start\": 136, \"end\": 139, \"score\": 0.36},\n",
    "            {\"char\": \"|\", \"start\": 139, \"end\": 143, \"score\": 0.50},\n",
    "            {\"char\": \"M\", \"start\": 143, \"end\": 146, \"score\": 1.00},\n",
    "            {\"char\": \"O\", \"start\": 146, \"end\": 149, \"score\": 1.00},\n",
    "            {\"char\": \"M\", \"start\": 149, \"end\": 152, \"score\": 1.00},\n",
    "            {\"char\": \"E\", \"start\": 152, \"end\": 153, \"score\": 1.00},\n",
    "            {\"char\": \"N\", \"start\": 153, \"end\": 155, \"score\": 0.66},\n",
    "            {\"char\": \"T\", \"start\": 155, \"end\": 157, \"score\": 0.51},\n",
    "            {\"char\": \"|\", \"start\": 157, \"end\": 169, \"score\": 0.96},\n",
    "        ]\n",
    "        \n",
    "        # Transcript text\n",
    "        TRANSCRIPT = \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        \n",
    "        # Frame parameters\n",
    "        FRAME_RATE = 50  # frames per second (20ms per frame)\n",
    "        SAMPLE_RATE = 16000\n",
    "        \n",
    "        print(\"\\nüìã Ground Truth Data:\")\n",
    "        print(f\"   ‚Ä¢ Transcript: '{TRANSCRIPT}'\")\n",
    "        print(f\"   ‚Ä¢ Frame rate: {FRAME_RATE} fps (20ms/frame)\")\n",
    "        print(f\"   ‚Ä¢ Words: {len(GROUND_TRUTH_WORDS)}\")\n",
    "        print(f\"   ‚Ä¢ Characters: {len(GROUND_TRUTH_CHARS)}\")\n",
    "        \n",
    "        print(\"\\nüìù Word-level ground truth:\")\n",
    "        for w in GROUND_TRUTH_WORDS:\n",
    "            start_sec = w['start'] / FRAME_RATE\n",
    "            end_sec = w['end'] / FRAME_RATE\n",
    "            print(f\"   {w['word']:12s} ({w['score']:.2f}): [{w['start']:4d}, {w['end']:4d}) = [{start_sec:.2f}s, {end_sec:.2f}s)\")\n",
    "        \n",
    "        test_results[\"Test 11\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 11 PASSED - Ground truth data loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 11\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 11 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 12: Run WFST Alignment on Sample Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 12: Run WFST Alignment on Sample Audio\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if dependencies not available\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    missing = []\n",
    "    if not K2_AVAILABLE:\n",
    "        missing.append(\"k2\")\n",
    "    if not LIS_AVAILABLE:\n",
    "        missing.append(\"lis\")\n",
    "    test_results[\"Test 12\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(f\"‚è≠Ô∏è Test 12 SKIPPED - Missing dependencies: {', '.join(missing)}\")\n",
    "else:\n",
    "    try:\n",
    "        import torchaudio\n",
    "        from alignment import WFSTAligner, AlignmentConfig, SegmentAlignmentResult\n",
    "        \n",
    "        # =================================================================\n",
    "        # Load Sample Audio\n",
    "        # =================================================================\n",
    "        # We need a sample audio file. Try to download or use existing.\n",
    "        \n",
    "        print(\"\\nüéµ Loading sample audio...\")\n",
    "        \n",
    "        # Option 1: Use torchaudio's built-in sample (LibriSpeech)\n",
    "        try:\n",
    "            # Try to load from examples folder first\n",
    "            example_path = \"../examples/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "            waveform, sr = torchaudio.load(example_path)\n",
    "            print(f\"   ‚Ä¢ Loaded from: {example_path}\")\n",
    "        except:\n",
    "            # Download LibriSpeech sample\n",
    "            SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "            print(f\"   ‚Ä¢ Downloading sample audio...\")\n",
    "            waveform, sr = torchaudio.load(SPEECH_URL)\n",
    "            print(f\"   ‚Ä¢ Downloaded from PyTorch assets\")\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "            sr = 16000\n",
    "        \n",
    "        # Use only first channel if stereo\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform[0:1]\n",
    "        \n",
    "        duration_sec = waveform.size(1) / sr\n",
    "        print(f\"   ‚Ä¢ Sample rate: {sr}\")\n",
    "        print(f\"   ‚Ä¢ Shape: {waveform.shape}\")\n",
    "        print(f\"   ‚Ä¢ Duration: {duration_sec:.2f}s\")\n",
    "        \n",
    "        # The transcript for this sample\n",
    "        # Note: This is a short sample, so we're using a short transcript\n",
    "        # that matches approximately (you may need to adjust based on actual content)\n",
    "        \n",
    "        # For this VOiCES sample, the transcript is:\n",
    "        # \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        \n",
    "        print(f\"\\nüìù Transcript: '{TRANSCRIPT}'\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # Load MMS-FA Model\n",
    "        # =================================================================\n",
    "        print(\"\\nüîß Loading MMS-FA model...\")\n",
    "        \n",
    "        try:\n",
    "            from labeling_utils import load_model\n",
    "            model = load_model(\"mms-fa\")\n",
    "            print(\"   ‚Ä¢ Model loaded: mms-fa\")\n",
    "        except ImportError:\n",
    "            print(\"   ‚ö†Ô∏è labeling_utils not available\")\n",
    "            print(\"   Trying torchaudio bundle directly...\")\n",
    "            \n",
    "            # Fallback: use torchaudio bundle directly\n",
    "            bundle = torchaudio.pipelines.MMS_FA\n",
    "            model = bundle.get_model()\n",
    "            model = model.to(\"cpu\")\n",
    "            \n",
    "            # Create a mock model backend\n",
    "            class MockModelBackend:\n",
    "                def __init__(self, model, bundle):\n",
    "                    self._model = model\n",
    "                    self._bundle = bundle\n",
    "                    \n",
    "                def get_emissions(self, waveforms, lengths):\n",
    "                    with torch.inference_mode():\n",
    "                        emissions, emission_lengths = self._model(waveforms.squeeze(-1))\n",
    "                    return emissions, emission_lengths\n",
    "                \n",
    "                def get_vocab_info(self):\n",
    "                    class VocabInfo:\n",
    "                        labels = tuple(bundle.get_labels())\n",
    "                        blank_token = '-'\n",
    "                        unk_token = '*'\n",
    "                        blank_id = labels.index(blank_token) if blank_token in labels else 0\n",
    "                        unk_id = labels.index(unk_token) if unk_token in labels else None\n",
    "                    return VocabInfo()\n",
    "            \n",
    "            model = MockModelBackend(model, bundle)\n",
    "            print(\"   ‚Ä¢ Model loaded: torchaudio MMS_FA bundle\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # Run WFST Alignment\n",
    "        # =================================================================\n",
    "        print(\"\\nüîß Running WFST alignment...\")\n",
    "        \n",
    "        config = AlignmentConfig(\n",
    "            backend=\"wfst\",\n",
    "            segment_size=15.0,  # Short segment for this test\n",
    "            overlap=2.0,\n",
    "            skip_penalty=-0.5,\n",
    "            return_penalty=-18.0,\n",
    "        )\n",
    "        \n",
    "        aligner = WFSTAligner(config)\n",
    "        aligner.set_model(model)\n",
    "        \n",
    "        # Run alignment\n",
    "        result = aligner.align(waveform.squeeze(0), TRANSCRIPT)\n",
    "        \n",
    "        print(f\"\\nüìä Alignment Results:\")\n",
    "        print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n",
    "        print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n",
    "        \n",
    "        # Store for comparison\n",
    "        aligned_words = result.word_alignments\n",
    "        \n",
    "        print(f\"\\nüìù Word-level alignment results:\")\n",
    "        for idx, word in sorted(aligned_words.items()):\n",
    "            start_frame = int(word.start_time)\n",
    "            end_frame = int(word.end_time) if word.end_time else start_frame + 10\n",
    "            start_sec = start_frame / FRAME_RATE\n",
    "            end_sec = end_frame / FRAME_RATE if word.end_time else \"?\"\n",
    "            print(f\"   [{idx:2d}] {str(word.word):12s}: frame [{start_frame:4f}, {end_frame:4f}) = [{start_sec:.2f}s, {end_sec}s)\")\n",
    "        \n",
    "        test_results[\"Test 12\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 12 PASSED - WFST alignment completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 12\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 12 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-test13-md",
   "metadata": {},
   "source": [
    "## Test 13: Alignment Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 13: Alignment Accuracy Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if Test 12 didn't run\n",
    "if \"Test 12\" not in test_results or \"PASSED\" not in test_results.get(\"Test 12\", \"\"):\n",
    "    test_results[\"Test 13\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 13 SKIPPED - Test 12 (alignment) did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"\\nüìä Comparing alignment results to ground truth...\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # Compute Accuracy Metrics\n",
    "        # =================================================================\n",
    "        \n",
    "        def compute_frame_error(pred_start, pred_end, gt_start, gt_end):\n",
    "            \"\"\"Compute frame-level error between prediction and ground truth.\"\"\"\n",
    "            start_error = abs(pred_start - gt_start)\n",
    "            end_error = abs(pred_end - gt_end) if pred_end and gt_end else 0\n",
    "            return start_error, end_error\n",
    "        \n",
    "        def compute_iou(pred_start, pred_end, gt_start, gt_end):\n",
    "            \"\"\"Compute Intersection over Union for alignment boundaries.\"\"\"\n",
    "            if pred_end is None:\n",
    "                pred_end = pred_start + 10  # Estimate\n",
    "            \n",
    "            intersection_start = max(pred_start, gt_start)\n",
    "            intersection_end = min(pred_end, gt_end)\n",
    "            intersection = max(0, intersection_end - intersection_start)\n",
    "            \n",
    "            union_start = min(pred_start, gt_start)\n",
    "            union_end = max(pred_end, gt_end)\n",
    "            union = union_end - union_start\n",
    "            \n",
    "            return intersection / union if union > 0 else 0\n",
    "        \n",
    "        print(\"\\nüìù Word-by-word comparison:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Word':<12} {'GT Start':<10} {'Pred Start':<12} {'Œî Start':<10} {'IoU':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        total_start_error = 0\n",
    "        total_iou = 0\n",
    "        matched_words = 0\n",
    "        \n",
    "        for gt_word in GROUND_TRUTH_WORDS:\n",
    "            word = gt_word[\"word\"]\n",
    "            gt_start = gt_word[\"start\"]\n",
    "            gt_end = gt_word[\"end\"]\n",
    "            \n",
    "            # Find matching word in predictions\n",
    "            pred_word = None\n",
    "            for idx, aligned in aligned_words.items():\n",
    "                if aligned.word and aligned.word.upper() == word.upper():\n",
    "                    pred_word = aligned\n",
    "                    break\n",
    "            \n",
    "            if pred_word:\n",
    "                pred_start = pred_word.start_time\n",
    "                pred_end = pred_word.end_time if pred_word.end_time else pred_start + (gt_end - gt_start)\n",
    "                \n",
    "                start_err, end_err = compute_frame_error(pred_start, pred_end, gt_start, gt_end)\n",
    "                iou = compute_iou(pred_start, pred_end, gt_start, gt_end)\n",
    "                \n",
    "                total_start_error += start_err\n",
    "                total_iou += iou\n",
    "                matched_words += 1\n",
    "                \n",
    "                status = \"‚úÖ\" if start_err <= 5 else (\"‚ö†Ô∏è\" if start_err <= 10 else \"‚ùå\")\n",
    "                print(f\"{word:<12} {gt_start:<10} {pred_start:<12} {start_err:<10} {iou:.2f}     {status}\")\n",
    "            else:\n",
    "                print(f\"{word:<12} {gt_start:<10} {'N/A':<12} {'N/A':<10} {'N/A':<8} ‚ùå\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # =================================================================\n",
    "        # Summary Statistics\n",
    "        # =================================================================\n",
    "        if matched_words > 0:\n",
    "            avg_start_error = total_start_error / matched_words\n",
    "            avg_iou = total_iou / matched_words\n",
    "            \n",
    "            print(f\"\\nüìà Accuracy Summary:\")\n",
    "            print(f\"   ‚Ä¢ Matched words: {matched_words}/{len(GROUND_TRUTH_WORDS)}\")\n",
    "            print(f\"   ‚Ä¢ Avg start frame error: {avg_start_error:.1f} frames ({avg_start_error * 20:.0f}ms)\")\n",
    "            print(f\"   ‚Ä¢ Avg IoU: {avg_iou:.2%}\")\n",
    "            \n",
    "            # Thresholds for pass/fail\n",
    "            if avg_start_error <= 5 and avg_iou >= 0.7:\n",
    "                print(f\"\\n‚úÖ Alignment accuracy: EXCELLENT\")\n",
    "            elif avg_start_error <= 10 and avg_iou >= 0.5:\n",
    "                print(f\"\\n‚ö†Ô∏è Alignment accuracy: ACCEPTABLE\")\n",
    "            else:\n",
    "                print(f\"\\n‚ùå Alignment accuracy: NEEDS IMPROVEMENT\")\n",
    "        \n",
    "        test_results[\"Test 13\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 13 PASSED - Accuracy comparison complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 13\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 13 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 14: Listening Test (Audio Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 14: Listening Test (Audio Preview)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if Test 12 didn't run\n",
    "if \"Test 12\" not in test_results or \"PASSED\" not in test_results.get(\"Test 12\", \"\"):\n",
    "    test_results[\"Test 14\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 14 SKIPPED - Test 12 (alignment) did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        from IPython.display import Audio, display, HTML\n",
    "        \n",
    "        print(\"\\nüéß Audio Preview: Ground Truth vs Prediction\")\n",
    "        print(\"   Following torchaudio's forced_alignment_tutorial.py pattern\")\n",
    "        \n",
    "        # Ratio to convert frames to samples\n",
    "        # Frame rate: 50fps, Sample rate: 16000\n",
    "        # Samples per frame = 16000 / 50 = 320\n",
    "        SAMPLES_PER_FRAME = sr // FRAME_RATE\n",
    "        \n",
    "        def get_audio_segment(start_frame, end_frame, padding_frames=2):\n",
    "            \"\"\"Extract audio segment by frame indices.\"\"\"\n",
    "            start_frame = max(0, int(start_frame) - padding_frames)\n",
    "            end_frame = int(end_frame) + padding_frames\n",
    "            x0 = start_frame * SAMPLES_PER_FRAME\n",
    "            x1 = min(end_frame * SAMPLES_PER_FRAME, waveform.size(1))\n",
    "            return waveform[:, x0:x1]\n",
    "        \n",
    "        # Show comparison for each word\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"Comparing Ground Truth vs Prediction for each word:\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for gt_word in GROUND_TRUTH_WORDS:\n",
    "            word = gt_word[\"word\"]\n",
    "            gt_start = gt_word[\"start\"]\n",
    "            gt_end = gt_word[\"end\"]\n",
    "            \n",
    "            # Find matching prediction\n",
    "            pred_word = None\n",
    "            for idx, aligned in aligned_words.items():\n",
    "                if aligned.word and aligned.word.upper() == word.upper():\n",
    "                    pred_word = aligned\n",
    "                    break\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            display(HTML(f\"<h3>{word}</h3>\"))\n",
    "            \n",
    "            # Ground Truth audio\n",
    "            gt_audio = get_audio_segment(gt_start, gt_end)\n",
    "            gt_start_sec = gt_start / FRAME_RATE\n",
    "            gt_end_sec = gt_end / FRAME_RATE\n",
    "            print(f\"üéØ Ground Truth: frames [{gt_start}, {gt_end}) = [{gt_start_sec:.3f}s - {gt_end_sec:.3f}s]\")\n",
    "            display(Audio(gt_audio.numpy(), rate=sr))\n",
    "            \n",
    "            # Prediction audio\n",
    "            if pred_word:\n",
    "                pred_start = int(pred_word.start_time)\n",
    "                pred_end = int(pred_word.end_time) if pred_word.end_time else pred_start + (gt_end - gt_start)\n",
    "                pred_audio = get_audio_segment(pred_start, pred_end)\n",
    "                pred_start_sec = pred_start / FRAME_RATE\n",
    "                pred_end_sec = pred_end / FRAME_RATE\n",
    "                \n",
    "                delta = abs(pred_start - gt_start)\n",
    "                status = \"‚úÖ\" if delta <= 5 else (\"‚ö†Ô∏è\" if delta <= 10 else \"‚ùå\")\n",
    "                \n",
    "                print(f\"üîÆ Prediction:   frames [{pred_start}, {pred_end}) = [{pred_start_sec:.3f}s - {pred_end_sec:.3f}s]  Œî={delta} frames {status}\")\n",
    "                display(Audio(pred_audio.numpy(), rate=sr))\n",
    "            else:\n",
    "                print(f\"üîÆ Prediction:   ‚ùå NOT FOUND\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        test_results[\"Test 14\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 14 PASSED - Audio preview complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 14\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 14 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 15: MFA Aligner Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"Test 15: MFA Aligner Test\")\nprint(\"=\" * 60)\n\ntry:\n    from alignment import MFAAligner, AlignmentConfig\n\n    print(\"\\nüîß MFA Aligner Configuration:\")\n    config = AlignmentConfig(backend=\"mfa\", language=\"english_us_arpa\")\n    aligner = MFAAligner(config)\n\n    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n    print(f\"   ‚Ä¢ Acoustic model: {aligner.acoustic_model}\")\n    print(f\"   ‚Ä¢ Dictionary: {aligner.dictionary}\")\n\n    # Check if MFA is available\n    mfa_available = aligner._check_mfa_available()\n    print(f\"\\nüì° MFA CLI available: {'‚úÖ' if mfa_available else '‚ùå'}\")\n\n    if not mfa_available:\n        # Skip test if MFA not installed\n        print(\"\\n‚è≠Ô∏è MFA not installed - skipping alignment test\")\n        print(\"\\nüì¶ To install MFA:\")\n        print(\"   conda install -c conda-forge montreal-forced-aligner\")\n        print(\"   # Or: pip install montreal-forced-aligner\")\n        test_results[\"Test 15\"] = \"‚è≠Ô∏è SKIPPED (MFA not installed)\"\n        print(f\"\\n‚è≠Ô∏è Test 15 SKIPPED - MFA not available\")\n    else:\n        # Try to run alignment on sample audio\n        print(\"\\nüîÑ Running MFA alignment on sample audio...\")\n\n        # Load sample audio (reuse from Test 12)\n        if 'waveform' in dir() and 'TRANSCRIPT' in dir():\n            result = aligner.align(waveform.squeeze(0), TRANSCRIPT)\n\n            print(f\"\\nüìä MFA Alignment Results:\")\n            print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n            print(f\"   ‚Ä¢ Backend: {result.metadata.get('backend', 'N/A')}\")\n\n            if result.word_alignments:\n                print(\"\\nüìù Word-level results:\")\n                for idx, word in sorted(result.word_alignments.items())[:5]:\n                    print(f\"   [{idx}] {word.word}: {word.start_time} - {word.end_time}\")\n                if len(result.word_alignments) > 5:\n                    print(f\"   ... and {len(result.word_alignments) - 5} more\")\n\n            test_results[\"Test 15\"] = \"‚úÖ PASSED\"\n            print(f\"\\n‚úÖ Test 15 PASSED - MFA alignment completed\")\n        else:\n            print(\"   ‚ö†Ô∏è Sample audio not available (run Test 12 first)\")\n            test_results[\"Test 15\"] = \"‚è≠Ô∏è SKIPPED (no audio)\"\n            print(f\"\\n‚è≠Ô∏è Test 15 SKIPPED - No sample audio\")\n\nexcept Exception as e:\n    test_results[\"Test 15\"] = \"‚ùå FAILED\"\n    print(f\"\\n‚ùå Test 15 FAILED: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 16: Gentle Aligner Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"Test 16: Gentle Aligner Test\")\nprint(\"=\" * 60)\n\ntry:\n    from alignment import GentleAligner, AlignmentConfig\n\n    print(\"\\nüîß Gentle Aligner Configuration:\")\n    config = AlignmentConfig(backend=\"gentle\")\n    aligner = GentleAligner(config)\n\n    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n    print(f\"   ‚Ä¢ Server URL: {aligner.server_url}\")\n    print(f\"   ‚Ä¢ Supported languages: {aligner.SUPPORTED_LANGUAGES}\")\n\n    # Check availability\n    python_available = aligner._check_gentle_python()\n    server_available = aligner._check_gentle_server()\n\n    print(f\"\\nüì° Availability:\")\n    print(f\"   ‚Ä¢ Python API: {'‚úÖ' if python_available else '‚ùå not installed'}\")\n    print(f\"   ‚Ä¢ Server ({aligner.server_url}): {'‚úÖ' if server_available else '‚ùå not running'}\")\n\n    if not python_available and not server_available:\n        # Skip test if Gentle not available\n        print(\"\\n‚è≠Ô∏è Gentle not available - skipping alignment test\")\n        print(\"\\nüì¶ To install Gentle:\")\n        print(\"   git clone https://github.com/lowerquality/gentle && cd gentle && ./install.sh\")\n        print(\"   Or start server: docker run -p 8765:8765 lowerquality/gentle\")\n        test_results[\"Test 16\"] = \"‚è≠Ô∏è SKIPPED (Gentle not installed)\"\n        print(f\"\\n‚è≠Ô∏è Test 16 SKIPPED - Gentle not available\")\n    else:\n        # Try to run alignment on sample audio\n        print(\"\\nüîÑ Running Gentle alignment on sample audio...\")\n\n        # Load sample audio (reuse from Test 12)\n        if 'waveform' in dir() and 'TRANSCRIPT' in dir():\n            # Use 4 threads for parallelization\n            result = aligner.align(waveform.squeeze(0), TRANSCRIPT, nthreads=4)\n\n            print(f\"\\nüìä Gentle Alignment Results:\")\n            print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n            print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n            print(f\"   ‚Ä¢ Backend: {result.metadata.get('backend', 'N/A')}\")\n\n            if result.word_alignments:\n                print(\"\\nüìù Word-level results:\")\n                for idx, word in sorted(result.word_alignments.items())[:5]:\n                    end_str = f\"{word.end_time}\" if word.end_time else \"?\"\n                    print(f\"   [{idx}] {word.word}: {word.start_time} - {end_str}\")\n                if len(result.word_alignments) > 5:\n                    print(f\"   ... and {len(result.word_alignments) - 5} more\")\n\n            test_results[\"Test 16\"] = \"‚úÖ PASSED\"\n            print(f\"\\n‚úÖ Test 16 PASSED - Gentle alignment completed\")\n        else:\n            print(\"   ‚ö†Ô∏è Sample audio not available (run Test 12 first)\")\n            test_results[\"Test 16\"] = \"‚è≠Ô∏è SKIPPED (no audio)\"\n            print(f\"\\n‚è≠Ô∏è Test 16 SKIPPED - No sample audio\")\n\nexcept Exception as e:\n    test_results[\"Test 16\"] = \"‚ùå FAILED\"\n    print(f\"\\n‚ùå Test 16 FAILED: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive: Listen to All Aligned Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Interactive: Listen to all aligned words\n",
    "# =================================================================\n",
    "# Run this cell to hear each aligned word with audio players\n",
    "\n",
    "if \"Test 12\" in test_results and \"PASSED\" in test_results.get(\"Test 12\", \"\"):\n",
    "    from IPython.display import Audio, display\n",
    "    \n",
    "    print(\"üéß Listen to each aligned word:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Helper function to preview words (local implementation)\n",
    "    def preview_aligned_words(waveform, word_alignments, sample_rate=16000, frame_rate=50, max_words=20):\n",
    "        \"\"\"Preview aligned words with audio players.\"\"\"\n",
    "        samples_per_frame = sample_rate // frame_rate\n",
    "        \n",
    "        for idx, word in sorted(word_alignments.items())[:max_words]:\n",
    "            start_frame = int(word.start_time)\n",
    "            end_frame = int(word.end_time) if word.end_time else start_frame + 10\n",
    "            \n",
    "            # Add padding\n",
    "            start_frame = max(0, start_frame - 2)\n",
    "            end_frame = end_frame + 2\n",
    "            \n",
    "            # Extract audio segment\n",
    "            x0 = start_frame * samples_per_frame\n",
    "            x1 = min(end_frame * samples_per_frame, waveform.size(-1))\n",
    "            \n",
    "            if waveform.dim() == 2:\n",
    "                segment = waveform[:, x0:x1]\n",
    "            else:\n",
    "                segment = waveform[x0:x1]\n",
    "            \n",
    "            start_sec = start_frame / frame_rate\n",
    "            end_sec = end_frame / frame_rate\n",
    "            \n",
    "            print(f\"\\n[{idx}] '{word.word}' ({start_sec:.2f}s - {end_sec:.2f}s)\")\n",
    "            display(Audio(segment.numpy(), rate=sample_rate))\n",
    "    \n",
    "    # Preview the aligned words\n",
    "    preview_aligned_words(waveform, aligned_words, sample_rate=sr, frame_rate=FRAME_RATE)\n",
    "    \n",
    "    if len(aligned_words) > 20:\n",
    "        print(f\"\\n... showing first 20 of {len(aligned_words)} words\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Alignment not available - run Test 12 first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}