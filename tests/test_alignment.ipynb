{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook: Alignment Module\n",
    "\n",
    "This notebook tests the `alignment` module for speech-to-text alignment.\n",
    "\n",
    "**Features tested:**\n",
    "1. Module imports and structure\n",
    "2. Data classes (AlignmentResult, AlignedWord, AlignedToken)\n",
    "3. WFST factor transducer construction\n",
    "4. Tokenizers (Character, BPE, Phoneme) - via unified `text_frontend`\n",
    "5. Audio segmentation - via unified `audio_frontend`\n",
    "6. LIS (Longest Increasing Subsequence) utilities\n",
    "7. MFA backend availability\n",
    "8. Gentle backend availability\n",
    "9. Full WFST Aligner integration\n",
    "10. **Segment-wise alignment API** (for use with stitching_utils)\n",
    "11. **Ground truth data** loading\n",
    "12. **Run WFST alignment** on sample audio\n",
    "13. **Accuracy comparison** (frame error, IoU metrics)\n",
    "14. **Listening test** (audio preview of aligned words)\n",
    "15. **MFA aligner test** (if installed)\n",
    "16. **Gentle aligner test** (if installed)\n",
    "\n",
    "**Architecture:**\n",
    "The alignment module produces **SEGMENT-WISE** results (each segment aligned independently).\n",
    "For global alignment, use `stitching_utils` to combine segments.\n",
    "\n",
    "**Alignment Backends:**\n",
    "| Backend | Description | Fuzzy Support | Languages |\n",
    "|---------|-------------|---------------|-----------|\n",
    "| `WFSTAligner` | k2-based factor transducer | ‚úÖ Yes | 1100+ (MMS) |\n",
    "| `MFAAligner` | Montreal Forced Aligner | ‚ùå No | 50+ |\n",
    "| `GentleAligner` | Kaldi-based (English) | ‚ùå No | English only |\n",
    "\n",
    "**Key methods:**\n",
    "- `aligner.align_segments(waveform, text)` ‚Üí `List[SegmentAlignmentResult]` (no stitching)\n",
    "- `aligner.align(waveform, text, stitch=True)` ‚Üí `AlignmentResult` (with optional stitching)\n",
    "\n",
    "**Accuracy Testing:**\n",
    "- Ground truth from MMS-FA CTC alignment (50fps frame rate)\n",
    "- Metrics: Frame error (start/end), IoU (boundary overlap)\n",
    "- Audio preview: `preview_word(idx)`, `preview_word_by_name(\"CURIOSITY\")`, `preview_all_words()`\n",
    "\n",
    "**Installation (Colab):**\n",
    "```bash\n",
    "# GPU Version\n",
    "pip install k2==1.24.4.dev20251030+cuda12.6.torch2.9.0 -f https://k2-fsa.github.io/k2/cuda.html\n",
    "\n",
    "# CPU Version (use --no-deps to avoid env changes)\n",
    "pip install k2==1.24.4.dev20251029+cpu.torch2.9.0 --no-deps -f https://k2-fsa.github.io/k2/cpu.html\n",
    "\n",
    "# Common dependencies\n",
    "pip install pytorch-lightning cmudict g2p_en pydub\n",
    "pip install git+https://github.com/huangruizhe/lis.git\n",
    "\n",
    "# Optional: MFA\n",
    "pip install montreal-forced-aligner\n",
    "\n",
    "# Optional: Gentle\n",
    "pip install gentle  # or docker run -p 8765:8765 lowerquality/gentle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/torchaudio_aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://k2-fsa.github.io/k2/cpu.html\n",
      "Requirement already satisfied: k2==1.24.4.dev20251029+cpu.torch2.9.0 in /usr/local/lib/python3.12/dist-packages (1.24.4.dev20251029+cpu.torch2.9.0)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.9.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
      "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.15.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (0.15.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.11)\n",
      "Requirement already satisfied: cmudict in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
      "Requirement already satisfied: g2p_en in /usr/local/lib/python3.12/dist-packages (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.12/dist-packages (from cmudict) (8.7.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.12/dist-packages (from cmudict) (6.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (2.0.2)\n",
      "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (3.9.1)\n",
      "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (7.5.0)\n",
      "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (0.1.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=5->cmudict) (3.23.0)\n",
      "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (10.8.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (4.4.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en) (4.15.0)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
      "Collecting git+https://github.com/huangruizhe/lis.git\n",
      "  Cloning https://github.com/huangruizhe/lis.git to /tmp/pip-req-build-3uc1b1me\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huangruizhe/lis.git /tmp/pip-req-build-3uc1b1me\n",
      "  Resolved https://github.com/huangruizhe/lis.git to commit 3501cbae3daac664d29be3cc330008b0731aa021\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lis_package==0.1) (2.0.2)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Install Dependencies (run once)\n",
    "# =============================================================================\n",
    "# Uncomment and run the appropriate section for your environment\n",
    "\n",
    "# ===== GPU Version (Colab with GPU) =====\n",
    "# !pip install k2==1.24.4.dev20251030+cuda12.6.torch2.9.0 -f https://k2-fsa.github.io/k2/cuda.html\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install cmudict g2p_en\n",
    "# !pip install pydub\n",
    "# !pip install git+https://github.com/huangruizhe/lis.git\n",
    "\n",
    "# ===== CPU Version (Colab CPU or local) =====\n",
    "# Note: --no-deps to avoid changing the Python environment\n",
    "!pip install k2==1.24.4.dev20251029+cpu.torch2.9.0 --no-deps -f https://k2-fsa.github.io/k2/cpu.html\n",
    "!pip install pytorch-lightning\n",
    "!pip install cmudict g2p_en\n",
    "!pip install pydub\n",
    "!pip install git+https://github.com/huangruizhe/lis.git\n",
    "!pip install torchcodec\n",
    "\n",
    "# ===== Optional: MFA (Montreal Forced Aligner) =====\n",
    "# !pip install montreal-forced-aligner\n",
    "# # Or via conda: conda install -c conda-forge montreal-forced-aligner\n",
    "\n",
    "# ===== Optional: Gentle Aligner =====\n",
    "# !pip install gentle\n",
    "# # Or via Docker: docker run -p 8765:8765 lowerquality/gentle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repository (branch: dev)...\n",
      "Repository cloned\n",
      "\n",
      "============================================================\n",
      "Checking dependencies...\n",
      "============================================================\n",
      "‚úÖ k2 version:\n",
      "Name: k2\n",
      "Version: 1.24.4.dev20251029+cpu.torch2.9.0\n",
      "Summary: FSA/FST algorithms, intended to (eventually) be interoperable with PyTorch and similar\n",
      "Home-page: https://github.com/k2-fsa/k2\n",
      "Author: Daniel Povey\n",
      "Author-email: dpovey@gmail.com\n",
      "License: \n",
      "Location: /usr/local/lib/python3.12/dist-packages\n",
      "Requires: graphviz, torch\n",
      "Required-by: \n",
      "‚úÖ lis library available\n",
      "   Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Setup: Configure Imports\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "GITHUB_REPO = \"https://github.com/huangruizhe/torchaudio_aligner.git\"\n",
    "BRANCH = \"dev\"  # Use 'dev' for testing, 'main' for stable\n",
    "# =========================\n",
    "\n",
    "# Test result tracking\n",
    "test_results = {}\n",
    "\n",
    "def setup_imports():\n",
    "    \"\"\"Setup Python path for imports based on environment.\"\"\"\n",
    "    \n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        repo_path = '/content/torchaudio_aligner'\n",
    "        src_path = f'{repo_path}/src'\n",
    "        \n",
    "        if not os.path.exists(repo_path):\n",
    "            print(f\"Cloning repository (branch: {BRANCH})...\")\n",
    "            os.system(f'git clone -b {BRANCH} {GITHUB_REPO} {repo_path}')\n",
    "            print(\"Repository cloned\")\n",
    "        else:\n",
    "            print(f\"Updating repository (branch: {BRANCH})...\")\n",
    "            os.system(f'cd {repo_path} && git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}')\n",
    "            print(\"Repository updated\")\n",
    "    else:\n",
    "        possible_paths = [\n",
    "            Path(\".\").absolute().parent / \"src\",\n",
    "            Path(\".\").absolute() / \"src\",\n",
    "        ]\n",
    "        \n",
    "        src_path = None\n",
    "        for p in possible_paths:\n",
    "            if p.exists() and (p / \"alignment\").exists():\n",
    "                src_path = str(p.absolute())\n",
    "                break\n",
    "        \n",
    "        if src_path is None:\n",
    "            raise FileNotFoundError(\"src directory not found\")\n",
    "        \n",
    "        print(f\"Running locally from: {src_path}\")\n",
    "    \n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "    \n",
    "    return src_path\n",
    "\n",
    "src_path = setup_imports()\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Check dependencies\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Checking dependencies...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check k2\n",
    "try:\n",
    "    import k2\n",
    "    print(f\"‚úÖ k2 version:\")\n",
    "    ! pip show k2\n",
    "    K2_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è k2 not available - WFST tests will be limited\")\n",
    "    print(\"   Install with: pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\")\n",
    "    K2_AVAILABLE = False\n",
    "\n",
    "# Check lis\n",
    "try:\n",
    "    import lis\n",
    "    print(\"‚úÖ lis library available\")\n",
    "    LIS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è lis not available - LIS tests will be skipped\")\n",
    "    print(\"   Install with: pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "    LIS_AVAILABLE = False\n",
    "\n",
    "print(f\"   Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Module Imports and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 1: Module Imports and Structure\n",
      "============================================================\n",
      "üì¶ Imports successful!\n",
      "\n",
      "üîß Available backends:\n",
      "   ‚úÖ wfst: WFST/k2-based fuzzy alignment with factor transducer\n",
      "      Languages: 1100+ (with MMS)\n",
      "      Fuzzy alignment: True\n",
      "   ‚úÖ mfa: Montreal Forced Aligner (Kaldi-based)\n",
      "      Languages: Many (with pretrained models)\n",
      "      Fuzzy alignment: False\n",
      "   ‚úÖ gentle: Gentle aligner for English\n",
      "      Languages: English only\n",
      "      Fuzzy alignment: False\n",
      "   üöß asr_ngram: ASR + ngram LM alignment (NOT IMPLEMENTED)\n",
      "      Languages: N/A\n",
      "      Fuzzy alignment: True\n",
      "\n",
      "‚úÖ Test 1 PASSED - Module imports successful\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 1: Module Imports and Structure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import (\n",
    "        # Data classes\n",
    "        AlignmentResult,\n",
    "        AlignedWord,\n",
    "        AlignedToken,\n",
    "        AlignmentConfig,\n",
    "        # Base class\n",
    "        AlignerBackend,\n",
    "        # Backends\n",
    "        WFSTAligner,\n",
    "        MFAAligner,\n",
    "        GentleAligner,\n",
    "        # API functions\n",
    "        align,\n",
    "        align_long_audio,\n",
    "        get_aligner,\n",
    "        list_backends,\n",
    "    )\n",
    "    \n",
    "    print(\"üì¶ Imports successful!\")\n",
    "    \n",
    "    # List available backends\n",
    "    backends = list_backends()\n",
    "    print(\"\\nüîß Available backends:\")\n",
    "    for name, info in backends.items():\n",
    "        status = \"üöß\" if info.get(\"status\") == \"placeholder\" else \"‚úÖ\"\n",
    "        print(f\"   {status} {name}: {info['description']}\")\n",
    "        print(f\"      Languages: {info['languages']}\")\n",
    "        print(f\"      Fuzzy alignment: {info['fuzzy']}\")\n",
    "    \n",
    "    test_results[\"Test 1\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 1 PASSED - Module imports successful\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 1\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 1 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 2: Data Classes (AlignmentConfig, AlignedWord, AlignmentResult)\n",
      "============================================================\n",
      "\n",
      "üìã AlignmentConfig:\n",
      "   ‚Ä¢ Backend: wfst\n",
      "   ‚Ä¢ Device: cpu\n",
      "   ‚Ä¢ Segment size: 15.0s\n",
      "   ‚Ä¢ Skip penalty: -0.5\n",
      "   ‚Ä¢ Return penalty: -18.0\n",
      "\n",
      "üìù AlignedWord:\n",
      "   ‚Ä¢ Word: 'hello'\n",
      "   ‚Ä¢ Start: 2.00s\n",
      "   ‚Ä¢ End: 3.00s\n",
      "   ‚Ä¢ Duration: 1.00s\n",
      "   ‚Ä¢ Phones: ['h', 'e', 'l', 'l', 'o']\n",
      "\n",
      "üìä AlignmentResult:\n",
      "   ‚Ä¢ Aligned words: 2\n",
      "   ‚Ä¢ Aligned text: 'hello world'\n",
      "   ‚Ä¢ Unaligned regions: [(2, 3)]\n",
      "\n",
      "üè∑Ô∏è Audacity labels format:\n",
      "   2.00\t2.00\thello\n",
      "   3.20\t3.20\tworld\n",
      "\n",
      "‚úÖ Test 2 PASSED - Data classes work correctly\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 2: Data Classes (AlignmentConfig, AlignedWord, AlignmentResult)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Test AlignmentConfig\n",
    "    print(\"\\nüìã AlignmentConfig:\")\n",
    "    config = AlignmentConfig(\n",
    "        backend=\"wfst\",\n",
    "        language=\"eng\",\n",
    "        segment_size=15.0,\n",
    "        overlap=2.0,\n",
    "        skip_penalty=-0.5,\n",
    "        return_penalty=-18.0,\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Backend: {config.backend}\")\n",
    "    print(f\"   ‚Ä¢ Device: {config.device}\")\n",
    "    print(f\"   ‚Ä¢ Segment size: {config.segment_size}s\")\n",
    "    print(f\"   ‚Ä¢ Skip penalty: {config.skip_penalty}\")\n",
    "    print(f\"   ‚Ä¢ Return penalty: {config.return_penalty}\")\n",
    "    \n",
    "    # Test AlignedWord\n",
    "    print(\"\\nüìù AlignedWord:\")\n",
    "    word = AlignedWord(\n",
    "        word=\"hello\",\n",
    "        start_time=100,\n",
    "        end_time=150,\n",
    "        phones=[\n",
    "            AlignedToken(token_id=\"h\", timestamp=100, score=0.9),\n",
    "            AlignedToken(token_id=\"e\", timestamp=110, score=0.85),\n",
    "            AlignedToken(token_id=\"l\", timestamp=120, score=0.88),\n",
    "            AlignedToken(token_id=\"l\", timestamp=130, score=0.92),\n",
    "            AlignedToken(token_id=\"o\", timestamp=140, score=0.87),\n",
    "        ],\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Word: '{word.word}'\")\n",
    "    print(f\"   ‚Ä¢ Start: {word.start_seconds:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ End: {word.end_seconds:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Duration: {word.duration:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Phones: {[p.token_id for p in word.phones]}\")\n",
    "    \n",
    "    # Test AlignmentResult\n",
    "    print(\"\\nüìä AlignmentResult:\")\n",
    "    result = AlignmentResult(\n",
    "        word_alignments={\n",
    "            0: AlignedWord(\"hello\", 100, 150),\n",
    "            1: AlignedWord(\"world\", 160, 220),\n",
    "        },\n",
    "        unaligned_indices=[(2, 3)],\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n",
    "    print(f\"   ‚Ä¢ Aligned text: '{result.aligned_text}'\")\n",
    "    print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n",
    "    \n",
    "    # Test Audacity export\n",
    "    labels = result.to_audacity_labels()\n",
    "    print(f\"\\nüè∑Ô∏è Audacity labels format:\")\n",
    "    for line in labels.split('\\n'):\n",
    "        print(f\"   {line}\")\n",
    "    \n",
    "    test_results[\"Test 2\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 2 PASSED - Data classes work correctly\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 2\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 2 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: WFST Factor Transducer Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 3: WFST Factor Transducer Construction\n",
      "============================================================\n",
      "\n",
      "üìù Tokenized text: [[7, 4, 11, 11, 14], [22, 14, 17, 11, 3]]\n",
      "   Flattened: [7, 4, 11, 11, 14, 22, 14, 17, 11, 3]\n",
      "\n",
      "üîß Factor Transducer:\n",
      "   ‚Ä¢ States: 23\n",
      "   ‚Ä¢ Arcs: 66\n",
      "   ‚Ä¢ Skip ID: 21\n",
      "   ‚Ä¢ Return ID: 22\n",
      "\n",
      "üìñ Symbol tables:\n",
      "   ‚Ä¢ Word index table: {0: 0, 1: 0, 6: 1, 11: 2}\n",
      "   ‚Ä¢ Token table (first 5): {0: 0, 1: 7, 2: 4, 3: 11, 4: 11}...\n",
      "\n",
      "‚úÖ Test 3 PASSED - Factor transducer construction works\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 3: WFST Factor Transducer Construction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE:\n",
    "    test_results[\"Test 3\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 3 SKIPPED - k2 not available\")\n",
    "    print(\"   Install with: pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment.wfst import (\n",
    "            make_factor_transducer_word_level_index_with_skip,\n",
    "            flatten_list,\n",
    "        )\n",
    "        \n",
    "        # Simulated tokenized text: [[h,e,l,l,o], [w,o,r,l,d]]\n",
    "        # Using fake token IDs\n",
    "        tokenized_text = [\n",
    "            [7, 4, 11, 11, 14],   # hello\n",
    "            [22, 14, 17, 11, 3],  # world\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nüìù Tokenized text: {tokenized_text}\")\n",
    "        print(f\"   Flattened: {flatten_list(tokenized_text)}\")\n",
    "        \n",
    "        # Build factor transducer\n",
    "        graph, word_sym, token_sym = make_factor_transducer_word_level_index_with_skip(\n",
    "            tokenized_text,\n",
    "            skip_penalty=-0.5,\n",
    "            return_penalty=-18.0,\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüîß Factor Transducer:\")\n",
    "        print(f\"   ‚Ä¢ States: {graph.shape[0]}\")\n",
    "        print(f\"   ‚Ä¢ Arcs: {graph.num_arcs}\")\n",
    "        print(f\"   ‚Ä¢ Skip ID: {graph.skip_id}\")\n",
    "        print(f\"   ‚Ä¢ Return ID: {graph.return_id}\")\n",
    "        \n",
    "        print(f\"\\nüìñ Symbol tables:\")\n",
    "        print(f\"   ‚Ä¢ Word index table: {word_sym}\")\n",
    "        print(f\"   ‚Ä¢ Token table (first 5): {dict(list(token_sym.items())[:5])}...\")\n",
    "        \n",
    "        test_results[\"Test 3\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 3 PASSED - Factor transducer construction works\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 3\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 3 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 4: Tokenizers (via text_frontend)\n",
      "============================================================\n",
      "\n",
      "üî§ CharTokenizer (MMS-FA style):\n",
      "   ‚Ä¢ Vocab size: 29\n",
      "   ‚Ä¢ Blank ID: 0\n",
      "   ‚Ä¢ UNK ID: 28\n",
      "   ‚Ä¢ Implements TokenizerInterface: True\n",
      "\n",
      "üìù Encoding test:\n",
      "   ‚Ä¢ Original: 'hello world'\n",
      "   ‚Ä¢ Normalized: 'hello world'\n",
      "   ‚Ä¢ Encoded: [[15, 3, 12, 12, 5], [19, 5, 9, 12, 13]]\n",
      "   ‚Ä¢ Decoded: ['hello', 'world']\n",
      "   ‚Ä¢ Flattened: [15, 3, 12, 12, 5, 19, 5, 9, 12, 13]\n",
      "\n",
      "üåê OOV handling:\n",
      "   ‚Ä¢ Original: 'hello ‰Ω†Â•Ω world'\n",
      "   ‚Ä¢ Normalized: 'hello ‰Ω†Â•Ω world'\n",
      "   ‚Ä¢ Encoded: [[15, 3, 12, 12, 5], [28, 28], [19, 5, 9, 12, 13]]\n",
      "\n",
      "‚úÖ Test 4 PASSED - Tokenizers work correctly\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 4: Tokenizers (via text_frontend)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Import from unified text_frontend\n",
    "    from text_frontend import (\n",
    "        TokenizerInterface,\n",
    "        CharTokenizer,\n",
    "        create_tokenizer_from_labels,\n",
    "    )\n",
    "    \n",
    "    # Create tokenizer with MMS-FA style labels\n",
    "    labels = ('-', 'a', 'i', 'e', 'n', 'o', 'u', 't', 's', 'r', 'm', 'k', 'l', 'd', \n",
    "              'g', 'h', 'y', 'b', 'p', 'w', 'c', 'v', 'j', 'z', 'f', \"'\", 'q', 'x', '*')\n",
    "    \n",
    "    tokenizer = create_tokenizer_from_labels(labels, blank_token='-', unk_token='*')\n",
    "    \n",
    "    print(f\"\\nüî§ CharTokenizer (MMS-FA style):\")\n",
    "    print(f\"   ‚Ä¢ Vocab size: {len(tokenizer.token2id)}\")\n",
    "    print(f\"   ‚Ä¢ Blank ID: {tokenizer.blk_id}\")\n",
    "    print(f\"   ‚Ä¢ UNK ID: {tokenizer.unk_id}\")\n",
    "    print(f\"   ‚Ä¢ Implements TokenizerInterface: {isinstance(tokenizer, TokenizerInterface)}\")\n",
    "    \n",
    "    # Test encoding\n",
    "    text = \"hello world\"\n",
    "    normalized = tokenizer.text_normalize(text)\n",
    "    encoded = tokenizer.encode(normalized)\n",
    "    decoded = tokenizer.decode(encoded)\n",
    "    \n",
    "    print(f\"\\nüìù Encoding test:\")\n",
    "    print(f\"   ‚Ä¢ Original: '{text}'\")\n",
    "    print(f\"   ‚Ä¢ Normalized: '{normalized}'\")\n",
    "    print(f\"   ‚Ä¢ Encoded: {encoded}\")\n",
    "    print(f\"   ‚Ä¢ Decoded: {decoded}\")\n",
    "    \n",
    "    # Test flatten\n",
    "    flattened = tokenizer.encode_flatten(normalized)\n",
    "    print(f\"   ‚Ä¢ Flattened: {flattened}\")\n",
    "    \n",
    "    # Test with OOV characters\n",
    "    text_oov = \"hello ‰Ω†Â•Ω world\"\n",
    "    normalized_oov = tokenizer.text_normalize(text_oov)\n",
    "    encoded_oov = tokenizer.encode(normalized_oov)\n",
    "    \n",
    "    print(f\"\\nüåê OOV handling:\")\n",
    "    print(f\"   ‚Ä¢ Original: '{text_oov}'\")\n",
    "    print(f\"   ‚Ä¢ Normalized: '{normalized_oov}'\")\n",
    "    print(f\"   ‚Ä¢ Encoded: {encoded_oov}\")\n",
    "    \n",
    "    test_results[\"Test 4\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 4 PASSED - Tokenizers work correctly\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 4\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 4 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Audio Segmentation (via audio_frontend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 5: Audio Segmentation (via audio_frontend)\n",
      "============================================================\n",
      "\n",
      "üéµ Input waveform:\n",
      "   ‚Ä¢ Shape: torch.Size([480000])\n",
      "   ‚Ä¢ Duration: 30.00s\n",
      "\n",
      "‚úÇÔ∏è Segmentation result (SegmentationResult):\n",
      "   ‚Ä¢ Num segments: 3\n",
      "   ‚Ä¢ Segment size: 240128 samples (15.01s)\n",
      "   ‚Ä¢ Overlap: 32128 samples (2.01s)\n",
      "   ‚Ä¢ Original duration: 30.00s\n",
      "\n",
      "üì¶ Batched tensors:\n",
      "   ‚Ä¢ Segments shape: torch.Size([3, 240128])\n",
      "   ‚Ä¢ Lengths: [240128, 240128, 64000]\n",
      "   ‚Ä¢ Offsets: [0, 208000, 416000]\n",
      "\n",
      "üîç First segment (AudioSegment):\n",
      "   ‚Ä¢ Waveform shape: torch.Size([240128])\n",
      "   ‚Ä¢ Offset: 0 samples (0.00s)\n",
      "   ‚Ä¢ Duration: 15.01s\n",
      "   ‚Ä¢ Index: 0\n",
      "\n",
      "üìê Overlap verification:\n",
      "   ‚Ä¢ Step size: 208000 samples (13.00s)\n",
      "   ‚Ä¢ Offsets approximately match expected: ‚úÖ\n",
      "\n",
      "‚úÖ Test 5 PASSED - Segmentation works correctly\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 5: Audio Segmentation (via audio_frontend)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Import from unified audio_frontend\n",
    "    from audio_frontend import (\n",
    "        segment_waveform,\n",
    "        AudioSegment,\n",
    "        SegmentationResult,\n",
    "    )\n",
    "    \n",
    "    # Create test waveform: 30 seconds at 16kHz\n",
    "    waveform = torch.randn(480000)  # (T,) - 1D\n",
    "    sample_rate = 16000\n",
    "    \n",
    "    print(f\"\\nüéµ Input waveform:\")\n",
    "    print(f\"   ‚Ä¢ Shape: {waveform.shape}\")\n",
    "    print(f\"   ‚Ä¢ Duration: {waveform.shape[0] / sample_rate:.2f}s\")\n",
    "    \n",
    "    # Segment with overlap using audio_frontend\n",
    "    result = segment_waveform(\n",
    "        waveform,\n",
    "        sample_rate=sample_rate,\n",
    "        segment_size=15.0,    # 15 seconds\n",
    "        overlap=2.0,          # 2 seconds overlap\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÇÔ∏è Segmentation result (SegmentationResult):\")\n",
    "    print(f\"   ‚Ä¢ Num segments: {result.num_segments}\")\n",
    "    print(f\"   ‚Ä¢ Segment size: {result.segment_size_samples} samples ({result.segment_size_samples/sample_rate:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Overlap: {result.overlap_samples} samples ({result.overlap_samples/sample_rate:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Original duration: {result.original_duration_seconds:.2f}s\")\n",
    "    \n",
    "    # Get batched tensors\n",
    "    segments, lengths = result.get_waveforms_batched()\n",
    "    offsets = torch.tensor([seg.offset_samples for seg in result.segments])\n",
    "    \n",
    "    print(f\"\\nüì¶ Batched tensors:\")\n",
    "    print(f\"   ‚Ä¢ Segments shape: {segments.shape}\")\n",
    "    print(f\"   ‚Ä¢ Lengths: {lengths.tolist()}\")\n",
    "    print(f\"   ‚Ä¢ Offsets: {offsets.tolist()}\")\n",
    "    \n",
    "    # Verify AudioSegment objects\n",
    "    print(f\"\\nüîç First segment (AudioSegment):\")\n",
    "    seg0 = result.segments[0]\n",
    "    print(f\"   ‚Ä¢ Waveform shape: {seg0.waveform.shape}\")\n",
    "    print(f\"   ‚Ä¢ Offset: {seg0.offset_samples} samples ({seg0.offset_seconds:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Duration: {seg0.duration_seconds:.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Index: {seg0.segment_index}\")\n",
    "    \n",
    "    # Verify overlap\n",
    "    step = result.segment_size_samples - result.overlap_samples\n",
    "    expected_offsets = [i * step for i in range(result.num_segments)]\n",
    "    # Allow for small differences due to extra_samples\n",
    "    offsets_match = all(abs(a - e) < 200 for a, e in zip(offsets.tolist(), expected_offsets))\n",
    "    \n",
    "    print(f\"\\nüìê Overlap verification:\")\n",
    "    print(f\"   ‚Ä¢ Step size: {step} samples ({step/sample_rate:.2f}s)\")\n",
    "    print(f\"   ‚Ä¢ Offsets approximately match expected: {'‚úÖ' if offsets_match else '‚ùå'}\")\n",
    "    \n",
    "    test_results[\"Test 5\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 5 PASSED - Segmentation works correctly\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 5\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 5 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: LIS Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 6: LIS (Longest Increasing Subsequence) Utilities\n",
      "============================================================\n",
      "\n",
      "üìà LIS computation:\n",
      "   ‚Ä¢ Input: [1, 5, 2, 6, 3, 7, 4, 8, 9, 10, 11, 15, 12, 16, 13]\n",
      "   ‚Ä¢ LIS: [1, 2, 3, 4, 8, 9, 10, 11, 12, 13]\n",
      "   ‚Ä¢ LIS length: 10\n",
      "   ‚Ä¢ Is strictly increasing: ‚úÖ\n",
      "\n",
      "üîç Outlier removal:\n",
      "   ‚Ä¢ Input: [5, 100, 10, 15, 20, 25, 30, 35, 200]\n",
      "   ‚Ä¢ Cleaned: [5, 100, 10, 15, 20, 25, 30, 35, 200]\n",
      "\n",
      "üï≥Ô∏è Unaligned region detection:\n",
      "   ‚Ä¢ Aligned range: [1, 13]\n",
      "   ‚Ä¢ Aligned indices: [1, 2, 3, 4, 8, 9, 10, 11, 12, 13]\n",
      "   ‚Ä¢ Unaligned regions: [(5, 7)]\n",
      "\n",
      "‚úÖ Test 6 PASSED - LIS utilities work correctly\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 6: LIS (Longest Increasing Subsequence) Utilities\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not LIS_AVAILABLE:\n",
    "    test_results[\"Test 6\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 6 SKIPPED - lis library not available\")\n",
    "    print(\"   Install with: pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment.wfst.lis_utils import (\n",
    "            compute_lis,\n",
    "            remove_outliers,\n",
    "            remove_isolated_words,\n",
    "            find_unaligned_regions,\n",
    "        )\n",
    "        \n",
    "        # Test LIS computation\n",
    "        # Simulating word indices from multiple overlapping segments\n",
    "        word_indices = [1, 5, 2, 6, 3, 7, 4, 8, 9, 10, 11, 15, 12, 16, 13]\n",
    "        \n",
    "        print(f\"\\nüìà LIS computation:\")\n",
    "        print(f\"   ‚Ä¢ Input: {word_indices}\")\n",
    "        \n",
    "        lis_result = compute_lis(word_indices)\n",
    "        print(f\"   ‚Ä¢ LIS: {lis_result}\")\n",
    "        print(f\"   ‚Ä¢ LIS length: {len(lis_result)}\")\n",
    "        \n",
    "        # Verify LIS is increasing\n",
    "        is_increasing = all(lis_result[i] < lis_result[i+1] for i in range(len(lis_result)-1))\n",
    "        print(f\"   ‚Ä¢ Is strictly increasing: {'‚úÖ' if is_increasing else '‚ùå'}\")\n",
    "        \n",
    "        # Test outlier removal\n",
    "        print(f\"\\nüîç Outlier removal:\")\n",
    "        with_outliers = [5, 100, 10, 15, 20, 25, 30, 35, 200]\n",
    "        cleaned = remove_outliers(with_outliers, scan_range=3, outlier_threshold=50)\n",
    "        print(f\"   ‚Ä¢ Input: {with_outliers}\")\n",
    "        print(f\"   ‚Ä¢ Cleaned: {cleaned}\")\n",
    "        \n",
    "        # Test unaligned region detection\n",
    "        print(f\"\\nüï≥Ô∏è Unaligned region detection:\")\n",
    "        aligned = set(lis_result)\n",
    "        rg_min, rg_max = min(lis_result), max(lis_result)\n",
    "        unaligned = find_unaligned_regions(rg_min, rg_max, aligned)\n",
    "        print(f\"   ‚Ä¢ Aligned range: [{rg_min}, {rg_max}]\")\n",
    "        print(f\"   ‚Ä¢ Aligned indices: {sorted(aligned)}\")\n",
    "        print(f\"   ‚Ä¢ Unaligned regions: {unaligned}\")\n",
    "        \n",
    "        test_results[\"Test 6\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 6 PASSED - LIS utilities work correctly\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 6\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 6 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7: MFA Backend Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:alignment.mfa:MFA not found. Install with: conda install -c conda-forge montreal-forced-aligner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 7: MFA Backend Availability\n",
      "============================================================\n",
      "\n",
      "üîß MFA Aligner:\n",
      "   ‚Ä¢ Backend name: mfa\n",
      "   ‚Ä¢ Acoustic model: english_us_arpa\n",
      "   ‚Ä¢ Dictionary: english_us_arpa\n",
      "   ‚Ä¢ Supported languages (sample): ['english_us_arpa', 'english_uk_arpa', 'english_mfa', 'french_mfa', 'german_mfa']...\n",
      "\n",
      "‚ö†Ô∏è MFA CLI not installed (optional)\n",
      "   Install with: conda install -c conda-forge montreal-forced-aligner\n",
      "\n",
      "‚úÖ Test 7 PASSED - MFA backend class works\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 7: MFA Backend Availability\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import MFAAligner, AlignmentConfig\n",
    "    \n",
    "    config = AlignmentConfig(backend=\"mfa\", language=\"english_us_arpa\")\n",
    "    aligner = MFAAligner(config)\n",
    "    \n",
    "    print(f\"\\nüîß MFA Aligner:\")\n",
    "    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "    print(f\"   ‚Ä¢ Acoustic model: {aligner.acoustic_model}\")\n",
    "    print(f\"   ‚Ä¢ Dictionary: {aligner.dictionary}\")\n",
    "    print(f\"   ‚Ä¢ Supported languages (sample): {aligner.SUPPORTED_LANGUAGES[:5]}...\")\n",
    "    \n",
    "    # Check if MFA is available\n",
    "    mfa_available = aligner._check_mfa_available()\n",
    "    \n",
    "    if mfa_available:\n",
    "        print(f\"\\n‚úÖ MFA CLI is installed and available\")\n",
    "        test_results[\"Test 7\"] = \"‚úÖ PASSED\"\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è MFA CLI not installed (optional)\")\n",
    "        print(f\"   Install with: conda install -c conda-forge montreal-forced-aligner\")\n",
    "        test_results[\"Test 7\"] = \"‚ö†Ô∏è MFA NOT INSTALLED\"\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test 7 PASSED - MFA backend class works\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 7\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 7 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8: Gentle Backend Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 8: Gentle Backend Availability\n",
      "============================================================\n",
      "\n",
      "üîß Gentle Aligner:\n",
      "   ‚Ä¢ Backend name: gentle\n",
      "   ‚Ä¢ Server URL: http://localhost:8765\n",
      "   ‚Ä¢ Supported languages: ['eng', 'en', 'english']\n",
      "\n",
      "üì° Availability:\n",
      "   ‚Ä¢ Python API: ‚ùå not installed\n",
      "   ‚Ä¢ Server (localhost:8765): ‚ùå not running\n",
      "\n",
      "‚ö†Ô∏è Gentle not available (optional)\n",
      "   Install: git clone https://github.com/lowerquality/gentle && cd gentle && ./install.sh\n",
      "   Or start server: docker run -p 8765:8765 lowerquality/gentle\n",
      "\n",
      "‚úÖ Test 8 PASSED - Gentle backend class works\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 8: Gentle Backend Availability\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import GentleAligner, AlignmentConfig\n",
    "    \n",
    "    config = AlignmentConfig(backend=\"gentle\")\n",
    "    aligner = GentleAligner(config)\n",
    "    \n",
    "    print(f\"\\nüîß Gentle Aligner:\")\n",
    "    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "    print(f\"   ‚Ä¢ Server URL: {aligner.server_url}\")\n",
    "    print(f\"   ‚Ä¢ Supported languages: {aligner.SUPPORTED_LANGUAGES}\")\n",
    "    \n",
    "    # Check availability\n",
    "    python_available = aligner._check_gentle_python()\n",
    "    server_available = aligner._check_gentle_server()\n",
    "    \n",
    "    print(f\"\\nüì° Availability:\")\n",
    "    print(f\"   ‚Ä¢ Python API: {'‚úÖ' if python_available else '‚ùå not installed'}\")\n",
    "    print(f\"   ‚Ä¢ Server (localhost:8765): {'‚úÖ' if server_available else '‚ùå not running'}\")\n",
    "    \n",
    "    if python_available or server_available:\n",
    "        test_results[\"Test 8\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Gentle is available\")\n",
    "    else:\n",
    "        test_results[\"Test 8\"] = \"‚ö†Ô∏è GENTLE NOT INSTALLED\"\n",
    "        print(f\"\\n‚ö†Ô∏è Gentle not available (optional)\")\n",
    "        print(f\"   Install: git clone https://github.com/lowerquality/gentle && cd gentle && ./install.sh\")\n",
    "        print(f\"   Or start server: docker run -p 8765:8765 lowerquality/gentle\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test 8 PASSED - Gentle backend class works\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 8\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 8 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 10: Segment-wise Alignment (for stitching_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 10: Segment-wise Alignment (for stitching_utils)\n",
      "============================================================\n",
      "\n",
      "üìã SegmentAlignmentResult data class:\n",
      "   ‚Ä¢ Available: ‚úÖ\n",
      "   ‚Ä¢ Num tokens: 2\n",
      "   ‚Ä¢ Word indices: [0, 1]\n",
      "   ‚Ä¢ Rejected: False\n",
      "   ‚Ä¢ Score: 0.95\n",
      "\n",
      "üîß WFSTAligner.align_segments method:\n",
      "   ‚Ä¢ Method exists: ‚úÖ\n",
      "   ‚Ä¢ Parameters: ['waveform', 'text', 'kwargs']\n",
      "   ‚Ä¢ Returns: List[SegmentAlignmentResult]\n",
      "\n",
      "üîß WFSTAligner.align(stitch=False) option:\n",
      "   ‚Ä¢ 'stitch' parameter exists: ‚úÖ\n",
      "   ‚Ä¢ Default value: True\n",
      "\n",
      "üìù Usage with stitching_utils:\n",
      "   # Get segment-wise results\n",
      "   segment_results = aligner.align_segments(waveform, text)\n",
      "   \n",
      "   # Convert to stitching_utils format\n",
      "   from stitching_utils import SegmentAlignment, stitch_alignments\n",
      "   stitch_input = [\n",
      "       SegmentAlignment(\n",
      "           tokens=seg.tokens,\n",
      "           segment_index=seg.segment_index,\n",
      "           frame_offset=seg.frame_offset,\n",
      "           rejected=seg.rejected,\n",
      "       )\n",
      "       for seg in segment_results\n",
      "   ]\n",
      "   final = stitch_alignments(stitch_input, method='lis')\n",
      "\n",
      "‚úÖ Test 10 PASSED - Segment-wise alignment API ready\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 10: Segment-wise Alignment (for stitching_utils)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    missing = []\n",
    "    if not K2_AVAILABLE:\n",
    "        missing.append(\"k2\")\n",
    "    if not LIS_AVAILABLE:\n",
    "        missing.append(\"lis\")\n",
    "    test_results[\"Test 10\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(f\"‚è≠Ô∏è Test 10 SKIPPED - Missing dependencies: {', '.join(missing)}\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment import WFSTAligner, AlignmentConfig, SegmentAlignmentResult\n",
    "        \n",
    "        print(\"\\nüìã SegmentAlignmentResult data class:\")\n",
    "        print(f\"   ‚Ä¢ Available: ‚úÖ\")\n",
    "        \n",
    "        # Test SegmentAlignmentResult\n",
    "        from alignment.base import AlignedToken\n",
    "        test_tokens = [\n",
    "            AlignedToken(1, 10, 0.9, {\"wid\": 0}),\n",
    "            AlignedToken(2, 20, 0.85, {\"wid\": 1}),\n",
    "        ]\n",
    "        seg_result = SegmentAlignmentResult(\n",
    "            tokens=test_tokens,\n",
    "            segment_index=0,\n",
    "            frame_offset=0,\n",
    "            rejected=False,\n",
    "            score=0.95,\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Num tokens: {len(seg_result)}\")\n",
    "        print(f\"   ‚Ä¢ Word indices: {seg_result.get_word_indices()}\")\n",
    "        print(f\"   ‚Ä¢ Rejected: {seg_result.rejected}\")\n",
    "        print(f\"   ‚Ä¢ Score: {seg_result.score:.2f}\")\n",
    "        \n",
    "        # Test WFSTAligner.align_segments method exists\n",
    "        print(f\"\\nüîß WFSTAligner.align_segments method:\")\n",
    "        config = AlignmentConfig(\n",
    "            backend=\"wfst\",\n",
    "            segment_size=15.0,\n",
    "            overlap=2.0,\n",
    "        )\n",
    "        aligner = WFSTAligner(config)\n",
    "        \n",
    "        has_align_segments = hasattr(aligner, 'align_segments')\n",
    "        print(f\"   ‚Ä¢ Method exists: {'‚úÖ' if has_align_segments else '‚ùå'}\")\n",
    "        \n",
    "        if has_align_segments:\n",
    "            import inspect\n",
    "            sig = inspect.signature(aligner.align_segments)\n",
    "            params = list(sig.parameters.keys())\n",
    "            print(f\"   ‚Ä¢ Parameters: {params}\")\n",
    "            print(f\"   ‚Ä¢ Returns: List[SegmentAlignmentResult]\")\n",
    "        \n",
    "        # Test align() with stitch=False option\n",
    "        print(f\"\\nüîß WFSTAligner.align(stitch=False) option:\")\n",
    "        sig = inspect.signature(aligner.align)\n",
    "        params = dict(sig.parameters)\n",
    "        has_stitch_param = 'stitch' in params\n",
    "        print(f\"   ‚Ä¢ 'stitch' parameter exists: {'‚úÖ' if has_stitch_param else '‚ùå'}\")\n",
    "        if has_stitch_param:\n",
    "            default = params['stitch'].default\n",
    "            print(f\"   ‚Ä¢ Default value: {default}\")\n",
    "        \n",
    "        # Show usage example\n",
    "        print(f\"\\nüìù Usage with stitching_utils:\")\n",
    "        print(f\"   # Get segment-wise results\")\n",
    "        print(f\"   segment_results = aligner.align_segments(waveform, text)\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Convert to stitching_utils format\")\n",
    "        print(f\"   from stitching_utils import SegmentAlignment, stitch_alignments\")\n",
    "        print(f\"   stitch_input = [\")\n",
    "        print(f\"       SegmentAlignment(\")\n",
    "        print(f\"           tokens=seg.tokens,\")\n",
    "        print(f\"           segment_index=seg.segment_index,\")\n",
    "        print(f\"           frame_offset=seg.frame_offset,\")\n",
    "        print(f\"           rejected=seg.rejected,\")\n",
    "        print(f\"       )\")\n",
    "        print(f\"       for seg in segment_results\")\n",
    "        print(f\"   ]\")\n",
    "        print(f\"   final = stitch_alignments(stitch_input, method='lis')\")\n",
    "        \n",
    "        test_results[\"Test 10\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 10 PASSED - Segment-wise alignment API ready\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 10\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 10 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 9: WFST Aligner Integration\n",
      "============================================================\n",
      "\n",
      "üîß WFST Aligner:\n",
      "   ‚Ä¢ Backend name: wfst\n",
      "   ‚Ä¢ Config segment_size: 15.0s\n",
      "   ‚Ä¢ Config skip_penalty: -0.5\n",
      "\n",
      "üìù To use WFST aligner:\n",
      "   from labeling_utils import load_model\n",
      "   from alignment import align\n",
      "   \n",
      "   model = load_model('mms-fa')\n",
      "   result = align(waveform, text, model_backend=model)\n",
      "   \n",
      "   for idx, word in result.word_alignments.items():\n",
      "       print(f'{word.word}: {word.start_seconds:.2f}s')\n",
      "\n",
      "‚úÖ Test 9 PASSED - WFST Aligner class works\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 9: WFST Aligner Integration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    missing = []\n",
    "    if not K2_AVAILABLE:\n",
    "        missing.append(\"k2\")\n",
    "    if not LIS_AVAILABLE:\n",
    "        missing.append(\"lis\")\n",
    "    test_results[\"Test 9\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(f\"‚è≠Ô∏è Test 9 SKIPPED - Missing dependencies: {', '.join(missing)}\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment import WFSTAligner, AlignmentConfig\n",
    "        \n",
    "        config = AlignmentConfig(\n",
    "            backend=\"wfst\",\n",
    "            segment_size=15.0,\n",
    "            overlap=2.0,\n",
    "            skip_penalty=-0.5,\n",
    "            return_penalty=-18.0,\n",
    "        )\n",
    "        \n",
    "        aligner = WFSTAligner(config)\n",
    "        \n",
    "        print(f\"\\nüîß WFST Aligner:\")\n",
    "        print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "        print(f\"   ‚Ä¢ Config segment_size: {config.segment_size}s\")\n",
    "        print(f\"   ‚Ä¢ Config skip_penalty: {config.skip_penalty}\")\n",
    "        \n",
    "        print(f\"\\nüìù To use WFST aligner:\")\n",
    "        print(f\"   from labeling_utils import load_model\")\n",
    "        print(f\"   from alignment import align\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   model = load_model('mms-fa')\")\n",
    "        print(f\"   result = align(waveform, text, model_backend=model)\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   for idx, word in result.word_alignments.items():\")\n",
    "        print(f\"       print(f'{{word.word}}: {{word.start_seconds:.2f}}s')\")\n",
    "        \n",
    "        test_results[\"Test 9\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 9 PASSED - WFST Aligner class works\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 9\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 9 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìã TEST RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "  ‚úÖ PASSED  Test 1\n",
      "  ‚úÖ PASSED  Test 2\n",
      "  ‚úÖ PASSED  Test 3\n",
      "  ‚úÖ PASSED  Test 4\n",
      "  ‚úÖ PASSED  Test 5\n",
      "  ‚úÖ PASSED  Test 6\n",
      "  ‚ö†Ô∏è MFA NOT INSTALLED  Test 7\n",
      "  ‚ö†Ô∏è GENTLE NOT INSTALLED  Test 8\n",
      "  ‚úÖ PASSED  Test 10\n",
      "  ‚úÖ PASSED  Test 9\n",
      "----------------------------------------\n",
      "\n",
      "  Total: 10 tests\n",
      "  ‚úÖ Passed:  8\n",
      "  ‚ö†Ô∏è Warning: 2\n",
      "\n",
      "============================================================\n",
      "üéâ All tests passed (or skipped due to optional dependencies)!\n",
      "============================================================\n",
      "\n",
      "üì¶ To enable all tests, install:\n",
      "   pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\n",
      "   pip install git+https://github.com/huangruizhe/lis.git\n",
      "\n",
      "üèóÔ∏è Architecture note:\n",
      "   The alignment module uses unified frontends:\n",
      "   ‚Ä¢ text_frontend: TokenizerInterface, CharTokenizer, create_tokenizer_from_labels\n",
      "   ‚Ä¢ audio_frontend: segment_waveform, AudioSegment, SegmentationResult\n",
      "   This eliminates duplicate code and provides a consistent API.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üìã TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display test results\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "for test_name, result in test_results.items():\n",
    "    print(f\"  {result}  {test_name}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Count results\n",
    "passed = sum(1 for r in test_results.values() if \"‚úÖ\" in r)\n",
    "failed = sum(1 for r in test_results.values() if \"‚ùå\" in r)\n",
    "skipped = sum(1 for r in test_results.values() if \"‚è≠Ô∏è\" in r)\n",
    "warning = sum(1 for r in test_results.values() if \"‚ö†Ô∏è\" in r)\n",
    "total = len(test_results)\n",
    "\n",
    "print(f\"\\n  Total: {total} tests\")\n",
    "print(f\"  ‚úÖ Passed:  {passed}\")\n",
    "if warning > 0:\n",
    "    print(f\"  ‚ö†Ô∏è Warning: {warning}\")\n",
    "if skipped > 0:\n",
    "    print(f\"  ‚è≠Ô∏è Skipped: {skipped}\")\n",
    "if failed > 0:\n",
    "    print(f\"  ‚ùå Failed:  {failed}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if failed == 0:\n",
    "    print(\"üéâ All tests passed (or skipped due to optional dependencies)!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {failed} test(s) failed - please check above for details\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüì¶ To enable all tests, install:\")\n",
    "print(\"   pip install k2 -f https://k2-fsa.github.io/k2/cpu.html\")\n",
    "print(\"   pip install git+https://github.com/huangruizhe/lis.git\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Architecture note:\")\n",
    "print(\"   The alignment module uses unified frontends:\")\n",
    "print(\"   ‚Ä¢ text_frontend: TokenizerInterface, CharTokenizer, create_tokenizer_from_labels\")\n",
    "print(\"   ‚Ä¢ audio_frontend: segment_waveform, AudioSegment, SegmentationResult\")\n",
    "print(\"   This eliminates duplicate code and provides a consistent API.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 16: Gentle Aligner Test\n",
      "============================================================\n",
      "\n",
      "üîß Gentle Aligner Configuration:\n",
      "   ‚Ä¢ Backend name: gentle\n",
      "   ‚Ä¢ Server URL: http://localhost:8765\n",
      "   ‚Ä¢ Supported languages: ['eng', 'en', 'english']\n",
      "\n",
      "üì° Availability:\n",
      "   ‚Ä¢ Python API: ‚ùå\n",
      "   ‚Ä¢ Server (http://localhost:8765): ‚ùå\n",
      "\n",
      "üì¶ To install Gentle:\n",
      "   # Option 1: Python API\n",
      "   pip install gentle\n",
      "   # Or clone and build:\n",
      "   git clone https://github.com/lowerquality/gentle && cd gentle && ./install.sh\n",
      "\n",
      "   # Option 2: Docker (server mode)\n",
      "   docker run -p 8765:8765 lowerquality/gentle\n",
      "\n",
      "   # Option 3: Colab (pip install)\n",
      "   !pip install gentle\n",
      "\n",
      "‚úÖ Test 16 Complete - Gentle Aligner class verified\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 16: Gentle Aligner Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import GentleAligner, AlignmentConfig\n",
    "    \n",
    "    print(\"\\nüîß Gentle Aligner Configuration:\")\n",
    "    config = AlignmentConfig(backend=\"gentle\")\n",
    "    aligner = GentleAligner(config)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "    print(f\"   ‚Ä¢ Server URL: {aligner.server_url}\")\n",
    "    print(f\"   ‚Ä¢ Supported languages: {aligner.SUPPORTED_LANGUAGES}\")\n",
    "    \n",
    "    # Check availability\n",
    "    python_available = aligner._check_gentle_python()\n",
    "    server_available = aligner._check_gentle_server()\n",
    "    \n",
    "    print(f\"\\nüì° Availability:\")\n",
    "    print(f\"   ‚Ä¢ Python API: {'‚úÖ' if python_available else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Server ({aligner.server_url}): {'‚úÖ' if server_available else '‚ùå'}\")\n",
    "    \n",
    "    if python_available or server_available:\n",
    "        # Try to run alignment on sample audio\n",
    "        print(\"\\nüîÑ Running Gentle alignment on sample audio...\")\n",
    "        \n",
    "        try:\n",
    "            # Load sample audio (reuse from Test 12)\n",
    "            if 'waveform' in dir() and 'TRANSCRIPT' in dir():\n",
    "                # Use 4 threads for parallelization\n",
    "                result = aligner.align(waveform.squeeze(0), TRANSCRIPT, nthreads=4)\n",
    "                \n",
    "                print(f\"\\nüìä Gentle Alignment Results:\")\n",
    "                print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n",
    "                print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n",
    "                print(f\"   ‚Ä¢ Backend: {result.metadata.get('backend', 'N/A')}\")\n",
    "                \n",
    "                if result.word_alignments:\n",
    "                    print(\"\\nüìù Word-level results:\")\n",
    "                    for idx, word in sorted(result.word_alignments.items())[:5]:\n",
    "                        end_str = f\"{word.end_time}\" if word.end_time else \"?\"\n",
    "                        print(f\"   [{idx}] {word.word}: {word.start_time} - {end_str}\")\n",
    "                    if len(result.word_alignments) > 5:\n",
    "                        print(f\"   ... and {len(result.word_alignments) - 5} more\")\n",
    "                \n",
    "                test_results[\"Test 16\"] = \"‚úÖ PASSED\"\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Sample audio not available (run Test 12 first)\")\n",
    "                test_results[\"Test 16\"] = \"‚ö†Ô∏è SKIPPED (no audio)\"\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Alignment failed: {e}\")\n",
    "            test_results[\"Test 16\"] = f\"‚ùå FAILED: {e}\"\n",
    "    else:\n",
    "        print(\"\\nüì¶ To install Gentle:\")\n",
    "        print(\"   # Option 1: Python API\")\n",
    "        print(\"   pip install gentle\")\n",
    "        print(\"   # Or clone and build:\")\n",
    "        print(\"   git clone https://github.com/lowerquality/gentle && cd gentle && ./install.sh\")\n",
    "        print(\"\")\n",
    "        print(\"   # Option 2: Docker (server mode)\")\n",
    "        print(\"   docker run -p 8765:8765 lowerquality/gentle\")\n",
    "        print(\"\")\n",
    "        print(\"   # Option 3: Colab (pip install)\")\n",
    "        print(\"   !pip install gentle\")\n",
    "        test_results[\"Test 16\"] = \"‚ö†Ô∏è GENTLE NOT INSTALLED\"\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test 16 Complete - Gentle Aligner class verified\")\n",
    "    \n",
    "except Exception as e:\n",
    "    test_results[\"Test 16\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 16 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 16: Gentle Aligner Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:alignment.mfa:MFA not found. Install with: conda install -c conda-forge montreal-forced-aligner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 15: MFA Aligner Test\n",
      "============================================================\n",
      "\n",
      "üîß MFA Aligner Configuration:\n",
      "   ‚Ä¢ Backend name: mfa\n",
      "   ‚Ä¢ Acoustic model: english_us_arpa\n",
      "   ‚Ä¢ Dictionary: english_us_arpa\n",
      "\n",
      "üì° MFA CLI available: ‚ùå\n",
      "\n",
      "üì¶ To install MFA:\n",
      "   conda install -c conda-forge montreal-forced-aligner\n",
      "   # Or: pip install montreal-forced-aligner\n",
      "\n",
      "‚úÖ Test 15 Complete - MFA Aligner class verified\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 15: MFA Aligner Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import MFAAligner, AlignmentConfig\n",
    "    \n",
    "    print(\"\\nüîß MFA Aligner Configuration:\")\n",
    "    config = AlignmentConfig(backend=\"mfa\", language=\"english_us_arpa\")\n",
    "    aligner = MFAAligner(config)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Backend name: {aligner.name}\")\n",
    "    print(f\"   ‚Ä¢ Acoustic model: {aligner.acoustic_model}\")\n",
    "    print(f\"   ‚Ä¢ Dictionary: {aligner.dictionary}\")\n",
    "    \n",
    "    # Check if MFA is available\n",
    "    mfa_available = aligner._check_mfa_available()\n",
    "    print(f\"\\nüì° MFA CLI available: {'‚úÖ' if mfa_available else '‚ùå'}\")\n",
    "    \n",
    "    if mfa_available:\n",
    "        # Try to run alignment on sample audio\n",
    "        print(\"\\nüîÑ Running MFA alignment on sample audio...\")\n",
    "        \n",
    "        try:\n",
    "            # Load sample audio (reuse from Test 12)\n",
    "            if 'waveform' in dir() and 'TRANSCRIPT' in dir():\n",
    "                result = aligner.align(waveform.squeeze(0), TRANSCRIPT)\n",
    "                \n",
    "                print(f\"\\nüìä MFA Alignment Results:\")\n",
    "                print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n",
    "                print(f\"   ‚Ä¢ Backend: {result.metadata.get('backend', 'N/A')}\")\n",
    "                \n",
    "                if result.word_alignments:\n",
    "                    print(\"\\nüìù Word-level results:\")\n",
    "                    for idx, word in sorted(result.word_alignments.items())[:5]:\n",
    "                        print(f\"   [{idx}] {word.word}: {word.start_time} - {word.end_time}\")\n",
    "                    if len(result.word_alignments) > 5:\n",
    "                        print(f\"   ... and {len(result.word_alignments) - 5} more\")\n",
    "                \n",
    "                test_results[\"Test 15\"] = \"‚úÖ PASSED\"\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Sample audio not available (run Test 12 first)\")\n",
    "                test_results[\"Test 15\"] = \"‚ö†Ô∏è SKIPPED (no audio)\"\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Alignment failed: {e}\")\n",
    "            test_results[\"Test 15\"] = f\"‚ùå FAILED: {e}\"\n",
    "    else:\n",
    "        print(\"\\nüì¶ To install MFA:\")\n",
    "        print(\"   conda install -c conda-forge montreal-forced-aligner\")\n",
    "        print(\"   # Or: pip install montreal-forced-aligner\")\n",
    "        test_results[\"Test 15\"] = \"‚ö†Ô∏è MFA NOT INSTALLED\"\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test 15 Complete - MFA Aligner class verified\")\n",
    "    \n",
    "except Exception as e:\n",
    "    test_results[\"Test 15\"] = \"‚ùå FAILED\"\n",
    "    print(f\"\\n‚ùå Test 15 FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 15: MFA Aligner Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≠Ô∏è Alignment not available - run Test 12 first\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# Interactive: Listen to all aligned words\n",
    "# =================================================================\n",
    "# Run this cell to hear each aligned word with audio players\n",
    "\n",
    "if \"Test 12\" in test_results and \"PASSED\" in test_results.get(\"Test 12\", \"\"):\n",
    "    print(\"üéß Listen to each aligned word:\")\n",
    "    print(\"-\" * 40)\n",
    "    preview_all_words()\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Alignment not available - run Test 12 first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive: Listen to All Aligned Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 14: Listening Test (Audio Preview)\n",
      "============================================================\n",
      "‚è≠Ô∏è Test 14 SKIPPED - Test 12 (alignment) did not pass\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 14: Listening Test (Audio Preview)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if Test 12 didn't run\n",
    "if \"Test 12\" not in test_results or \"PASSED\" not in test_results.get(\"Test 12\", \"\"):\n",
    "    test_results[\"Test 14\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 14 SKIPPED - Test 12 (alignment) did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        from IPython.display import Audio, display, HTML\n",
    "        \n",
    "        print(\"\\nüéß Audio Preview Functions\")\n",
    "        print(\"   Following torchaudio's forced_alignment_tutorial.py pattern\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # Audio Preview Functions\n",
    "        # =================================================================\n",
    "        \n",
    "        # Ratio to convert frames to samples\n",
    "        # Frame rate: 50fps, Sample rate: 16000\n",
    "        # Samples per frame = 16000 / 50 = 320\n",
    "        SAMPLES_PER_FRAME = sr // FRAME_RATE\n",
    "        \n",
    "        def preview_word(word_idx, padding_frames=2):\n",
    "            \"\"\"\n",
    "            Preview audio for an aligned word.\n",
    "            \n",
    "            Args:\n",
    "                word_idx: Index of the word in aligned_words\n",
    "                padding_frames: Extra frames to add before/after\n",
    "            \n",
    "            Returns:\n",
    "                IPython.display.Audio widget\n",
    "            \"\"\"\n",
    "            if word_idx not in aligned_words:\n",
    "                print(f\"Word index {word_idx} not found in alignment\")\n",
    "                return None\n",
    "            \n",
    "            word = aligned_words[word_idx]\n",
    "            start_frame = word.start_time - padding_frames\n",
    "            end_frame = (word.end_time if word.end_time else word.start_time + 20) + padding_frames\n",
    "            \n",
    "            start_frame = max(0, start_frame)\n",
    "            \n",
    "            x0 = int(start_frame * SAMPLES_PER_FRAME)\n",
    "            x1 = int(end_frame * SAMPLES_PER_FRAME)\n",
    "            x1 = min(x1, waveform.size(1))\n",
    "            \n",
    "            start_sec = x0 / sr\n",
    "            end_sec = x1 / sr\n",
    "            \n",
    "            print(f\"üîä {word.word} ({word_idx}): [{start_sec:.3f}s - {end_sec:.3f}s]\")\n",
    "            \n",
    "            segment = waveform[:, x0:x1]\n",
    "            return Audio(segment.numpy(), rate=sr)\n",
    "        \n",
    "        def preview_word_by_name(word_name, padding_frames=2):\n",
    "            \"\"\"Preview audio for a word by its text.\"\"\"\n",
    "            for idx, word in aligned_words.items():\n",
    "                if word.word and word.word.upper() == word_name.upper():\n",
    "                    return preview_word(idx, padding_frames)\n",
    "            print(f\"Word '{word_name}' not found\")\n",
    "            return None\n",
    "        \n",
    "        def preview_all_words():\n",
    "            \"\"\"Display all aligned words with audio players.\"\"\"\n",
    "            for idx in sorted(aligned_words.keys()):\n",
    "                word = aligned_words[idx]\n",
    "                if word.word:\n",
    "                    display(HTML(f\"<b>{word.word}</b>\"))\n",
    "                    display(preview_word(idx))\n",
    "        \n",
    "        # =================================================================\n",
    "        # Preview Individual Words\n",
    "        # =================================================================\n",
    "        print(\"\\nüìù Preview individual aligned words:\")\n",
    "        print(\"   Run: preview_word(0) or preview_word_by_name('CURIOSITY')\")\n",
    "        \n",
    "        # Show first word\n",
    "        print(\"\\nüîä First word preview:\")\n",
    "        if aligned_words:\n",
    "            first_idx = min(aligned_words.keys())\n",
    "            display(preview_word(first_idx))\n",
    "        \n",
    "        # Show a longer word\n",
    "        print(\"\\nüîä 'CURIOSITY' preview:\")\n",
    "        display(preview_word_by_name(\"CURIOSITY\"))\n",
    "        \n",
    "        test_results[\"Test 14\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 14 PASSED - Audio preview functions available\")\n",
    "        print(\"\\nüí° To listen to all words, run: preview_all_words()\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 14\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 14 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 14: Listening Test (Audio Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 13: Alignment Accuracy Comparison\n",
      "============================================================\n",
      "‚è≠Ô∏è Test 13 SKIPPED - Test 12 (alignment) did not pass\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 13: Alignment Accuracy Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if Test 12 didn't run\n",
    "if \"Test 12\" not in test_results or \"PASSED\" not in test_results.get(\"Test 12\", \"\"):\n",
    "    test_results[\"Test 13\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 13 SKIPPED - Test 12 (alignment) did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"\\nüìä Comparing alignment results to ground truth...\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # Compute Accuracy Metrics\n",
    "        # =================================================================\n",
    "        \n",
    "        def compute_frame_error(pred_start, pred_end, gt_start, gt_end):\n",
    "            \"\"\"Compute frame-level error between prediction and ground truth.\"\"\"\n",
    "            start_error = abs(pred_start - gt_start)\n",
    "            end_error = abs(pred_end - gt_end) if pred_end and gt_end else 0\n",
    "            return start_error, end_error\n",
    "        \n",
    "        def compute_iou(pred_start, pred_end, gt_start, gt_end):\n",
    "            \"\"\"Compute Intersection over Union for alignment boundaries.\"\"\"\n",
    "            if pred_end is None:\n",
    "                pred_end = pred_start + 10  # Estimate\n",
    "            \n",
    "            intersection_start = max(pred_start, gt_start)\n",
    "            intersection_end = min(pred_end, gt_end)\n",
    "            intersection = max(0, intersection_end - intersection_start)\n",
    "            \n",
    "            union_start = min(pred_start, gt_start)\n",
    "            union_end = max(pred_end, gt_end)\n",
    "            union = union_end - union_start\n",
    "            \n",
    "            return intersection / union if union > 0 else 0\n",
    "        \n",
    "        print(\"\\nüìù Word-by-word comparison:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Word':<12} {'GT Start':<10} {'Pred Start':<12} {'Œî Start':<10} {'IoU':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        total_start_error = 0\n",
    "        total_iou = 0\n",
    "        matched_words = 0\n",
    "        \n",
    "        for gt_word in GROUND_TRUTH_WORDS:\n",
    "            word = gt_word[\"word\"]\n",
    "            gt_start = gt_word[\"start\"]\n",
    "            gt_end = gt_word[\"end\"]\n",
    "            \n",
    "            # Find matching word in predictions\n",
    "            pred_word = None\n",
    "            for idx, aligned in aligned_words.items():\n",
    "                if aligned.word and aligned.word.upper() == word.upper():\n",
    "                    pred_word = aligned\n",
    "                    break\n",
    "            \n",
    "            if pred_word:\n",
    "                pred_start = pred_word.start_time\n",
    "                pred_end = pred_word.end_time if pred_word.end_time else pred_start + (gt_end - gt_start)\n",
    "                \n",
    "                start_err, end_err = compute_frame_error(pred_start, pred_end, gt_start, gt_end)\n",
    "                iou = compute_iou(pred_start, pred_end, gt_start, gt_end)\n",
    "                \n",
    "                total_start_error += start_err\n",
    "                total_iou += iou\n",
    "                matched_words += 1\n",
    "                \n",
    "                status = \"‚úÖ\" if start_err <= 5 else (\"‚ö†Ô∏è\" if start_err <= 10 else \"‚ùå\")\n",
    "                print(f\"{word:<12} {gt_start:<10} {pred_start:<12} {start_err:<10} {iou:.2f}     {status}\")\n",
    "            else:\n",
    "                print(f\"{word:<12} {gt_start:<10} {'N/A':<12} {'N/A':<10} {'N/A':<8} ‚ùå\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # =================================================================\n",
    "        # Summary Statistics\n",
    "        # =================================================================\n",
    "        if matched_words > 0:\n",
    "            avg_start_error = total_start_error / matched_words\n",
    "            avg_iou = total_iou / matched_words\n",
    "            \n",
    "            print(f\"\\nüìà Accuracy Summary:\")\n",
    "            print(f\"   ‚Ä¢ Matched words: {matched_words}/{len(GROUND_TRUTH_WORDS)}\")\n",
    "            print(f\"   ‚Ä¢ Avg start frame error: {avg_start_error:.1f} frames ({avg_start_error * 20:.0f}ms)\")\n",
    "            print(f\"   ‚Ä¢ Avg IoU: {avg_iou:.2%}\")\n",
    "            \n",
    "            # Thresholds for pass/fail\n",
    "            if avg_start_error <= 5 and avg_iou >= 0.7:\n",
    "                print(f\"\\n‚úÖ Alignment accuracy: EXCELLENT\")\n",
    "            elif avg_start_error <= 10 and avg_iou >= 0.5:\n",
    "                print(f\"\\n‚ö†Ô∏è Alignment accuracy: ACCEPTABLE\")\n",
    "            else:\n",
    "                print(f\"\\n‚ùå Alignment accuracy: NEEDS IMPROVEMENT\")\n",
    "        \n",
    "        test_results[\"Test 13\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 13 PASSED - Accuracy comparison complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 13\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 13 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "print(\"=\" * 60)\nprint(\"Test 12: Run WFST Alignment on Sample Audio\")\nprint(\"=\" * 60)\n\n# Skip if dependencies not available\nif not K2_AVAILABLE or not LIS_AVAILABLE:\n    missing = []\n    if not K2_AVAILABLE:\n        missing.append(\"k2\")\n    if not LIS_AVAILABLE:\n        missing.append(\"lis\")\n    test_results[\"Test 12\"] = \"‚è≠Ô∏è SKIPPED\"\n    print(f\"‚è≠Ô∏è Test 12 SKIPPED - Missing dependencies: {', '.join(missing)}\")\nelse:\n    try:\n        import torchaudio\n        from alignment import WFSTAligner, AlignmentConfig, SegmentAlignmentResult\n        \n        # =================================================================\n        # Load Sample Audio\n        # =================================================================\n        # We need a sample audio file. Try to download or use existing.\n        \n        print(\"\\nüéµ Loading sample audio...\")\n        \n        # Option 1: Use torchaudio's built-in sample (LibriSpeech)\n        try:\n            # Try to load from examples folder first\n            example_path = \"../examples/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n            waveform, sr = torchaudio.load(example_path)\n            print(f\"   ‚Ä¢ Loaded from: {example_path}\")\n        except:\n            # Download LibriSpeech sample\n            SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n            print(f\"   ‚Ä¢ Downloading sample audio...\")\n            waveform, sr = torchaudio.load(SPEECH_URL)\n            print(f\"   ‚Ä¢ Downloaded from PyTorch assets\")\n        \n        # Resample if needed\n        if sr != 16000:\n            waveform = torchaudio.functional.resample(waveform, sr, 16000)\n            sr = 16000\n        \n        # Use only first channel if stereo\n        if waveform.size(0) > 1:\n            waveform = waveform[0:1]\n        \n        duration_sec = waveform.size(1) / sr\n        print(f\"   ‚Ä¢ Sample rate: {sr}\")\n        print(f\"   ‚Ä¢ Shape: {waveform.shape}\")\n        print(f\"   ‚Ä¢ Duration: {duration_sec:.2f}s\")\n        \n        # The transcript for this sample\n        # Note: This is a short sample, so we're using a short transcript\n        # that matches approximately (you may need to adjust based on actual content)\n        \n        # For this VOiCES sample, the transcript is:\n        # \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n        \n        print(f\"\\nüìù Transcript: '{TRANSCRIPT}'\")\n        \n        # =================================================================\n        # Load MMS-FA Model\n        # =================================================================\n        print(\"\\nüîß Loading MMS-FA model...\")\n        \n        try:\n            from labeling_utils import load_model\n            model = load_model(\"mms-fa\")\n            print(\"   ‚Ä¢ Model loaded: mms-fa\")\n        except ImportError:\n            print(\"   ‚ö†Ô∏è labeling_utils not available\")\n            print(\"   Trying torchaudio bundle directly...\")\n            \n            # Fallback: use torchaudio bundle directly\n            bundle = torchaudio.pipelines.MMS_FA\n            model = bundle.get_model()\n            model = model.to(\"cpu\")\n            \n            # Create a mock model backend\n            class MockModelBackend:\n                def __init__(self, model, bundle):\n                    self._model = model\n                    self._bundle = bundle\n                    \n                def get_emissions(self, waveforms, lengths):\n                    with torch.inference_mode():\n                        emissions, emission_lengths = self._model(waveforms.squeeze(-1))\n                    return emissions, emission_lengths\n                \n                def get_vocab_info(self):\n                    class VocabInfo:\n                        labels = tuple(bundle.get_labels())\n                        blank_token = '-'\n                        unk_token = '*'\n                        blank_id = labels.index(blank_token) if blank_token in labels else 0\n                        unk_id = labels.index(unk_token) if unk_token in labels else None\n                    return VocabInfo()\n            \n            model = MockModelBackend(model, bundle)\n            print(\"   ‚Ä¢ Model loaded: torchaudio MMS_FA bundle\")\n        \n        # =================================================================\n        # Run WFST Alignment\n        # =================================================================\n        print(\"\\nüîß Running WFST alignment...\")\n        \n        config = AlignmentConfig(\n            backend=\"wfst\",\n            segment_size=15.0,  # Short segment for this test\n            overlap=2.0,\n            skip_penalty=-0.5,\n            return_penalty=-18.0,\n        )\n        \n        aligner = WFSTAligner(config)\n        aligner.set_model(model)\n        \n        # Run alignment\n        result = aligner.align(waveform.squeeze(0), TRANSCRIPT)\n        \n        print(f\"\\nüìä Alignment Results:\")\n        print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n        print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n        \n        # Store for comparison\n        aligned_words = result.word_alignments\n        \n        print(f\"\\nüìù Word-level alignment results:\")\n        for idx, word in sorted(aligned_words.items()):\n            start_frame = int(word.start_time)\n            end_frame = int(word.end_time) if word.end_time else start_frame + 10\n            start_sec = start_frame / FRAME_RATE\n            end_sec = end_frame / FRAME_RATE if word.end_time else \"?\"\n            print(f\"   [{idx:2d}] {word.word:12s}: frame [{start_frame:4d}, {end_frame:4d}) = [{start_sec:.2f}s, {end_sec}s)\")\n        \n        test_results[\"Test 12\"] = \"‚úÖ PASSED\"\n        print(f\"\\n‚úÖ Test 12 PASSED - WFST alignment completed\")\n        \n    except Exception as e:\n        test_results[\"Test 12\"] = \"‚ùå FAILED\"\n        print(f\"\\n‚ùå Test 12 FAILED: {e}\")\n        import traceback\n        traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 12: Run WFST Alignment on Sample Audio\n",
      "============================================================\n",
      "\n",
      "üéµ Loading sample audio...\n",
      "   ‚Ä¢ Downloading sample audio...\n",
      "   ‚Ä¢ Downloaded from PyTorch assets\n",
      "   ‚Ä¢ Sample rate: 16000\n",
      "   ‚Ä¢ Shape: torch.Size([1, 54400])\n",
      "   ‚Ä¢ Duration: 3.40s\n",
      "\n",
      "‚ùå Test 12 FAILED: name 'TRANSCRIPT' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-3960940537.py\", line 60, in <cell line: 0>\n",
      "    print(f\"\\nüìù Transcript: '{TRANSCRIPT}'\")\n",
      "                               ^^^^^^^^^^\n",
      "NameError: name 'TRANSCRIPT' is not defined\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 12: Run WFST Alignment on Sample Audio\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if dependencies not available\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    missing = []\n",
    "    if not K2_AVAILABLE:\n",
    "        missing.append(\"k2\")\n",
    "    if not LIS_AVAILABLE:\n",
    "        missing.append(\"lis\")\n",
    "    test_results[\"Test 12\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(f\"‚è≠Ô∏è Test 12 SKIPPED - Missing dependencies: {', '.join(missing)}\")\n",
    "else:\n",
    "    try:\n",
    "        import torchaudio\n",
    "        from alignment import WFSTAligner, AlignmentConfig, SegmentAlignmentResult\n",
    "        \n",
    "        # =================================================================\n",
    "        # Load Sample Audio\n",
    "        # =================================================================\n",
    "        # We need a sample audio file. Try to download or use existing.\n",
    "        \n",
    "        print(\"\\nüéµ Loading sample audio...\")\n",
    "        \n",
    "        # Option 1: Use torchaudio's built-in sample (LibriSpeech)\n",
    "        try:\n",
    "            # Try to load from examples folder first\n",
    "            example_path = \"../examples/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "            waveform, sr = torchaudio.load(example_path)\n",
    "            print(f\"   ‚Ä¢ Loaded from: {example_path}\")\n",
    "        except:\n",
    "            # Download LibriSpeech sample\n",
    "            SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "            print(f\"   ‚Ä¢ Downloading sample audio...\")\n",
    "            waveform, sr = torchaudio.load(SPEECH_URL)\n",
    "            print(f\"   ‚Ä¢ Downloaded from PyTorch assets\")\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "            sr = 16000\n",
    "        \n",
    "        # Use only first channel if stereo\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform[0:1]\n",
    "        \n",
    "        duration_sec = waveform.size(1) / sr\n",
    "        print(f\"   ‚Ä¢ Sample rate: {sr}\")\n",
    "        print(f\"   ‚Ä¢ Shape: {waveform.shape}\")\n",
    "        print(f\"   ‚Ä¢ Duration: {duration_sec:.2f}s\")\n",
    "        \n",
    "        # The transcript for this sample\n",
    "        # Note: This is a short sample, so we're using a short transcript\n",
    "        # that matches approximately (you may need to adjust based on actual content)\n",
    "        \n",
    "        # For this VOiCES sample, the transcript is:\n",
    "        # \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        TRANSCRIPT = \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        \n",
    "        print(f\"\\nüìù Transcript: '{TRANSCRIPT}'\")\n",
    "\n",
    "        FRAME_RATE = 16000\n",
    "        \n",
    "        # =================================================================\n",
    "        # Load MMS-FA Model\n",
    "        # =================================================================\n",
    "        print(\"\\nüîß Loading MMS-FA model...\")\n",
    "        \n",
    "        try:\n",
    "            from labeling_utils import load_model\n",
    "            model = load_model(\"mms-fa\")\n",
    "            print(\"   ‚Ä¢ Model loaded: mms-fa\")\n",
    "        except ImportError:\n",
    "            print(\"   ‚ö†Ô∏è labeling_utils not available\")\n",
    "            print(\"   Trying torchaudio bundle directly...\")\n",
    "            \n",
    "            # Fallback: use torchaudio bundle directly\n",
    "            bundle = torchaudio.pipelines.MMS_FA\n",
    "            model = bundle.get_model()\n",
    "            model = model.to(\"cpu\")\n",
    "            \n",
    "            # Create a mock model backend\n",
    "            class MockModelBackend:\n",
    "                def __init__(self, model, bundle):\n",
    "                    self._model = model\n",
    "                    self._bundle = bundle\n",
    "                    \n",
    "                def get_emissions(self, waveforms, lengths):\n",
    "                    with torch.inference_mode():\n",
    "                        emissions, emission_lengths = self._model(waveforms.squeeze(-1))\n",
    "                    return emissions, emission_lengths\n",
    "                \n",
    "                def get_vocab_info(self):\n",
    "                    class VocabInfo:\n",
    "                        labels = tuple(bundle.get_labels())\n",
    "                        blank_token = '-'\n",
    "                        unk_token = '*'\n",
    "                        blank_id = labels.index(blank_token) if blank_token in labels else 0\n",
    "                        unk_id = labels.index(unk_token) if unk_token in labels else None\n",
    "                    return VocabInfo()\n",
    "            \n",
    "            model = MockModelBackend(model, bundle)\n",
    "            print(\"   ‚Ä¢ Model loaded: torchaudio MMS_FA bundle\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # Run WFST Alignment\n",
    "        # =================================================================\n",
    "        print(\"\\nüîß Running WFST alignment...\")\n",
    "        \n",
    "        config = AlignmentConfig(\n",
    "            backend=\"wfst\",\n",
    "            segment_size=15.0,  # Short segment for this test\n",
    "            overlap=2.0,\n",
    "            skip_penalty=-0.5,\n",
    "            return_penalty=-18.0,\n",
    "        )\n",
    "        \n",
    "        aligner = WFSTAligner(config)\n",
    "        aligner.set_model(model)\n",
    "        \n",
    "        # Run alignment\n",
    "        result = aligner.align(waveform.squeeze(0), TRANSCRIPT)\n",
    "        \n",
    "        print(f\"\\nüìä Alignment Results:\")\n",
    "        print(f\"   ‚Ä¢ Aligned words: {result.num_aligned_words}\")\n",
    "        print(f\"   ‚Ä¢ Unaligned regions: {result.unaligned_indices}\")\n",
    "        \n",
    "        # Store for comparison\n",
    "        aligned_words = result.word_alignments\n",
    "        \n",
    "        print(f\"\\nüìù Word-level alignment results:\")\n",
    "        for idx, word in sorted(aligned_words.items()):\n",
    "            start_frame = word.start_time\n",
    "            end_frame = word.end_time if word.end_time else start_frame + 10\n",
    "            start_sec = start_frame / FRAME_RATE\n",
    "            end_sec = end_frame / FRAME_RATE if word.end_time else \"?\"\n",
    "            print(f\"   [{idx:2d}] {word.word:12s}: frame [{start_frame:4d}, {end_frame:4d}) = [{start_sec:.2f}s, {end_sec}s)\")\n",
    "        \n",
    "        test_results[\"Test 12\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 12 PASSED - WFST alignment completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 12\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 12 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 12: Run WFST Alignment on Sample Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test 11: Alignment Accuracy Test (with Ground Truth)\n",
      "============================================================\n",
      "\n",
      "üìã Ground Truth Data:\n",
      "   ‚Ä¢ Transcript: 'I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT'\n",
      "   ‚Ä¢ Frame rate: 50 fps (20ms/frame)\n",
      "   ‚Ä¢ Words: 9\n",
      "   ‚Ä¢ Characters: 47\n",
      "\n",
      "üìù Word-level ground truth:\n",
      "   I            (0.78): [  31,   35) = [0.62s, 0.70s)\n",
      "   HAD          (0.84): [  37,   44) = [0.74s, 0.88s)\n",
      "   THAT         (0.52): [  45,   53) = [0.90s, 1.06s)\n",
      "   CURIOSITY    (0.89): [  56,   92) = [1.12s, 1.84s)\n",
      "   BESIDE       (0.94): [  95,  116) = [1.90s, 2.32s)\n",
      "   ME           (0.67): [ 118,  124) = [2.36s, 2.48s)\n",
      "   AT           (0.66): [ 126,  129) = [2.52s, 2.58s)\n",
      "   THIS         (0.70): [ 131,  139) = [2.62s, 2.78s)\n",
      "   MOMENT       (0.88): [ 143,  157) = [2.86s, 3.14s)\n",
      "\n",
      "‚úÖ Test 11 PASSED - Ground truth data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 11: Alignment Accuracy Test (with Ground Truth)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Skip if dependencies not available\n",
    "if not K2_AVAILABLE:\n",
    "    test_results[\"Test 11\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Test 11 SKIPPED - k2 not available\")\n",
    "else:\n",
    "    try:\n",
    "        import torchaudio\n",
    "        from IPython.display import Audio, display\n",
    "        \n",
    "        # =================================================================\n",
    "        # Ground Truth Data (from MMS-FA CTC alignment)\n",
    "        # =================================================================\n",
    "        # Transcript: \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        # Frame rate: 50fps (20ms per frame)\n",
    "        \n",
    "        GROUND_TRUTH_WORDS = [\n",
    "            {\"word\": \"I\", \"start\": 31, \"end\": 35, \"score\": 0.78},\n",
    "            {\"word\": \"HAD\", \"start\": 37, \"end\": 44, \"score\": 0.84},\n",
    "            {\"word\": \"THAT\", \"start\": 45, \"end\": 53, \"score\": 0.52},\n",
    "            {\"word\": \"CURIOSITY\", \"start\": 56, \"end\": 92, \"score\": 0.89},\n",
    "            {\"word\": \"BESIDE\", \"start\": 95, \"end\": 116, \"score\": 0.94},\n",
    "            {\"word\": \"ME\", \"start\": 118, \"end\": 124, \"score\": 0.67},\n",
    "            {\"word\": \"AT\", \"start\": 126, \"end\": 129, \"score\": 0.66},\n",
    "            {\"word\": \"THIS\", \"start\": 131, \"end\": 139, \"score\": 0.70},\n",
    "            {\"word\": \"MOMENT\", \"start\": 143, \"end\": 157, \"score\": 0.88},\n",
    "        ]\n",
    "        \n",
    "        GROUND_TRUTH_CHARS = [\n",
    "            {\"char\": \"|\", \"start\": 0, \"end\": 31, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 31, \"end\": 35, \"score\": 0.78},\n",
    "            {\"char\": \"|\", \"start\": 35, \"end\": 37, \"score\": 0.80},\n",
    "            {\"char\": \"H\", \"start\": 37, \"end\": 39, \"score\": 1.00},\n",
    "            {\"char\": \"A\", \"start\": 39, \"end\": 41, \"score\": 0.96},\n",
    "            {\"char\": \"D\", \"start\": 41, \"end\": 44, \"score\": 0.65},\n",
    "            {\"char\": \"|\", \"start\": 44, \"end\": 45, \"score\": 1.00},\n",
    "            {\"char\": \"T\", \"start\": 45, \"end\": 47, \"score\": 0.55},\n",
    "            {\"char\": \"H\", \"start\": 47, \"end\": 49, \"score\": 1.00},\n",
    "            {\"char\": \"A\", \"start\": 49, \"end\": 52, \"score\": 0.03},\n",
    "            {\"char\": \"T\", \"start\": 52, \"end\": 53, \"score\": 1.00},\n",
    "            {\"char\": \"|\", \"start\": 53, \"end\": 56, \"score\": 1.00},\n",
    "            {\"char\": \"C\", \"start\": 56, \"end\": 61, \"score\": 0.97},\n",
    "            {\"char\": \"U\", \"start\": 61, \"end\": 63, \"score\": 1.00},\n",
    "            {\"char\": \"R\", \"start\": 63, \"end\": 67, \"score\": 0.75},\n",
    "            {\"char\": \"I\", \"start\": 67, \"end\": 75, \"score\": 0.88},\n",
    "            {\"char\": \"O\", \"start\": 75, \"end\": 79, \"score\": 0.99},\n",
    "            {\"char\": \"S\", \"start\": 79, \"end\": 83, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 83, \"end\": 86, \"score\": 0.89},\n",
    "            {\"char\": \"T\", \"start\": 86, \"end\": 90, \"score\": 0.78},\n",
    "            {\"char\": \"Y\", \"start\": 90, \"end\": 92, \"score\": 0.70},\n",
    "            {\"char\": \"|\", \"start\": 92, \"end\": 95, \"score\": 0.66},\n",
    "            {\"char\": \"B\", \"start\": 95, \"end\": 98, \"score\": 1.00},\n",
    "            {\"char\": \"E\", \"start\": 98, \"end\": 102, \"score\": 1.00},\n",
    "            {\"char\": \"S\", \"start\": 102, \"end\": 109, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 109, \"end\": 111, \"score\": 1.00},\n",
    "            {\"char\": \"D\", \"start\": 111, \"end\": 113, \"score\": 0.93},\n",
    "            {\"char\": \"E\", \"start\": 113, \"end\": 116, \"score\": 0.66},\n",
    "            {\"char\": \"|\", \"start\": 116, \"end\": 118, \"score\": 1.00},\n",
    "            {\"char\": \"M\", \"start\": 118, \"end\": 121, \"score\": 0.67},\n",
    "            {\"char\": \"E\", \"start\": 121, \"end\": 124, \"score\": 0.67},\n",
    "            {\"char\": \"|\", \"start\": 124, \"end\": 126, \"score\": 0.49},\n",
    "            {\"char\": \"A\", \"start\": 126, \"end\": 127, \"score\": 1.00},\n",
    "            {\"char\": \"T\", \"start\": 127, \"end\": 129, \"score\": 0.50},\n",
    "            {\"char\": \"|\", \"start\": 129, \"end\": 131, \"score\": 0.51},\n",
    "            {\"char\": \"T\", \"start\": 131, \"end\": 132, \"score\": 1.00},\n",
    "            {\"char\": \"H\", \"start\": 132, \"end\": 134, \"score\": 1.00},\n",
    "            {\"char\": \"I\", \"start\": 134, \"end\": 136, \"score\": 0.75},\n",
    "            {\"char\": \"S\", \"start\": 136, \"end\": 139, \"score\": 0.36},\n",
    "            {\"char\": \"|\", \"start\": 139, \"end\": 143, \"score\": 0.50},\n",
    "            {\"char\": \"M\", \"start\": 143, \"end\": 146, \"score\": 1.00},\n",
    "            {\"char\": \"O\", \"start\": 146, \"end\": 149, \"score\": 1.00},\n",
    "            {\"char\": \"M\", \"start\": 149, \"end\": 152, \"score\": 1.00},\n",
    "            {\"char\": \"E\", \"start\": 152, \"end\": 153, \"score\": 1.00},\n",
    "            {\"char\": \"N\", \"start\": 153, \"end\": 155, \"score\": 0.66},\n",
    "            {\"char\": \"T\", \"start\": 155, \"end\": 157, \"score\": 0.51},\n",
    "            {\"char\": \"|\", \"start\": 157, \"end\": 169, \"score\": 0.96},\n",
    "        ]\n",
    "        \n",
    "        # Transcript text\n",
    "        TRANSCRIPT = \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "        \n",
    "        # Frame parameters\n",
    "        FRAME_RATE = 50  # frames per second (20ms per frame)\n",
    "        SAMPLE_RATE = 16000\n",
    "        \n",
    "        print(\"\\nüìã Ground Truth Data:\")\n",
    "        print(f\"   ‚Ä¢ Transcript: '{TRANSCRIPT}'\")\n",
    "        print(f\"   ‚Ä¢ Frame rate: {FRAME_RATE} fps (20ms/frame)\")\n",
    "        print(f\"   ‚Ä¢ Words: {len(GROUND_TRUTH_WORDS)}\")\n",
    "        print(f\"   ‚Ä¢ Characters: {len(GROUND_TRUTH_CHARS)}\")\n",
    "        \n",
    "        print(\"\\nüìù Word-level ground truth:\")\n",
    "        for w in GROUND_TRUTH_WORDS:\n",
    "            start_sec = w['start'] / FRAME_RATE\n",
    "            end_sec = w['end'] / FRAME_RATE\n",
    "            print(f\"   {w['word']:12s} ({w['score']:.2f}): [{w['start']:4d}, {w['end']:4d}) = [{start_sec:.2f}s, {end_sec:.2f}s)\")\n",
    "        \n",
    "        test_results[\"Test 11\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n‚úÖ Test 11 PASSED - Ground truth data loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 11\"] = \"‚ùå FAILED\"\n",
    "        print(f\"\\n‚ùå Test 11 FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 11: Alignment Accuracy Test (with Ground Truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}