{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Test Notebook: Alignment Module\n",
    "\n",
    "This notebook tests the `alignment` module for speech-to-text alignment.\n",
    "\n",
    "**Tests:**\n",
    "1. Module imports and structure\n",
    "2. Data classes (AlignmentResult, AlignedWord, AlignedToken)\n",
    "3. WFST factor transducer construction\n",
    "4. Tokenizers (via text_frontend)\n",
    "5. Audio segmentation (via audio_frontend)\n",
    "6. LIS utilities\n",
    "7. MFA backend availability\n",
    "8. Gentle backend availability\n",
    "9. WFST Aligner integration\n",
    "10. Segment-wise alignment API\n",
    "11. Ground truth data loading\n",
    "12. Run WFST alignment on sample audio\n",
    "13. Accuracy comparison (prediction vs ground truth)\n",
    "14. Listening test (audio preview)\n",
    "\n",
    "**Installation (Colab):**\n",
    "```bash\n",
    "# GPU Version\n",
    "pip install k2==1.24.4.dev20251030+cuda12.6.torch2.9.0 -f https://k2-fsa.github.io/k2/cuda.html\n",
    "\n",
    "# CPU Version (use --no-deps to avoid env changes)\n",
    "pip install k2==1.24.4.dev20251029+cpu.torch2.9.0 --no-deps -f https://k2-fsa.github.io/k2/cpu.html\n",
    "\n",
    "# Common dependencies\n",
    "pip install pytorch-lightning cmudict g2p_en pydub\n",
    "pip install git+https://github.com/huangruizhe/lis.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset repo if needed (uncomment to force fresh clone)\n",
    "# !rm -rf /content/torchaudio_aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Install Dependencies (run once)\n",
    "# =============================================================================\n",
    "\n",
    "# ===== GPU Version =====\n",
    "# !pip install k2==1.24.4.dev20251030+cuda12.6.torch2.9.0 -f https://k2-fsa.github.io/k2/cuda.html\n",
    "\n",
    "# ===== CPU Version (--no-deps to avoid env changes) =====\n",
    "# !pip install k2==1.24.4.dev20251029+cpu.torch2.9.0 --no-deps -f https://k2-fsa.github.io/k2/cpu.html\n",
    "\n",
    "# ===== Common dependencies =====\n",
    "# !pip install pytorch-lightning cmudict g2p_en pydub\n",
    "# !pip install git+https://github.com/huangruizhe/lis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Setup: Configure Imports\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "GITHUB_REPO = \"https://github.com/huangruizhe/torchaudio_aligner.git\"\n",
    "BRANCH = \"dev\"\n",
    "# =========================\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "def setup_imports():\n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        repo_path = '/content/torchaudio_aligner'\n",
    "        src_path = f'{repo_path}/src'\n",
    "        \n",
    "        if not os.path.exists(repo_path):\n",
    "            print(f\"Cloning repository (branch: {BRANCH})...\")\n",
    "            os.system(f'git clone -b {BRANCH} {GITHUB_REPO} {repo_path}')\n",
    "        else:\n",
    "            print(f\"Updating repository (branch: {BRANCH})...\")\n",
    "            os.system(f'cd {repo_path} && git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}')\n",
    "    else:\n",
    "        possible_paths = [\n",
    "            Path(\".\").absolute().parent / \"src\",\n",
    "            Path(\".\").absolute() / \"src\",\n",
    "        ]\n",
    "        src_path = None\n",
    "        for p in possible_paths:\n",
    "            if p.exists() and (p / \"alignment\").exists():\n",
    "                src_path = str(p.absolute())\n",
    "                break\n",
    "        if src_path is None:\n",
    "            raise FileNotFoundError(\"src directory not found\")\n",
    "        print(f\"Running locally from: {src_path}\")\n",
    "    \n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "    return src_path\n",
    "\n",
    "src_path = setup_imports()\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Checking dependencies...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    import k2\n",
    "    print(f\"‚úÖ k2 available\")\n",
    "    K2_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è k2 not available\")\n",
    "    K2_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lis\n",
    "    print(\"‚úÖ lis library available\")\n",
    "    LIS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è lis not available\")\n",
    "    LIS_AVAILABLE = False\n",
    "\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Test 1: Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 1: Module Imports and Structure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from alignment import (\n",
    "        AlignmentResult, AlignedWord, AlignedToken, AlignmentConfig,\n",
    "        AlignerBackend, WFSTAligner, MFAAligner, GentleAligner,\n",
    "        align, get_aligner, list_backends,\n",
    "    )\n",
    "    print(\"üì¶ Imports successful!\")\n",
    "    backends = list_backends()\n",
    "    print(f\"\\nüîß Available backends: {list(backends.keys())}\")\n",
    "    test_results[\"Test 1\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 1 PASSED\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 1\"] = \"‚ùå FAILED\"\n",
    "    print(f\"‚ùå Test 1 FAILED: {e}\")\n",
    "    import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Test 2: Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 2: Data Classes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    config = AlignmentConfig(backend=\"wfst\", segment_size=15.0, skip_penalty=-0.5)\n",
    "    print(f\"AlignmentConfig: segment_size={config.segment_size}s\")\n",
    "    \n",
    "    word = AlignedWord(word=\"hello\", start_time=100, end_time=150)\n",
    "    print(f\"AlignedWord: '{word.word}' [{word.start_time}-{word.end_time}]\")\n",
    "    \n",
    "    result = AlignmentResult(\n",
    "        word_alignments={0: AlignedWord(\"hello\", 100, 150), 1: AlignedWord(\"world\", 160, 220)},\n",
    "        unaligned_indices=[(2, 3)],\n",
    "    )\n",
    "    print(f\"AlignmentResult: {result.num_aligned_words} words\")\n",
    "    \n",
    "    test_results[\"Test 2\"] = \"‚úÖ PASSED\"\n",
    "    print(f\"\\n‚úÖ Test 2 PASSED\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 2\"] = \"‚ùå FAILED\"\n",
    "    print(f\"‚ùå Test 2 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Test 3-10: Core Components\n",
    "\n",
    "Tests 3-10 verify WFST transducer, tokenizers, segmentation, LIS, and aligner backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: WFST Factor Transducer\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 3: WFST Factor Transducer\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE:\n",
    "    test_results[\"Test 3\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Skipped - k2 not available\")\n",
    "else:\n",
    "    try:\n",
    "        from alignment.wfst import make_factor_transducer_word_level_index_with_skip\n",
    "        tokenized = [[7, 4, 11, 11, 14], [22, 14, 17, 11, 3]]\n",
    "        graph, word_sym, token_sym = make_factor_transducer_word_level_index_with_skip(tokenized)\n",
    "        print(f\"Graph: {graph.shape[0]} states, {graph.num_arcs} arcs\")\n",
    "        test_results[\"Test 3\"] = \"‚úÖ PASSED\"\n",
    "        print(\"‚úÖ Test 3 PASSED\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 3\"] = \"‚ùå FAILED\"\n",
    "        print(f\"‚ùå Test 3 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Tokenizers\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 4: Tokenizers\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from text_frontend import CharTokenizer, create_tokenizer_from_labels\n",
    "    labels = ('-', 'a', 'i', 'e', 'n', 'o', 'u', 't', 's', 'r', 'm', 'k', 'l', 'd', \n",
    "              'g', 'h', 'y', 'b', 'p', 'w', 'c', 'v', 'j', 'z', 'f', \"'\", 'q', 'x', '*')\n",
    "    tokenizer = create_tokenizer_from_labels(labels)\n",
    "    encoded = tokenizer.encode(\"hello world\")\n",
    "    print(f\"Encoded 'hello world': {encoded}\")\n",
    "    test_results[\"Test 4\"] = \"‚úÖ PASSED\"\n",
    "    print(\"‚úÖ Test 4 PASSED\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 4\"] = \"‚ùå FAILED\"\n",
    "    print(f\"‚ùå Test 4 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Audio Segmentation\n",
    "print(\"=\" * 60)\n",
    "print(\"Test 5: Audio Segmentation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from audio_frontend import segment_waveform\n",
    "    waveform_test = torch.randn(480000)\n",
    "    result = segment_waveform(waveform_test, sample_rate=16000, segment_size=15.0, overlap=2.0)\n",
    "    print(f\"Segmented into {result.num_segments} segments\")\n",
    "    test_results[\"Test 5\"] = \"‚úÖ PASSED\"\n",
    "    print(\"‚úÖ Test 5 PASSED\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 5\"] = \"‚ùå FAILED\"\n",
    "    print(f\"‚ùå Test 5 FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests 6-10: LIS, MFA, Gentle, WFST Aligner, Segment API\n",
    "print(\"=\" * 60)\n",
    "print(\"Tests 6-10: Backend checks\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test 6: LIS\n",
    "if LIS_AVAILABLE:\n",
    "    try:\n",
    "        from alignment.wfst.lis_utils import compute_lis\n",
    "        lis_result = compute_lis([1, 5, 2, 6, 3, 7])\n",
    "        print(f\"Test 6 LIS: {lis_result} ‚úÖ\")\n",
    "        test_results[\"Test 6\"] = \"‚úÖ PASSED\"\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 6\"] = \"‚ùå FAILED\"\n",
    "        print(f\"Test 6 LIS: ‚ùå {e}\")\n",
    "else:\n",
    "    test_results[\"Test 6\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"Test 6 LIS: ‚è≠Ô∏è Skipped\")\n",
    "\n",
    "# Test 7: MFA\n",
    "try:\n",
    "    aligner = MFAAligner(AlignmentConfig(backend=\"mfa\"))\n",
    "    mfa_ok = aligner._check_mfa_available()\n",
    "    test_results[\"Test 7\"] = \"‚úÖ PASSED\" if mfa_ok else \"‚ö†Ô∏è MFA NOT INSTALLED\"\n",
    "    print(f\"Test 7 MFA: {'‚úÖ Available' if mfa_ok else '‚ö†Ô∏è Not installed'}\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 7\"] = \"‚ùå FAILED\"\n",
    "    print(f\"Test 7 MFA: ‚ùå {e}\")\n",
    "\n",
    "# Test 8: Gentle\n",
    "try:\n",
    "    aligner = GentleAligner(AlignmentConfig(backend=\"gentle\"))\n",
    "    gentle_ok = aligner._check_gentle_python() or aligner._check_gentle_server()\n",
    "    test_results[\"Test 8\"] = \"‚úÖ PASSED\" if gentle_ok else \"‚ö†Ô∏è GENTLE NOT INSTALLED\"\n",
    "    print(f\"Test 8 Gentle: {'‚úÖ Available' if gentle_ok else '‚ö†Ô∏è Not installed'}\")\n",
    "except Exception as e:\n",
    "    test_results[\"Test 8\"] = \"‚ùå FAILED\"\n",
    "    print(f\"Test 8 Gentle: ‚ùå {e}\")\n",
    "\n",
    "# Test 9-10: WFST Aligner\n",
    "if K2_AVAILABLE and LIS_AVAILABLE:\n",
    "    try:\n",
    "        from alignment import WFSTAligner, SegmentAlignmentResult\n",
    "        aligner = WFSTAligner(AlignmentConfig(backend=\"wfst\"))\n",
    "        has_align_segments = hasattr(aligner, 'align_segments')\n",
    "        test_results[\"Test 9\"] = \"‚úÖ PASSED\"\n",
    "        test_results[\"Test 10\"] = \"‚úÖ PASSED\" if has_align_segments else \"‚ùå FAILED\"\n",
    "        print(f\"Test 9 WFST Aligner: ‚úÖ\")\n",
    "        print(f\"Test 10 Segment API: {'‚úÖ' if has_align_segments else '‚ùå'}\")\n",
    "    except Exception as e:\n",
    "        test_results[\"Test 9\"] = \"‚ùå FAILED\"\n",
    "        test_results[\"Test 10\"] = \"‚ùå FAILED\"\n",
    "        print(f\"Test 9-10: ‚ùå {e}\")\n",
    "else:\n",
    "    test_results[\"Test 9\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    test_results[\"Test 10\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"Test 9-10: ‚è≠Ô∏è Skipped (missing k2/lis)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Test 11: Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 11: Ground Truth Data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ground truth from MMS-FA CTC alignment (50fps = 20ms per frame)\n",
    "TRANSCRIPT = \"I HAD THAT CURIOSITY BESIDE ME AT THIS MOMENT\"\n",
    "FRAME_RATE = 50  # 20ms per frame\n",
    "\n",
    "GROUND_TRUTH_WORDS = [\n",
    "    {\"word\": \"I\", \"start\": 31, \"end\": 35},\n",
    "    {\"word\": \"HAD\", \"start\": 37, \"end\": 44},\n",
    "    {\"word\": \"THAT\", \"start\": 45, \"end\": 53},\n",
    "    {\"word\": \"CURIOSITY\", \"start\": 56, \"end\": 92},\n",
    "    {\"word\": \"BESIDE\", \"start\": 95, \"end\": 116},\n",
    "    {\"word\": \"ME\", \"start\": 118, \"end\": 124},\n",
    "    {\"word\": \"AT\", \"start\": 126, \"end\": 129},\n",
    "    {\"word\": \"THIS\", \"start\": 131, \"end\": 139},\n",
    "    {\"word\": \"MOMENT\", \"start\": 143, \"end\": 157},\n",
    "]\n",
    "\n",
    "print(f\"Transcript: '{TRANSCRIPT}'\")\n",
    "print(f\"Frame rate: {FRAME_RATE} fps (20ms/frame)\")\n",
    "print(f\"\\nGround truth ({len(GROUND_TRUTH_WORDS)} words):\")\n",
    "for w in GROUND_TRUTH_WORDS:\n",
    "    start_sec = w['start'] / FRAME_RATE\n",
    "    end_sec = w['end'] / FRAME_RATE\n",
    "    print(f\"  {w['word']:12s}: [{w['start']:3d}, {w['end']:3d}) = [{start_sec:.2f}s, {end_sec:.2f}s)\")\n",
    "\n",
    "test_results[\"Test 11\"] = \"‚úÖ PASSED\"\n",
    "print(f\"\\n‚úÖ Test 11 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Test 12: Run WFST Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 12: Run WFST Alignment on Sample Audio\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not K2_AVAILABLE or not LIS_AVAILABLE:\n",
    "    test_results[\"Test 12\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Skipped - missing k2 or lis\")\n",
    "else:\n",
    "    try:\n",
    "        import torchaudio\n",
    "        from alignment import WFSTAligner, AlignmentConfig\n",
    "        \n",
    "        # Load sample audio\n",
    "        print(\"\\nüéµ Loading sample audio...\")\n",
    "        SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "        waveform, sr = torchaudio.load(SPEECH_URL)\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "            sr = 16000\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform[0:1]\n",
    "        print(f\"   Shape: {waveform.shape}, Duration: {waveform.size(1)/sr:.2f}s\")\n",
    "        \n",
    "        # Load model\n",
    "        print(\"\\nüîß Loading MMS-FA model...\")\n",
    "        try:\n",
    "            from labeling_utils import load_model\n",
    "            model = load_model(\"mms-fa\")\n",
    "        except ImportError:\n",
    "            bundle = torchaudio.pipelines.MMS_FA\n",
    "            _model = bundle.get_model().to(\"cpu\")\n",
    "            class MockModelBackend:\n",
    "                def __init__(self, model, bundle):\n",
    "                    self._model, self._bundle = model, bundle\n",
    "                def get_emissions(self, waveforms, lengths):\n",
    "                    with torch.inference_mode():\n",
    "                        return self._model(waveforms.squeeze(-1))\n",
    "                def get_vocab_info(self):\n",
    "                    class VI:\n",
    "                        labels = tuple(bundle.get_labels())\n",
    "                        blank_token, unk_token = '-', '*'\n",
    "                    return VI()\n",
    "            model = MockModelBackend(_model, bundle)\n",
    "        print(\"   Model loaded\")\n",
    "        \n",
    "        # Run alignment\n",
    "        print(\"\\nüîß Running alignment...\")\n",
    "        config = AlignmentConfig(backend=\"wfst\", segment_size=15.0, overlap=2.0)\n",
    "        aligner = WFSTAligner(config)\n",
    "        aligner.set_model(model)\n",
    "        alignment_result = aligner.align(waveform.squeeze(0), TRANSCRIPT)\n",
    "        \n",
    "        aligned_words = alignment_result.word_alignments\n",
    "        print(f\"\\nüìä Aligned {len(aligned_words)} words\")\n",
    "        \n",
    "        # Store for later tests\n",
    "        ALIGNED_WORDS = aligned_words\n",
    "        WAVEFORM = waveform\n",
    "        SR = sr\n",
    "        \n",
    "        test_results[\"Test 12\"] = \"‚úÖ PASSED\"\n",
    "        print(\"\\n‚úÖ Test 12 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 12\"] = \"‚ùå FAILED\"\n",
    "        print(f\"‚ùå Test 12 FAILED: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Test 13: Prediction vs Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 13: Prediction vs Ground Truth Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 12\" not in test_results or \"PASSED\" not in test_results.get(\"Test 12\", \"\"):\n",
    "    test_results[\"Test 13\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Skipped - Test 12 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"\\nüìä Prediction vs Ground Truth:\")\n",
    "        print(\"-\" * 90)\n",
    "        print(f\"{'Word':<12} {'GT Start':<10} {'Pred Start':<12} {'Œî Start':<10} {'GT End':<10} {'Pred End':<12} {'Status'}\")\n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        total_start_error = 0\n",
    "        matched = 0\n",
    "        \n",
    "        for gt in GROUND_TRUTH_WORDS:\n",
    "            word = gt[\"word\"]\n",
    "            gt_start, gt_end = gt[\"start\"], gt[\"end\"]\n",
    "            \n",
    "            # Find prediction\n",
    "            pred = None\n",
    "            for idx, aligned in ALIGNED_WORDS.items():\n",
    "                if aligned.word and aligned.word.upper() == word.upper():\n",
    "                    pred = aligned\n",
    "                    break\n",
    "            \n",
    "            if pred:\n",
    "                pred_start = int(pred.start_time)\n",
    "                pred_end = int(pred.end_time) if pred.end_time else pred_start + (gt_end - gt_start)\n",
    "                delta = abs(pred_start - gt_start)\n",
    "                total_start_error += delta\n",
    "                matched += 1\n",
    "                status = \"‚úÖ\" if delta <= 5 else (\"‚ö†Ô∏è\" if delta <= 10 else \"‚ùå\")\n",
    "                print(f\"{word:<12} {gt_start:<10} {pred_start:<12} {delta:<10} {gt_end:<10} {pred_end:<12} {status}\")\n",
    "            else:\n",
    "                print(f\"{word:<12} {gt_start:<10} {'N/A':<12} {'N/A':<10} {gt_end:<10} {'N/A':<12} ‚ùå NOT FOUND\")\n",
    "        \n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        if matched > 0:\n",
    "            avg_error = total_start_error / matched\n",
    "            print(f\"\\nüìà Summary:\")\n",
    "            print(f\"   Matched: {matched}/{len(GROUND_TRUTH_WORDS)} words\")\n",
    "            print(f\"   Avg start frame error: {avg_error:.1f} frames ({avg_error * 20:.0f}ms)\")\n",
    "            \n",
    "            if avg_error <= 5:\n",
    "                print(\"   Accuracy: ‚úÖ EXCELLENT\")\n",
    "            elif avg_error <= 10:\n",
    "                print(\"   Accuracy: ‚ö†Ô∏è ACCEPTABLE\")\n",
    "            else:\n",
    "                print(\"   Accuracy: ‚ùå NEEDS IMPROVEMENT\")\n",
    "        \n",
    "        test_results[\"Test 13\"] = \"‚úÖ PASSED\"\n",
    "        print(\"\\n‚úÖ Test 13 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 13\"] = \"‚ùå FAILED\"\n",
    "        print(f\"‚ùå Test 13 FAILED: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Test 14: Listening Test (Audio Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Test 14: Listening Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"Test 12\" not in test_results or \"PASSED\" not in test_results.get(\"Test 12\", \"\"):\n",
    "    test_results[\"Test 14\"] = \"‚è≠Ô∏è SKIPPED\"\n",
    "    print(\"‚è≠Ô∏è Skipped - Test 12 did not pass\")\n",
    "else:\n",
    "    try:\n",
    "        from IPython.display import Audio, display, HTML\n",
    "        \n",
    "        SAMPLES_PER_FRAME = SR // FRAME_RATE  # 320 samples per frame at 16kHz/50fps\n",
    "        \n",
    "        def get_audio_segment(start_frame, end_frame, padding_frames=2):\n",
    "            \"\"\"Extract audio segment by frame indices.\"\"\"\n",
    "            start_frame = max(0, start_frame - padding_frames)\n",
    "            end_frame = end_frame + padding_frames\n",
    "            x0 = int(start_frame * SAMPLES_PER_FRAME)\n",
    "            x1 = min(int(end_frame * SAMPLES_PER_FRAME), WAVEFORM.size(1))\n",
    "            return WAVEFORM[:, x0:x1]\n",
    "        \n",
    "        print(\"\\nüéß Listening to aligned words (Prediction vs Ground Truth):\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for gt in GROUND_TRUTH_WORDS:\n",
    "            word = gt[\"word\"]\n",
    "            gt_start, gt_end = gt[\"start\"], gt[\"end\"]\n",
    "            \n",
    "            # Find prediction\n",
    "            pred = None\n",
    "            for idx, aligned in ALIGNED_WORDS.items():\n",
    "                if aligned.word and aligned.word.upper() == word.upper():\n",
    "                    pred = aligned\n",
    "                    break\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"Word: {word}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            # Ground Truth audio\n",
    "            gt_audio = get_audio_segment(gt_start, gt_end)\n",
    "            gt_start_sec = gt_start / FRAME_RATE\n",
    "            gt_end_sec = gt_end / FRAME_RATE\n",
    "            print(f\"\\nüéØ Ground Truth: [{gt_start_sec:.3f}s - {gt_end_sec:.3f}s]\")\n",
    "            display(Audio(gt_audio.numpy(), rate=SR))\n",
    "            \n",
    "            # Prediction audio\n",
    "            if pred:\n",
    "                pred_start = int(pred.start_time)\n",
    "                pred_end = int(pred.end_time) if pred.end_time else pred_start + (gt_end - gt_start)\n",
    "                pred_audio = get_audio_segment(pred_start, pred_end)\n",
    "                pred_start_sec = pred_start / FRAME_RATE\n",
    "                pred_end_sec = pred_end / FRAME_RATE\n",
    "                delta = abs(pred_start - gt_start)\n",
    "                status = \"‚úÖ\" if delta <= 5 else (\"‚ö†Ô∏è\" if delta <= 10 else \"‚ùå\")\n",
    "                print(f\"\\nüîÆ Prediction: [{pred_start_sec:.3f}s - {pred_end_sec:.3f}s] (Œî={delta} frames) {status}\")\n",
    "                display(Audio(pred_audio.numpy(), rate=SR))\n",
    "            else:\n",
    "                print(f\"\\nüîÆ Prediction: ‚ùå NOT FOUND\")\n",
    "        \n",
    "        test_results[\"Test 14\"] = \"‚úÖ PASSED\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ Test 14 PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        test_results[\"Test 14\"] = \"‚ùå FAILED\"\n",
    "        print(f\"‚ùå Test 14 FAILED: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üìã TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print()\n",
    "for test_name, result in sorted(test_results.items(), key=lambda x: int(x[0].split()[1]) if x[0].split()[1].isdigit() else 99):\n",
    "    print(f\"  {result}  {test_name}\")\n",
    "\n",
    "passed = sum(1 for r in test_results.values() if \"‚úÖ\" in r)\n",
    "failed = sum(1 for r in test_results.values() if \"‚ùå\" in r)\n",
    "skipped = sum(1 for r in test_results.values() if \"‚è≠Ô∏è\" in r or \"‚ö†Ô∏è\" in r)\n",
    "\n",
    "print()\n",
    "print(f\"  Passed:  {passed}\")\n",
    "print(f\"  Skipped: {skipped}\")\n",
    "print(f\"  Failed:  {failed}\")\n",
    "print()\n",
    "\n",
    "if failed == 0:\n",
    "    print(\"üéâ All tests passed!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {failed} test(s) failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
